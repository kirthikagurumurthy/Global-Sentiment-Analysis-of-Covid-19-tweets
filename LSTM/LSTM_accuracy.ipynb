{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Manam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Manam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Vader-sentiment value</th>\n",
       "      <th>Vader-sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I wish quick recovery for talented @TOLOnews J...</td>\n",
       "      <td>2020-04-29 23:33:40+00:00</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>These chinese people on campus are so consider...</td>\n",
       "      <td>2020-01-28 23:41:13</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.5777</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>China‚Äôs Leader, Under Fire, Says He Led Corona...</td>\n",
       "      <td>2020-02-15 23:17:09</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>RT @DarrenEuronews: Top 5 countries üåç with hig...</td>\n",
       "      <td>Sat Jun 13 07:50:54 +0000 2020</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>RT @MileyCyrus: Spain, you united in solidarit...</td>\n",
       "      <td>Sat Jun 13 09:52:29 +0000 2020</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>RT @_junaidahmad_: Inshallah Get well soon !! ...</td>\n",
       "      <td>Sat Jun 13 10:00:38 +0000 2020</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>RT @UNICEF: Singing üé§, filming üé• and learning ...</td>\n",
       "      <td>Sat Jun 13 12:51:28 +0000 2020</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>I am proud of my spritual brothers and sisters...</td>\n",
       "      <td>Sat Jun 13 14:16:52 +0000 2020</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Just finished co-leading an @IBWellsSociety vi...</td>\n",
       "      <td>2020-04-29 23:21:09+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>‚ÄòIt‚Äôs going to disappear‚Äô: Trump‚Äôs changing to...</td>\n",
       "      <td>2020-04-29 23:04:41+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>What Every Fleet Should Be Doing Right Now. Le...</td>\n",
       "      <td>2020-04-29 23:03:04+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Promising early results for UAB coronavirus dr...</td>\n",
       "      <td>2020-04-29 22:40:07+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Alabama hospitals eager to resume elective med...</td>\n",
       "      <td>2020-04-29 22:38:45+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>The Coronavirus map looks like an attack Of th...</td>\n",
       "      <td>2020-04-29 22:31:05+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>-0.2244</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Mark your calendars - Friday, May 1st! #spread...</td>\n",
       "      <td>2020-04-29 22:29:11+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.4003</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>We‚Äôve literally gone from the white sex traffi...</td>\n",
       "      <td>2020-05-30 23:14:05+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>\"Eventually, doctors will find a coronavirus v...</td>\n",
       "      <td>2020-05-30 22:15:38+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.3919</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Masks, cold love, and wisdom by @karenharmenin...</td>\n",
       "      <td>2020-05-30 21:49:51+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>This country is in a fix that it hasn't been i...</td>\n",
       "      <td>2020-05-30 20:38:42+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.4559</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>So the first month of the new decade went some...</td>\n",
       "      <td>2020-01-30 23:06:34+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Coronavirus sounds nice and all but I'm actual...</td>\n",
       "      <td>2020-01-30 22:09:54+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>The WH is talking about a targeted tax cut(?) ...</td>\n",
       "      <td>2020-02-28 22:00:53+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>#PandemicPreparedness #COVID19 Since there hav...</td>\n",
       "      <td>2020-02-28 20:44:29+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>#COVID19 Update‚Äî Back to Hygiene basics! Schoo...</td>\n",
       "      <td>2020-02-28 20:10:20+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>As #COVID19 continues to spread, @esri has put...</td>\n",
       "      <td>2020-02-28 19:01:14+00:00</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>Also a good compendium of information on #nCoV...</td>\n",
       "      <td>2020-01-22 23:19:57</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>OMG I WAS JUST\\n\\nearlier today I was explaini...</td>\n",
       "      <td>2020-01-21 23:45:18</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>PATRIOTS PLEASE WATCH. PUT POLITICS ON HOLD.  ...</td>\n",
       "      <td>2020-01-27 23:51:05</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>This coronavirus is fast resembling a John Rin...</td>\n",
       "      <td>2020-01-29 23:41:01</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>Nice work @ALPublicHealth on comprehensive web...</td>\n",
       "      <td>2020-02-05 23:54:33</td>\n",
       "      <td>albania</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113541</th>\n",
       "      <td>30475</td>\n",
       "      <td>30475</td>\n",
       "      <td>260 reports of coronavirus-related TV Licensin...</td>\n",
       "      <td>2020-05-30 22:24:39+00:00</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.7003</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113542</th>\n",
       "      <td>30476</td>\n",
       "      <td>30476</td>\n",
       "      <td>Monkeys steal coronavirus samples after attack...</td>\n",
       "      <td>2020-05-30 20:43:45+00:00</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.7351</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113543</th>\n",
       "      <td>30477</td>\n",
       "      <td>30477</td>\n",
       "      <td>Don‚Äôt know what will kill us first ... World W...</td>\n",
       "      <td>2020-01-30 23:18:00+00:00</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.8625</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113544</th>\n",
       "      <td>30478</td>\n",
       "      <td>30478</td>\n",
       "      <td>Bloody hell ! The woman asking the Corona viru...</td>\n",
       "      <td>2020-01-30 23:06:57+00:00</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.8313</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113545</th>\n",
       "      <td>30479</td>\n",
       "      <td>30479</td>\n",
       "      <td>I think planes bringing Nationals home of like...</td>\n",
       "      <td>2020-01-30 22:56:21+00:00</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113546</th>\n",
       "      <td>30480</td>\n",
       "      <td>30480</td>\n",
       "      <td>This is the most inhumane and insensitive stat...</td>\n",
       "      <td>2020-01-30 21:30:58+00:00</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.5209</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113547</th>\n",
       "      <td>30481</td>\n",
       "      <td>30481</td>\n",
       "      <td>What compassion are you talking about? Their t...</td>\n",
       "      <td>2020-02-28 09:14:16+00:00</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.1926</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113548</th>\n",
       "      <td>30482</td>\n",
       "      <td>30482</td>\n",
       "      <td>@WHO issues warning after 'mysterious' Chinese...</td>\n",
       "      <td>2020-01-16 23:42:08</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113549</th>\n",
       "      <td>30483</td>\n",
       "      <td>30483</td>\n",
       "      <td>In total, 41 people in Wuhan have been diagnos...</td>\n",
       "      <td>2020-01-17 13:53:12</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.2893</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113550</th>\n",
       "      <td>30484</td>\n",
       "      <td>30484</td>\n",
       "      <td>Plz lm blank wat is corona virus ?yu only like...</td>\n",
       "      <td>2020-01-25 23:59:21</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113551</th>\n",
       "      <td>30485</td>\n",
       "      <td>30485</td>\n",
       "      <td>A whole finance minister who is in Davos but d...</td>\n",
       "      <td>2020-01-22 23:03:46</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113552</th>\n",
       "      <td>30486</td>\n",
       "      <td>30486</td>\n",
       "      <td>No goin back on #ShutDownZimbabwe2016 on Wed 1...</td>\n",
       "      <td>2020-02-07 23:39:35</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.5448</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113553</th>\n",
       "      <td>30487</td>\n",
       "      <td>30487</td>\n",
       "      <td>\"It would really help if the Zimbabwean govern...</td>\n",
       "      <td>2020-02-05 23:39:55</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113554</th>\n",
       "      <td>30488</td>\n",
       "      <td>30488</td>\n",
       "      <td>Hi Garry, are you still coming to the UK with ...</td>\n",
       "      <td>2020-02-01 23:56:29</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113555</th>\n",
       "      <td>30489</td>\n",
       "      <td>30489</td>\n",
       "      <td>RT @SebDance: Populism is *very* bad for your ...</td>\n",
       "      <td>Sat Jun 13 07:51:43 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.5849</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113556</th>\n",
       "      <td>30490</td>\n",
       "      <td>30490</td>\n",
       "      <td>RT @Mamoxn: The govt of Zimbabweüáøüáº will not,\\n...</td>\n",
       "      <td>Sat Jun 13 10:00:33 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.9001</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113557</th>\n",
       "      <td>30491</td>\n",
       "      <td>30491</td>\n",
       "      <td>Beijing in a Wartime lockdown as new cases of ...</td>\n",
       "      <td>Sat Jun 13 10:06:19 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113558</th>\n",
       "      <td>30492</td>\n",
       "      <td>30492</td>\n",
       "      <td>RT @maDube_: Police have arrested 62 801 peopl...</td>\n",
       "      <td>Sat Jun 13 10:06:37 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113559</th>\n",
       "      <td>30493</td>\n",
       "      <td>30493</td>\n",
       "      <td>RT @antonioguterres: People with albinism cont...</td>\n",
       "      <td>Sat Jun 13 10:04:31 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113560</th>\n",
       "      <td>30494</td>\n",
       "      <td>30494</td>\n",
       "      <td>More here from @inzyrashid on what was in the ...</td>\n",
       "      <td>Sat Jun 13 10:44:12 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113561</th>\n",
       "      <td>30495</td>\n",
       "      <td>30495</td>\n",
       "      <td>SA To Make 10 000 Cheap Ventilators\\n\\nFor mor...</td>\n",
       "      <td>Sat Jun 13 10:46:07 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113562</th>\n",
       "      <td>30496</td>\n",
       "      <td>30496</td>\n",
       "      <td>RT @XHNews: There have been coordinated effort...</td>\n",
       "      <td>Sat Jun 13 10:10:25 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113563</th>\n",
       "      <td>30497</td>\n",
       "      <td>30497</td>\n",
       "      <td>@SAFoundationN and @SAfridiOfficial has done s...</td>\n",
       "      <td>Sat Jun 13 10:57:32 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113564</th>\n",
       "      <td>30498</td>\n",
       "      <td>30498</td>\n",
       "      <td>RT @PachotoTribe: Young girls who are not goin...</td>\n",
       "      <td>Sat Jun 13 11:18:22 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113565</th>\n",
       "      <td>30499</td>\n",
       "      <td>30499</td>\n",
       "      <td>RT @Wamagaisa: I hear Delish Nguwaya is appear...</td>\n",
       "      <td>Sat Jun 13 11:21:24 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.5267</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113566</th>\n",
       "      <td>30500</td>\n",
       "      <td>30500</td>\n",
       "      <td>RT @YourAnonNews: Yesterday, there were 140,92...</td>\n",
       "      <td>Sat Jun 13 11:24:47 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113567</th>\n",
       "      <td>30501</td>\n",
       "      <td>30501</td>\n",
       "      <td>RT @iloharare: In the face of #covid19, we run...</td>\n",
       "      <td>Sat Jun 13 14:12:11 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.3274</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113568</th>\n",
       "      <td>30502</td>\n",
       "      <td>30502</td>\n",
       "      <td>RT @SAfridiOfficial: I‚Äôve been feeling unwell ...</td>\n",
       "      <td>Sat Jun 13 09:52:26 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.8020</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113569</th>\n",
       "      <td>30503</td>\n",
       "      <td>30503</td>\n",
       "      <td>It must be this Gvt which is worse than corona...</td>\n",
       "      <td>2020-03-02 23:49:25</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113570</th>\n",
       "      <td>30504</td>\n",
       "      <td>30504</td>\n",
       "      <td>BREAKING: Deputy leader of Iran's parliament s...</td>\n",
       "      <td>2020-03-03 23:57:40</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113571 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  \\\n",
       "0                0             0   \n",
       "1                1             1   \n",
       "2                2             2   \n",
       "3                3             3   \n",
       "4                4             4   \n",
       "5                5             5   \n",
       "6                6             6   \n",
       "7                7             7   \n",
       "8                8             8   \n",
       "9                9             9   \n",
       "10              10            10   \n",
       "11              11            11   \n",
       "12              12            12   \n",
       "13              13            13   \n",
       "14              14            14   \n",
       "15              15            15   \n",
       "16              16            16   \n",
       "17              17            17   \n",
       "18              18            18   \n",
       "19              19            19   \n",
       "20              20            20   \n",
       "21              21            21   \n",
       "22              22            22   \n",
       "23              23            23   \n",
       "24              24            24   \n",
       "25              25            25   \n",
       "26              26            26   \n",
       "27              27            27   \n",
       "28              28            28   \n",
       "29              29            29   \n",
       "...            ...           ...   \n",
       "113541       30475         30475   \n",
       "113542       30476         30476   \n",
       "113543       30477         30477   \n",
       "113544       30478         30478   \n",
       "113545       30479         30479   \n",
       "113546       30480         30480   \n",
       "113547       30481         30481   \n",
       "113548       30482         30482   \n",
       "113549       30483         30483   \n",
       "113550       30484         30484   \n",
       "113551       30485         30485   \n",
       "113552       30486         30486   \n",
       "113553       30487         30487   \n",
       "113554       30488         30488   \n",
       "113555       30489         30489   \n",
       "113556       30490         30490   \n",
       "113557       30491         30491   \n",
       "113558       30492         30492   \n",
       "113559       30493         30493   \n",
       "113560       30494         30494   \n",
       "113561       30495         30495   \n",
       "113562       30496         30496   \n",
       "113563       30497         30497   \n",
       "113564       30498         30498   \n",
       "113565       30499         30499   \n",
       "113566       30500         30500   \n",
       "113567       30501         30501   \n",
       "113568       30502         30502   \n",
       "113569       30503         30503   \n",
       "113570       30504         30504   \n",
       "\n",
       "                                                   Tweets  \\\n",
       "0       I wish quick recovery for talented @TOLOnews J...   \n",
       "1       These chinese people on campus are so consider...   \n",
       "2       China‚Äôs Leader, Under Fire, Says He Led Corona...   \n",
       "3       RT @DarrenEuronews: Top 5 countries üåç with hig...   \n",
       "4       RT @MileyCyrus: Spain, you united in solidarit...   \n",
       "5       RT @_junaidahmad_: Inshallah Get well soon !! ...   \n",
       "6       RT @UNICEF: Singing üé§, filming üé• and learning ...   \n",
       "7       I am proud of my spritual brothers and sisters...   \n",
       "8       Just finished co-leading an @IBWellsSociety vi...   \n",
       "9       ‚ÄòIt‚Äôs going to disappear‚Äô: Trump‚Äôs changing to...   \n",
       "10      What Every Fleet Should Be Doing Right Now. Le...   \n",
       "11      Promising early results for UAB coronavirus dr...   \n",
       "12      Alabama hospitals eager to resume elective med...   \n",
       "13      The Coronavirus map looks like an attack Of th...   \n",
       "14      Mark your calendars - Friday, May 1st! #spread...   \n",
       "15      We‚Äôve literally gone from the white sex traffi...   \n",
       "16      \"Eventually, doctors will find a coronavirus v...   \n",
       "17      Masks, cold love, and wisdom by @karenharmenin...   \n",
       "18      This country is in a fix that it hasn't been i...   \n",
       "19      So the first month of the new decade went some...   \n",
       "20      Coronavirus sounds nice and all but I'm actual...   \n",
       "21      The WH is talking about a targeted tax cut(?) ...   \n",
       "22      #PandemicPreparedness #COVID19 Since there hav...   \n",
       "23      #COVID19 Update‚Äî Back to Hygiene basics! Schoo...   \n",
       "24      As #COVID19 continues to spread, @esri has put...   \n",
       "25      Also a good compendium of information on #nCoV...   \n",
       "26      OMG I WAS JUST\\n\\nearlier today I was explaini...   \n",
       "27      PATRIOTS PLEASE WATCH. PUT POLITICS ON HOLD.  ...   \n",
       "28      This coronavirus is fast resembling a John Rin...   \n",
       "29      Nice work @ALPublicHealth on comprehensive web...   \n",
       "...                                                   ...   \n",
       "113541  260 reports of coronavirus-related TV Licensin...   \n",
       "113542  Monkeys steal coronavirus samples after attack...   \n",
       "113543  Don‚Äôt know what will kill us first ... World W...   \n",
       "113544  Bloody hell ! The woman asking the Corona viru...   \n",
       "113545  I think planes bringing Nationals home of like...   \n",
       "113546  This is the most inhumane and insensitive stat...   \n",
       "113547  What compassion are you talking about? Their t...   \n",
       "113548  @WHO issues warning after 'mysterious' Chinese...   \n",
       "113549  In total, 41 people in Wuhan have been diagnos...   \n",
       "113550  Plz lm blank wat is corona virus ?yu only like...   \n",
       "113551  A whole finance minister who is in Davos but d...   \n",
       "113552  No goin back on #ShutDownZimbabwe2016 on Wed 1...   \n",
       "113553  \"It would really help if the Zimbabwean govern...   \n",
       "113554  Hi Garry, are you still coming to the UK with ...   \n",
       "113555  RT @SebDance: Populism is *very* bad for your ...   \n",
       "113556  RT @Mamoxn: The govt of Zimbabweüáøüáº will not,\\n...   \n",
       "113557  Beijing in a Wartime lockdown as new cases of ...   \n",
       "113558  RT @maDube_: Police have arrested 62 801 peopl...   \n",
       "113559  RT @antonioguterres: People with albinism cont...   \n",
       "113560  More here from @inzyrashid on what was in the ...   \n",
       "113561  SA To Make 10 000 Cheap Ventilators\\n\\nFor mor...   \n",
       "113562  RT @XHNews: There have been coordinated effort...   \n",
       "113563  @SAFoundationN and @SAfridiOfficial has done s...   \n",
       "113564  RT @PachotoTribe: Young girls who are not goin...   \n",
       "113565  RT @Wamagaisa: I hear Delish Nguwaya is appear...   \n",
       "113566  RT @YourAnonNews: Yesterday, there were 140,92...   \n",
       "113567  RT @iloharare: In the face of #covid19, we run...   \n",
       "113568  RT @SAfridiOfficial: I‚Äôve been feeling unwell ...   \n",
       "113569  It must be this Gvt which is worse than corona...   \n",
       "113570  BREAKING: Deputy leader of Iran's parliament s...   \n",
       "\n",
       "                                  Date      Country  Vader-sentiment value  \\\n",
       "0            2020-04-29 23:33:40+00:00  afghanistan                 0.9022   \n",
       "1                  2020-01-28 23:41:13  afghanistan                 0.5777   \n",
       "2                  2020-02-15 23:17:09  afghanistan                -0.6124   \n",
       "3       Sat Jun 13 07:50:54 +0000 2020  afghanistan                 0.2732   \n",
       "4       Sat Jun 13 09:52:29 +0000 2020  afghanistan                 0.6249   \n",
       "5       Sat Jun 13 10:00:38 +0000 2020  afghanistan                 0.7835   \n",
       "6       Sat Jun 13 12:51:28 +0000 2020  afghanistan                 0.4019   \n",
       "7       Sat Jun 13 14:16:52 +0000 2020  afghanistan                 0.7096   \n",
       "8            2020-04-29 23:21:09+00:00      albania                 0.9441   \n",
       "9            2020-04-29 23:04:41+00:00      albania                 0.0000   \n",
       "10           2020-04-29 23:03:04+00:00      albania                 0.6124   \n",
       "11           2020-04-29 22:40:07+00:00      albania                 0.7003   \n",
       "12           2020-04-29 22:38:45+00:00      albania                 0.6486   \n",
       "13           2020-04-29 22:31:05+00:00      albania                -0.2244   \n",
       "14           2020-04-29 22:29:11+00:00      albania                 0.4003   \n",
       "15           2020-05-30 23:14:05+00:00      albania                 0.0000   \n",
       "16           2020-05-30 22:15:38+00:00      albania                 0.3919   \n",
       "17           2020-05-30 21:49:51+00:00      albania                 0.8225   \n",
       "18           2020-05-30 20:38:42+00:00      albania                 0.4559   \n",
       "19           2020-01-30 23:06:34+00:00      albania                 0.2732   \n",
       "20           2020-01-30 22:09:54+00:00      albania                 0.2263   \n",
       "21           2020-02-28 22:00:53+00:00      albania                 0.5773   \n",
       "22           2020-02-28 20:44:29+00:00      albania                 0.5848   \n",
       "23           2020-02-28 20:10:20+00:00      albania                 0.2139   \n",
       "24           2020-02-28 19:01:14+00:00      albania                 0.2960   \n",
       "25                 2020-01-22 23:19:57      albania                 0.4404   \n",
       "26                 2020-01-21 23:45:18      albania                 0.9042   \n",
       "27                 2020-01-27 23:51:05      albania                 0.5160   \n",
       "28                 2020-01-29 23:41:01      albania                 0.3182   \n",
       "29                 2020-02-05 23:54:33      albania                 0.5859   \n",
       "...                                ...          ...                    ...   \n",
       "113541       2020-05-30 22:24:39+00:00     zimbabwe                -0.7003   \n",
       "113542       2020-05-30 20:43:45+00:00     zimbabwe                -0.7351   \n",
       "113543       2020-01-30 23:18:00+00:00     zimbabwe                -0.8625   \n",
       "113544       2020-01-30 23:06:57+00:00     zimbabwe                -0.8313   \n",
       "113545       2020-01-30 22:56:21+00:00     zimbabwe                 0.0000   \n",
       "113546       2020-01-30 21:30:58+00:00     zimbabwe                -0.5209   \n",
       "113547       2020-02-28 09:14:16+00:00     zimbabwe                -0.1926   \n",
       "113548             2020-01-16 23:42:08     zimbabwe                -0.3400   \n",
       "113549             2020-01-17 13:53:12     zimbabwe                 0.2893   \n",
       "113550             2020-01-25 23:59:21     zimbabwe                 0.7269   \n",
       "113551             2020-01-22 23:03:46     zimbabwe                 0.0000   \n",
       "113552             2020-02-07 23:39:35     zimbabwe                -0.5448   \n",
       "113553             2020-02-05 23:39:55     zimbabwe                 0.1263   \n",
       "113554             2020-02-01 23:56:29     zimbabwe                 0.0000   \n",
       "113555  Sat Jun 13 07:51:43 +0000 2020     zimbabwe                -0.5849   \n",
       "113556  Sat Jun 13 10:00:33 +0000 2020     zimbabwe                -0.9001   \n",
       "113557  Sat Jun 13 10:06:19 +0000 2020     zimbabwe                -0.4215   \n",
       "113558  Sat Jun 13 10:06:37 +0000 2020     zimbabwe                -0.8555   \n",
       "113559  Sat Jun 13 10:04:31 +0000 2020     zimbabwe                -0.6249   \n",
       "113560  Sat Jun 13 10:44:12 +0000 2020     zimbabwe                -0.4404   \n",
       "113561  Sat Jun 13 10:46:07 +0000 2020     zimbabwe                 0.0000   \n",
       "113562  Sat Jun 13 10:10:25 +0000 2020     zimbabwe                 0.2500   \n",
       "113563  Sat Jun 13 10:57:32 +0000 2020     zimbabwe                -0.3400   \n",
       "113564  Sat Jun 13 11:18:22 +0000 2020     zimbabwe                 0.0000   \n",
       "113565  Sat Jun 13 11:21:24 +0000 2020     zimbabwe                -0.5267   \n",
       "113566  Sat Jun 13 11:24:47 +0000 2020     zimbabwe                 0.0000   \n",
       "113567  Sat Jun 13 14:12:11 +0000 2020     zimbabwe                -0.3274   \n",
       "113568  Sat Jun 13 09:52:26 +0000 2020     zimbabwe                -0.8020   \n",
       "113569             2020-03-02 23:49:25     zimbabwe                -0.4767   \n",
       "113570             2020-03-03 23:57:40     zimbabwe                -0.4939   \n",
       "\n",
       "       Vader-sentiment  \n",
       "0             positive  \n",
       "1             positive  \n",
       "2             negative  \n",
       "3             positive  \n",
       "4             positive  \n",
       "5             positive  \n",
       "6             positive  \n",
       "7             positive  \n",
       "8             positive  \n",
       "9              Neutral  \n",
       "10            positive  \n",
       "11            positive  \n",
       "12            positive  \n",
       "13            negative  \n",
       "14            positive  \n",
       "15             Neutral  \n",
       "16            positive  \n",
       "17            positive  \n",
       "18            positive  \n",
       "19            positive  \n",
       "20            positive  \n",
       "21            positive  \n",
       "22            positive  \n",
       "23            positive  \n",
       "24            positive  \n",
       "25            positive  \n",
       "26            positive  \n",
       "27            positive  \n",
       "28            positive  \n",
       "29            positive  \n",
       "...                ...  \n",
       "113541        negative  \n",
       "113542        negative  \n",
       "113543        negative  \n",
       "113544        negative  \n",
       "113545         Neutral  \n",
       "113546        negative  \n",
       "113547         Neutral  \n",
       "113548        negative  \n",
       "113549        positive  \n",
       "113550        positive  \n",
       "113551         Neutral  \n",
       "113552        negative  \n",
       "113553         Neutral  \n",
       "113554         Neutral  \n",
       "113555        negative  \n",
       "113556        negative  \n",
       "113557        negative  \n",
       "113558        negative  \n",
       "113559        negative  \n",
       "113560        negative  \n",
       "113561         Neutral  \n",
       "113562        positive  \n",
       "113563        negative  \n",
       "113564         Neutral  \n",
       "113565        negative  \n",
       "113566         Neutral  \n",
       "113567        negative  \n",
       "113568        negative  \n",
       "113569        negative  \n",
       "113570        negative  \n",
       "\n",
       "[113571 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('vaderDataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweets']=df['Tweets'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n",
    "    text_rc = re.sub('[0-9]+', '', text_lc)\n",
    "    tokens = re.split('\\W+', text_rc)    # tokenization\n",
    "    text = [word for word in tokens if word not in stopword]  # remove stopwords and stemming\n",
    "    return text\n",
    "df['Text_cleaned'] = df['Tweets'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Vader-sentiment value</th>\n",
       "      <th>Vader-sentiment</th>\n",
       "      <th>Text_cleaned</th>\n",
       "      <th>Text_stemmed</th>\n",
       "      <th>Text_lemmatized_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I wish quick recovery for talented @TOLOnews J...</td>\n",
       "      <td>2020-04-29 23:33:40+00:00</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wish, quick, recovery, talented, tolonews, jo...</td>\n",
       "      <td>[wish, quick, recoveri, talent, tolonew, journ...</td>\n",
       "      <td>[wish, quick, recoveri, talent, tolonew, journ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These chinese people on campus are so consider...</td>\n",
       "      <td>2020-01-28 23:41:13</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.5777</td>\n",
       "      <td>positive</td>\n",
       "      <td>[chinese, people, campus, considerate, wear, m...</td>\n",
       "      <td>[chines, peopl, campu, consider, wear, mask, o...</td>\n",
       "      <td>[chine, peopl, campu, consider, wear, mask, ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China‚Äôs Leader, Under Fire, Says He Led Corona...</td>\n",
       "      <td>2020-02-15 23:17:09</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>negative</td>\n",
       "      <td>[china, leader, fire, says, led, coronavirus, ...</td>\n",
       "      <td>[china, leader, fire, say, led, coronaviru, fi...</td>\n",
       "      <td>[china, leader, fire, say, led, coronaviru, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @DarrenEuronews: Top 5 countries üåç with hig...</td>\n",
       "      <td>Sat Jun 13 07:50:54 +0000 2020</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>positive</td>\n",
       "      <td>[rt, darreneuronews, top, countries, highest, ...</td>\n",
       "      <td>[rt, darreneuronew, top, countri, highest, num...</td>\n",
       "      <td>[rt, darreneuronew, top, countri, highest, num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @MileyCyrus: Spain, you united in solidarit...</td>\n",
       "      <td>Sat Jun 13 09:52:29 +0000 2020</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>positive</td>\n",
       "      <td>[rt, mileycyrus, spain, united, solidarity, bl...</td>\n",
       "      <td>[rt, mileycyru, spain, unit, solidar, black, l...</td>\n",
       "      <td>[rt, mileycyru, spain, unit, solidar, black, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  I wish quick recovery for talented @TOLOnews J...   \n",
       "1  These chinese people on campus are so consider...   \n",
       "2  China‚Äôs Leader, Under Fire, Says He Led Corona...   \n",
       "3  RT @DarrenEuronews: Top 5 countries üåç with hig...   \n",
       "4  RT @MileyCyrus: Spain, you united in solidarit...   \n",
       "\n",
       "                             Date      Country  Vader-sentiment value  \\\n",
       "0       2020-04-29 23:33:40+00:00  afghanistan                 0.9022   \n",
       "1             2020-01-28 23:41:13  afghanistan                 0.5777   \n",
       "2             2020-02-15 23:17:09  afghanistan                -0.6124   \n",
       "3  Sat Jun 13 07:50:54 +0000 2020  afghanistan                 0.2732   \n",
       "4  Sat Jun 13 09:52:29 +0000 2020  afghanistan                 0.6249   \n",
       "\n",
       "  Vader-sentiment                                       Text_cleaned  \\\n",
       "0        positive  [wish, quick, recovery, talented, tolonews, jo...   \n",
       "1        positive  [chinese, people, campus, considerate, wear, m...   \n",
       "2        negative  [china, leader, fire, says, led, coronavirus, ...   \n",
       "3        positive  [rt, darreneuronews, top, countries, highest, ...   \n",
       "4        positive  [rt, mileycyrus, spain, united, solidarity, bl...   \n",
       "\n",
       "                                        Text_stemmed  \\\n",
       "0  [wish, quick, recoveri, talent, tolonew, journ...   \n",
       "1  [chines, peopl, campu, consider, wear, mask, o...   \n",
       "2  [china, leader, fire, say, led, coronaviru, fi...   \n",
       "3  [rt, darreneuronew, top, countri, highest, num...   \n",
       "4  [rt, mileycyru, spain, unit, solidar, black, l...   \n",
       "\n",
       "                             Text_lemmatized_stemmed  \n",
       "0  [wish, quick, recoveri, talent, tolonew, journ...  \n",
       "1  [chine, peopl, campu, consider, wear, mask, ot...  \n",
       "2  [china, leader, fire, say, led, coronaviru, fi...  \n",
       "3  [rt, darreneuronew, top, countri, highest, num...  \n",
       "4  [rt, mileycyru, spain, unit, solidar, black, l...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['Text_stemmed'] = df['Text_cleaned'].apply(lambda x: stemming(x))\n",
    "\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "df['Text_lemmatized_stemmed'] = df['Text_stemmed'].apply(lambda x: lemmatizer(x))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "le = LabelEncoder() \n",
    "#df['deceptive']= le.fit_transform(df['deceptive'])\n",
    "df['polarity']= le.fit_transform(df['Vader-sentiment'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23049     [china, quarantin, wuhan, shut, airport, publi...\n",
       "53095      [fauci, gilead, remdesivir, block, coronaviru, ]\n",
       "49356     [rt, kattanew, maharashtra, state, govern, red...\n",
       "88116     [coronaviru, latest, public, health, england, ...\n",
       "96239     [case, confus, corona, beer, noth, coronaviru,...\n",
       "93028                [asian, peopl, corona, viru, eat, dog]\n",
       "24308     [coronaviru, epidem, updat, antivir, drug, tre...\n",
       "4115      [someon, left, unopen, bag, crisp, train, coro...\n",
       "10399     [malaysia, make, posit, progress, contain, cor...\n",
       "101686    [coronaviru, death, toll, surpass, new, death,...\n",
       "6235      [second, day, coronaviru, home, quarantin, lik...\n",
       "65968     [midnight, pub, across, road, live, glossop, c...\n",
       "53117     [coronaviru, brief, zoom, hydroxychloroquin, t...\n",
       "37493     [scottmorrisonmp, gladysb, enforc, endgam, c, ...\n",
       "29776     [someon, live, thru, wischolera, honest, god, ...\n",
       "107144    [corona, viru, gonna, turn, hollieclapp, even,...\n",
       "112502    [wish, american, believ, coronaviru, seriou, t...\n",
       "55440     [plea, rais, hand, think, govern, correctli, h...\n",
       "38340                    [hope, catch, coronaviru, still, ]\n",
       "103284    [think, im, die, ive, drink, later, may, coron...\n",
       "110959    [ill, add, ebola, hysteria, use, justifi, raci...\n",
       "95075     [sad, state, affair, manchest, unit, odion, ig...\n",
       "32416     [white, hous, report, need, send, intern, dail...\n",
       "15081     [sod, hey, guy, dont, fanci, dose, coronaviru,...\n",
       "8591      [rt, hpcl, hpcl, impart, regular, train, brief...\n",
       "59628     [countri, affect, novel, coronaviru, mani, cas...\n",
       "75540     [rt, shahmiruk, british, govern, tri, hide, vi...\n",
       "1489      [democraticahoax, trump, aclearandpresentdang,...\n",
       "83717     [victoria, medic, research, forefront, fight, ...\n",
       "79740     [komo, list, neighborhood, coronaviru, quarant...\n",
       "                                ...                        \n",
       "83660     [thank, stay, sportsrort, corrupt, govt, actua...\n",
       "21024     [get, vaccin, coronaviru, dr, david, ho, colum...\n",
       "70423     [dont, need, medic, expert, covid, czar, need,...\n",
       "64488     [rt, policeserviceni, awar, possibl, prearrang...\n",
       "58229     [two, popul, provinc, countri, punjab, sindh, ...\n",
       "82895     [coronaviru, got, think, ill, ever, get, chanc...\n",
       "60109     [latest, mash, potato, httpstcocsftpkdmp, covi...\n",
       "112881    [ncaa, grant, everi, spring, sport, athlet, an...\n",
       "84359     [good, call, anz, q, like, go, neg, said, mond...\n",
       "8177      [true, effect, would, turn, breakthrough, mome...\n",
       "27822     [make, next, move, post, covid, best, move, fe...\n",
       "86412     [im, expert, understand, technolog, need, deve...\n",
       "9259      [finish, nice, macho, man, diver, unit, state,...\n",
       "82780     [philli, polic, stop, narcot, arrest, charg, c...\n",
       "65819                        [coronaviru, one, word, bimbo]\n",
       "73212     [new, york, coronaviru, doctor, reaction, mani...\n",
       "87728     [new, one, excus, list, meet, due, coronaviru,...\n",
       "83270     [chine, scientist, desper, research, coronavir...\n",
       "46863     [rt, moneycontrolcom, covid, advic, keep, mind...\n",
       "78138     [santa, clara, counti, confirm, new, case, cor...\n",
       "27427     [rt, graenni, bet, see, msnbc, cnn, abc, cbsne...\n",
       "2528      [lab, first, share, covid, coronaviru, sequenc...\n",
       "85546     [rt, ifpri, covid, worsen, food, insecur, lmic...\n",
       "18105     [aclu, oklahoma, seek, releas, model, show, ma...\n",
       "53511     [gileadsci, neighbor, treat, local, chicago, s...\n",
       "94927     [alert, corona, viru, spread, new, viru, left,...\n",
       "101320            [turkey, coronaviru, death, toll, rise, ]\n",
       "71259     [aapl, appl, exec, talk, coronaviru, impact, i...\n",
       "37826     [youth, sport, get, coronaviru, reopen, conver...\n",
       "23449     [ill, best, suspect, coronaviru, case, within,...\n",
       "Name: Text_lemmatized_stemmed, Length: 90856, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['polarity']\n",
    "X = df['Text_lemmatized_stemmed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.preprocessing import text\n",
    "\n",
    "TOP_K = 30000\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 10000\n",
    "\n",
    "def sequence_vectorize(train_texts, val_texts):\n",
    "    tokenizer = text.Tokenizer(num_words=TOP_K)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "    x_train = tokenizer.texts_to_sequences(train_texts)\n",
    "    x_val = tokenizer.texts_to_sequences(val_texts)\n",
    "\n",
    "    max_length = len(max(x_train, key=len))\n",
    "    if max_length > MAX_SEQUENCE_LENGTH:\n",
    "        max_length = MAX_SEQUENCE_LENGTH\n",
    "\n",
    "    x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
    "    x_val = sequence.pad_sequences(x_val, maxlen=max_length)\n",
    "    return x_train, x_val, tokenizer.word_index, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val = X_train.values, X_test.values\n",
    "x_train, x_val, word_index, max_length = sequence_vectorize(x_train, x_val)\n",
    "num_features = min(len(word_index) + 1, TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -2.6585 - accuracy: 0.4848 - val_loss: -5.7857 - val_accuracy: 0.5621\n",
      "Epoch 2/1000\n",
      "710/710 [==============================] - 3585s 5s/step - loss: -8.3552 - accuracy: 0.5496 - val_loss: -10.6490 - val_accuracy: 0.5595\n",
      "Epoch 3/1000\n",
      "710/710 [==============================] - 157s 222ms/step - loss: -13.5058 - accuracy: 0.5484 - val_loss: -15.3163 - val_accuracy: 0.5572\n",
      "Epoch 4/1000\n",
      "710/710 [==============================] - 135s 190ms/step - loss: -18.6956 - accuracy: 0.5519 - val_loss: -19.7504 - val_accuracy: 0.5493\n",
      "Epoch 5/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -23.9239 - accuracy: 0.5543 - val_loss: -24.3115 - val_accuracy: 0.5477\n",
      "Epoch 6/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -29.2936 - accuracy: 0.5546 - val_loss: -28.4925 - val_accuracy: 0.5444\n",
      "Epoch 7/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -35.0738 - accuracy: 0.5568 - val_loss: -32.7193 - val_accuracy: 0.5450\n",
      "Epoch 8/1000\n",
      "710/710 [==============================] - 109s 154ms/step - loss: -40.6564 - accuracy: 0.5520 - val_loss: -37.2036 - val_accuracy: 0.5410\n",
      "Epoch 9/1000\n",
      "710/710 [==============================] - 109s 153ms/step - loss: -46.7923 - accuracy: 0.5514 - val_loss: -41.4668 - val_accuracy: 0.5342\n",
      "Epoch 10/1000\n",
      "710/710 [==============================] - 109s 154ms/step - loss: -52.5304 - accuracy: 0.5478 - val_loss: -46.2133 - val_accuracy: 0.5367\n",
      "Epoch 11/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -58.3836 - accuracy: 0.5488 - val_loss: -50.5464 - val_accuracy: 0.5370\n",
      "Epoch 12/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -64.4841 - accuracy: 0.5507 - val_loss: -54.8245 - val_accuracy: 0.5360\n",
      "Epoch 13/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -70.3741 - accuracy: 0.5524 - val_loss: -58.2969 - val_accuracy: 0.5347\n",
      "Epoch 14/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -76.1776 - accuracy: 0.5505 - val_loss: -63.1801 - val_accuracy: 0.5370\n",
      "Epoch 15/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -81.9430 - accuracy: 0.5515 - val_loss: -67.2722 - val_accuracy: 0.5400\n",
      "Epoch 16/1000\n",
      "710/710 [==============================] - 109s 154ms/step - loss: -87.9355 - accuracy: 0.5535 - val_loss: -70.8704 - val_accuracy: 0.5408\n",
      "Epoch 17/1000\n",
      "710/710 [==============================] - -15s -21408us/step - loss: -94.1260 - accuracy: 0.5505 - val_loss: -75.6580 - val_accuracy: 0.5389\n",
      "Epoch 18/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -100.2286 - accuracy: 0.5506 - val_loss: -79.7739 - val_accuracy: 0.5406\n",
      "Epoch 19/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -106.1070 - accuracy: 0.5530 - val_loss: -84.2928 - val_accuracy: 0.5389\n",
      "Epoch 20/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -112.1522 - accuracy: 0.5511 - val_loss: -88.4643 - val_accuracy: 0.5339\n",
      "Epoch 21/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -117.9003 - accuracy: 0.5518 - val_loss: -92.7255 - val_accuracy: 0.5403\n",
      "Epoch 22/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -124.4252 - accuracy: 0.5553 - val_loss: -97.6705 - val_accuracy: 0.5394\n",
      "Epoch 23/1000\n",
      "710/710 [==============================] - 109s 153ms/step - loss: -130.2545 - accuracy: 0.5553 - val_loss: -101.5216 - val_accuracy: 0.5371\n",
      "Epoch 24/1000\n",
      "710/710 [==============================] - 110s 155ms/step - loss: -136.0789 - accuracy: 0.5546 - val_loss: -106.4214 - val_accuracy: 0.5403\n",
      "Epoch 25/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -142.1435 - accuracy: 0.5502 - val_loss: -109.3445 - val_accuracy: 0.5391\n",
      "Epoch 26/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -148.1566 - accuracy: 0.5550 - val_loss: -113.5309 - val_accuracy: 0.5418\n",
      "Epoch 27/1000\n",
      "710/710 [==============================] - 113s 160ms/step - loss: -154.6881 - accuracy: 0.5577 - val_loss: -117.9744 - val_accuracy: 0.5446\n",
      "Epoch 28/1000\n",
      "710/710 [==============================] - 117s 164ms/step - loss: -159.8465 - accuracy: 0.5566 - val_loss: -122.5204 - val_accuracy: 0.5446\n",
      "Epoch 29/1000\n",
      "710/710 [==============================] - 115s 163ms/step - loss: -166.6859 - accuracy: 0.5565 - val_loss: -127.4974 - val_accuracy: 0.5459\n",
      "Epoch 30/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -172.3490 - accuracy: 0.5549 - val_loss: -130.6582 - val_accuracy: 0.5463\n",
      "Epoch 31/1000\n",
      "710/710 [==============================] - 118s 167ms/step - loss: -179.1181 - accuracy: 0.5600 - val_loss: -134.0273 - val_accuracy: 0.5465\n",
      "Epoch 32/1000\n",
      "710/710 [==============================] - 129s 182ms/step - loss: -184.4967 - accuracy: 0.5587 - val_loss: -139.5237 - val_accuracy: 0.5481\n",
      "Epoch 33/1000\n",
      "710/710 [==============================] - 128s 180ms/step - loss: -190.7959 - accuracy: 0.5595 - val_loss: -142.4417 - val_accuracy: 0.5466\n",
      "Epoch 34/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -197.1488 - accuracy: 0.5590 - val_loss: -147.2346 - val_accuracy: 0.5492\n",
      "Epoch 35/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -203.7657 - accuracy: 0.5625 - val_loss: -151.6224 - val_accuracy: 0.5540\n",
      "Epoch 36/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -209.8166 - accuracy: 0.5644 - val_loss: -156.4409 - val_accuracy: 0.5541\n",
      "Epoch 37/1000\n",
      "710/710 [==============================] - 109s 154ms/step - loss: -215.6101 - accuracy: 0.5651 - val_loss: -160.9347 - val_accuracy: 0.5554\n",
      "Epoch 38/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -221.8622 - accuracy: 0.5606 - val_loss: -164.7313 - val_accuracy: 0.5580\n",
      "Epoch 39/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -227.9119 - accuracy: 0.5620 - val_loss: -169.1556 - val_accuracy: 0.5584\n",
      "Epoch 40/1000\n",
      "710/710 [==============================] - 107s 150ms/step - loss: -233.7397 - accuracy: 0.5641 - val_loss: -173.2365 - val_accuracy: 0.5530\n",
      "Epoch 41/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -240.3313 - accuracy: 0.5641 - val_loss: -177.1768 - val_accuracy: 0.5562\n",
      "Epoch 42/1000\n",
      "710/710 [==============================] - 109s 153ms/step - loss: -246.1200 - accuracy: 0.5672 - val_loss: -180.7414 - val_accuracy: 0.5552\n",
      "Epoch 43/1000\n",
      "710/710 [==============================] - 107s 150ms/step - loss: -252.2113 - accuracy: 0.5667 - val_loss: -185.8638 - val_accuracy: 0.5606\n",
      "Epoch 44/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -258.5786 - accuracy: 0.5675 - val_loss: -190.3757 - val_accuracy: 0.5603\n",
      "Epoch 45/1000\n",
      "710/710 [==============================] - 109s 154ms/step - loss: -264.8491 - accuracy: 0.5669 - val_loss: -195.3237 - val_accuracy: 0.5566\n",
      "Epoch 46/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -270.8687 - accuracy: 0.5698 - val_loss: -198.6624 - val_accuracy: 0.5593\n",
      "Epoch 47/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -277.1793 - accuracy: 0.5669 - val_loss: -203.5602 - val_accuracy: 0.5597\n",
      "Epoch 48/1000\n",
      "710/710 [==============================] - 113s 160ms/step - loss: -282.7310 - accuracy: 0.5650 - val_loss: -205.9948 - val_accuracy: 0.5592\n",
      "Epoch 49/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -289.3492 - accuracy: 0.5687 - val_loss: -210.6640 - val_accuracy: 0.5624\n",
      "Epoch 50/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -295.9375 - accuracy: 0.5679 - val_loss: -214.9400 - val_accuracy: 0.5627\n",
      "Epoch 51/1000\n",
      "710/710 [==============================] - 115s 163ms/step - loss: -301.2707 - accuracy: 0.5679 - val_loss: -220.4698 - val_accuracy: 0.5606\n",
      "Epoch 52/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -306.8123 - accuracy: 0.5664 - val_loss: -223.8393 - val_accuracy: 0.5633\n",
      "Epoch 53/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -313.2589 - accuracy: 0.5685 - val_loss: -227.8984 - val_accuracy: 0.5625\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/710 [==============================] - 112s 158ms/step - loss: -320.7173 - accuracy: 0.5732 - val_loss: -230.6051 - val_accuracy: 0.5623\n",
      "Epoch 55/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -327.3591 - accuracy: 0.5743 - val_loss: -235.7710 - val_accuracy: 0.5650\n",
      "Epoch 56/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -333.4516 - accuracy: 0.5761 - val_loss: -239.4234 - val_accuracy: 0.5648\n",
      "Epoch 57/1000\n",
      "710/710 [==============================] - 106s 150ms/step - loss: -338.7773 - accuracy: 0.5744 - val_loss: -242.8559 - val_accuracy: 0.5631\n",
      "Epoch 58/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -344.8363 - accuracy: 0.5706 - val_loss: -248.2832 - val_accuracy: 0.5655\n",
      "Epoch 59/1000\n",
      "710/710 [==============================] - 110s 155ms/step - loss: -352.0590 - accuracy: 0.5743 - val_loss: -249.5157 - val_accuracy: 0.5619\n",
      "Epoch 60/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -357.7084 - accuracy: 0.5750 - val_loss: -257.2934 - val_accuracy: 0.5637\n",
      "Epoch 61/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -364.4947 - accuracy: 0.5737 - val_loss: -257.9433 - val_accuracy: 0.5652\n",
      "Epoch 62/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -371.2393 - accuracy: 0.5749 - val_loss: -262.4294 - val_accuracy: 0.5640\n",
      "Epoch 63/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -376.6670 - accuracy: 0.5760 - val_loss: -268.6521 - val_accuracy: 0.5651\n",
      "Epoch 64/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -382.6342 - accuracy: 0.5754 - val_loss: -272.0201 - val_accuracy: 0.5623\n",
      "Epoch 65/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -388.3333 - accuracy: 0.5753 - val_loss: -276.4057 - val_accuracy: 0.5654\n",
      "Epoch 66/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -395.4400 - accuracy: 0.5785 - val_loss: -279.9109 - val_accuracy: 0.5661\n",
      "Epoch 67/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -401.4670 - accuracy: 0.5777 - val_loss: -282.5826 - val_accuracy: 0.5643\n",
      "Epoch 68/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -408.3979 - accuracy: 0.5739 - val_loss: -287.1045 - val_accuracy: 0.5648\n",
      "Epoch 69/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -414.8953 - accuracy: 0.5795 - val_loss: -293.0660 - val_accuracy: 0.5651\n",
      "Epoch 70/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -421.9482 - accuracy: 0.5746 - val_loss: -295.6871 - val_accuracy: 0.5651\n",
      "Epoch 71/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -427.2779 - accuracy: 0.5747 - val_loss: -298.2985 - val_accuracy: 0.5650\n",
      "Epoch 72/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -431.6783 - accuracy: 0.5774 - val_loss: -303.9052 - val_accuracy: 0.5661\n",
      "Epoch 73/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -439.1834 - accuracy: 0.5766 - val_loss: -309.1629 - val_accuracy: 0.5658\n",
      "Epoch 74/1000\n",
      "710/710 [==============================] - 129s 181ms/step - loss: -445.3763 - accuracy: 0.5775 - val_loss: -309.5036 - val_accuracy: 0.5639\n",
      "Epoch 75/1000\n",
      "710/710 [==============================] - 130s 183ms/step - loss: -453.1160 - accuracy: 0.5764 - val_loss: -316.6371 - val_accuracy: 0.5662\n",
      "Epoch 76/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -459.0266 - accuracy: 0.5766 - val_loss: -321.2526 - val_accuracy: 0.5667\n",
      "Epoch 77/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -464.2008 - accuracy: 0.5776 - val_loss: -325.7557 - val_accuracy: 0.5702\n",
      "Epoch 78/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -470.4319 - accuracy: 0.5786 - val_loss: -330.6232 - val_accuracy: 0.5666\n",
      "Epoch 79/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -476.2065 - accuracy: 0.5783 - val_loss: -333.6003 - val_accuracy: 0.5676\n",
      "Epoch 80/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -482.1307 - accuracy: 0.5780 - val_loss: -338.6105 - val_accuracy: 0.5668\n",
      "Epoch 81/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -488.8207 - accuracy: 0.5763 - val_loss: -341.3052 - val_accuracy: 0.5668\n",
      "Epoch 82/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -496.1788 - accuracy: 0.5751 - val_loss: -345.0251 - val_accuracy: 0.5664\n",
      "Epoch 83/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -501.1333 - accuracy: 0.5808 - val_loss: -349.8670 - val_accuracy: 0.5650\n",
      "Epoch 84/1000\n",
      "710/710 [==============================] - 126s 178ms/step - loss: -509.2837 - accuracy: 0.5753 - val_loss: -354.1340 - val_accuracy: 0.5668\n",
      "Epoch 85/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -515.4451 - accuracy: 0.5763 - val_loss: -357.9875 - val_accuracy: 0.5666\n",
      "Epoch 86/1000\n",
      "710/710 [==============================] - 125s 176ms/step - loss: -518.7883 - accuracy: 0.5782 - val_loss: -364.6018 - val_accuracy: 0.5657\n",
      "Epoch 87/1000\n",
      "710/710 [==============================] - 111s 157ms/step - loss: -526.6993 - accuracy: 0.5799 - val_loss: -367.5008 - val_accuracy: 0.5664\n",
      "Epoch 88/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -534.2192 - accuracy: 0.5801 - val_loss: -371.6566 - val_accuracy: 0.5653\n",
      "Epoch 89/1000\n",
      "710/710 [==============================] - 109s 153ms/step - loss: -539.2371 - accuracy: 0.5813 - val_loss: -373.8425 - val_accuracy: 0.5671\n",
      "Epoch 90/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -546.9030 - accuracy: 0.5818 - val_loss: -377.6987 - val_accuracy: 0.5634\n",
      "Epoch 91/1000\n",
      "710/710 [==============================] - 112s 157ms/step - loss: -550.7604 - accuracy: 0.5797 - val_loss: -384.8923 - val_accuracy: 0.5642\n",
      "Epoch 92/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -558.7850 - accuracy: 0.5799 - val_loss: -387.0091 - val_accuracy: 0.5642\n",
      "Epoch 93/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -563.9871 - accuracy: 0.5774 - val_loss: -392.6255 - val_accuracy: 0.5650\n",
      "Epoch 94/1000\n",
      "710/710 [==============================] - 110s 154ms/step - loss: -569.2542 - accuracy: 0.5784 - val_loss: -395.2555 - val_accuracy: 0.5635\n",
      "Epoch 95/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -577.9739 - accuracy: 0.5788 - val_loss: -400.6961 - val_accuracy: 0.5628\n",
      "Epoch 96/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -582.2734 - accuracy: 0.5811 - val_loss: -403.6521 - val_accuracy: 0.5637\n",
      "Epoch 97/1000\n",
      "710/710 [==============================] - 109s 154ms/step - loss: -589.8053 - accuracy: 0.5784 - val_loss: -411.4857 - val_accuracy: 0.5625\n",
      "Epoch 98/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -598.0308 - accuracy: 0.5792 - val_loss: -415.6375 - val_accuracy: 0.5642\n",
      "Epoch 99/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -602.4186 - accuracy: 0.5796 - val_loss: -417.5467 - val_accuracy: 0.5613\n",
      "Epoch 100/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -610.8029 - accuracy: 0.5802 - val_loss: -421.1515 - val_accuracy: 0.5591\n",
      "Epoch 101/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -617.0119 - accuracy: 0.5767 - val_loss: -427.3947 - val_accuracy: 0.5608\n",
      "Epoch 102/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -621.8781 - accuracy: 0.5798 - val_loss: -426.8537 - val_accuracy: 0.5614\n",
      "Epoch 103/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -627.2691 - accuracy: 0.5790 - val_loss: -432.0144 - val_accuracy: 0.5611\n",
      "Epoch 104/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -634.1417 - accuracy: 0.5834 - val_loss: -436.4794 - val_accuracy: 0.5620\n",
      "Epoch 105/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -641.6241 - accuracy: 0.5831 - val_loss: -441.4596 - val_accuracy: 0.5629\n",
      "Epoch 106/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -647.3038 - accuracy: 0.5810 - val_loss: -446.5941 - val_accuracy: 0.5613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -651.5580 - accuracy: 0.5830 - val_loss: -451.5698 - val_accuracy: 0.5622\n",
      "Epoch 108/1000\n",
      "710/710 [==============================] - 118s 167ms/step - loss: -660.9999 - accuracy: 0.5834 - val_loss: -452.4270 - val_accuracy: 0.5636\n",
      "Epoch 109/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -666.5715 - accuracy: 0.5819 - val_loss: -455.3858 - val_accuracy: 0.5666\n",
      "Epoch 110/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -671.6085 - accuracy: 0.5807 - val_loss: -462.5189 - val_accuracy: 0.5634\n",
      "Epoch 111/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -677.7142 - accuracy: 0.5813 - val_loss: -465.0641 - val_accuracy: 0.5623\n",
      "Epoch 112/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -685.7951 - accuracy: 0.5839 - val_loss: -468.9673 - val_accuracy: 0.5605\n",
      "Epoch 113/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -691.9517 - accuracy: 0.5812 - val_loss: -472.7981 - val_accuracy: 0.5576\n",
      "Epoch 114/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -697.4282 - accuracy: 0.5799 - val_loss: -478.6911 - val_accuracy: 0.5627\n",
      "Epoch 115/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -704.1397 - accuracy: 0.5797 - val_loss: -483.5630 - val_accuracy: 0.5621\n",
      "Epoch 116/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -707.6591 - accuracy: 0.5770 - val_loss: -484.1465 - val_accuracy: 0.5589\n",
      "Epoch 117/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -717.2387 - accuracy: 0.5795 - val_loss: -490.8329 - val_accuracy: 0.5617\n",
      "Epoch 118/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -725.5177 - accuracy: 0.5828 - val_loss: -496.3694 - val_accuracy: 0.5615\n",
      "Epoch 119/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -729.6213 - accuracy: 0.5789 - val_loss: -499.2094 - val_accuracy: 0.5643\n",
      "Epoch 120/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -735.9695 - accuracy: 0.5804 - val_loss: -501.6353 - val_accuracy: 0.5613\n",
      "Epoch 121/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -742.1822 - accuracy: 0.5810 - val_loss: -504.4601 - val_accuracy: 0.5605\n",
      "Epoch 122/1000\n",
      "710/710 [==============================] - 125s 177ms/step - loss: -747.4497 - accuracy: 0.5785 - val_loss: -505.3777 - val_accuracy: 0.5616\n",
      "Epoch 123/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -752.2839 - accuracy: 0.5785 - val_loss: -510.2510 - val_accuracy: 0.5602\n",
      "Epoch 124/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -760.5794 - accuracy: 0.5829 - val_loss: -511.7760 - val_accuracy: 0.5605\n",
      "Epoch 125/1000\n",
      "710/710 [==============================] - 125s 176ms/step - loss: -768.6027 - accuracy: 0.5834 - val_loss: -518.4393 - val_accuracy: 0.5627\n",
      "Epoch 126/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -773.7299 - accuracy: 0.5853 - val_loss: -520.9205 - val_accuracy: 0.5630\n",
      "Epoch 127/1000\n",
      "710/710 [==============================] - 125s 175ms/step - loss: -779.0859 - accuracy: 0.5817 - val_loss: -528.9671 - val_accuracy: 0.5642\n",
      "Epoch 128/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -785.5856 - accuracy: 0.5816 - val_loss: -531.6901 - val_accuracy: 0.5611\n",
      "Epoch 129/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -790.3965 - accuracy: 0.5808 - val_loss: -538.5991 - val_accuracy: 0.5623\n",
      "Epoch 130/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -797.9910 - accuracy: 0.5817 - val_loss: -539.8495 - val_accuracy: 0.5610\n",
      "Epoch 131/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -804.4467 - accuracy: 0.5803 - val_loss: -545.5112 - val_accuracy: 0.5581\n",
      "Epoch 132/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -808.7524 - accuracy: 0.5812 - val_loss: -549.5196 - val_accuracy: 0.5609\n",
      "Epoch 133/1000\n",
      "710/710 [==============================] - 109s 153ms/step - loss: -816.4522 - accuracy: 0.5838 - val_loss: -550.0225 - val_accuracy: 0.5591\n",
      "Epoch 134/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -823.9133 - accuracy: 0.5816 - val_loss: -556.2750 - val_accuracy: 0.5588\n",
      "Epoch 135/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -831.4080 - accuracy: 0.5808 - val_loss: -560.4370 - val_accuracy: 0.5572\n",
      "Epoch 136/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -833.9575 - accuracy: 0.5839 - val_loss: -569.2280 - val_accuracy: 0.5589\n",
      "Epoch 137/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -841.2230 - accuracy: 0.5812 - val_loss: -572.6239 - val_accuracy: 0.5587\n",
      "Epoch 138/1000\n",
      "710/710 [==============================] - 110s 155ms/step - loss: -846.9544 - accuracy: 0.5788 - val_loss: -572.9963 - val_accuracy: 0.5573\n",
      "Epoch 139/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -852.1646 - accuracy: 0.5799 - val_loss: -574.0910 - val_accuracy: 0.5548\n",
      "Epoch 140/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -860.4138 - accuracy: 0.5832 - val_loss: -580.6453 - val_accuracy: 0.5574\n",
      "Epoch 141/1000\n",
      "710/710 [==============================] - 181s 254ms/step - loss: -867.9558 - accuracy: 0.5798 - val_loss: -580.8768 - val_accuracy: 0.5557\n",
      "Epoch 142/1000\n",
      "710/710 [==============================] - 188s 265ms/step - loss: -873.0728 - accuracy: 0.5840 - val_loss: -592.5869 - val_accuracy: 0.5572\n",
      "Epoch 143/1000\n",
      "710/710 [==============================] - 151s 213ms/step - loss: -880.4617 - accuracy: 0.5835 - val_loss: -596.1683 - val_accuracy: 0.5579\n",
      "Epoch 144/1000\n",
      "710/710 [==============================] - 143s 201ms/step - loss: -885.7295 - accuracy: 0.5820 - val_loss: -596.6684 - val_accuracy: 0.5584\n",
      "Epoch 145/1000\n",
      "710/710 [==============================] - 139s 195ms/step - loss: -891.6849 - accuracy: 0.5837 - val_loss: -599.7819 - val_accuracy: 0.5611\n",
      "Epoch 146/1000\n",
      "710/710 [==============================] - 141s 199ms/step - loss: -897.2115 - accuracy: 0.5839 - val_loss: -599.7615 - val_accuracy: 0.5593\n",
      "Epoch 147/1000\n",
      "710/710 [==============================] - 143s 202ms/step - loss: -905.3676 - accuracy: 0.5812 - val_loss: -610.6514 - val_accuracy: 0.5583\n",
      "Epoch 148/1000\n",
      "710/710 [==============================] - 147s 206ms/step - loss: -912.1074 - accuracy: 0.5807 - val_loss: -611.7831 - val_accuracy: 0.5584\n",
      "Epoch 149/1000\n",
      "710/710 [==============================] - 145s 204ms/step - loss: -920.3028 - accuracy: 0.5852 - val_loss: -615.7017 - val_accuracy: 0.5572\n",
      "Epoch 150/1000\n",
      "710/710 [==============================] - 148s 208ms/step - loss: -924.2544 - accuracy: 0.5827 - val_loss: -615.9653 - val_accuracy: 0.5581\n",
      "Epoch 151/1000\n",
      "710/710 [==============================] - 148s 208ms/step - loss: -929.4235 - accuracy: 0.5853 - val_loss: -622.2490 - val_accuracy: 0.5570\n",
      "Epoch 152/1000\n",
      "710/710 [==============================] - 146s 206ms/step - loss: -938.2111 - accuracy: 0.5808 - val_loss: -628.8392 - val_accuracy: 0.5586\n",
      "Epoch 153/1000\n",
      "710/710 [==============================] - 146s 206ms/step - loss: -944.3103 - accuracy: 0.5801 - val_loss: -633.7816 - val_accuracy: 0.5565\n",
      "Epoch 154/1000\n",
      "710/710 [==============================] - 144s 203ms/step - loss: -951.9747 - accuracy: 0.5834 - val_loss: -636.1007 - val_accuracy: 0.5564\n",
      "Epoch 155/1000\n",
      "710/710 [==============================] - 142s 200ms/step - loss: -955.3698 - accuracy: 0.5832 - val_loss: -639.4149 - val_accuracy: 0.5582\n",
      "Epoch 156/1000\n",
      "710/710 [==============================] - 143s 201ms/step - loss: -961.0655 - accuracy: 0.5857 - val_loss: -646.1977 - val_accuracy: 0.5585\n",
      "Epoch 157/1000\n",
      "710/710 [==============================] - 138s 194ms/step - loss: -967.4066 - accuracy: 0.5821 - val_loss: -649.7443 - val_accuracy: 0.5581\n",
      "Epoch 158/1000\n",
      "710/710 [==============================] - 139s 195ms/step - loss: -974.8566 - accuracy: 0.5835 - val_loss: -655.2002 - val_accuracy: 0.5568\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/710 [==============================] - 140s 197ms/step - loss: -980.6348 - accuracy: 0.5831 - val_loss: -657.1827 - val_accuracy: 0.5566\n",
      "Epoch 160/1000\n",
      "710/710 [==============================] - 172s 242ms/step - loss: -987.6516 - accuracy: 0.5819 - val_loss: -663.7927 - val_accuracy: 0.5584\n",
      "Epoch 161/1000\n",
      "710/710 [==============================] - 189s 266ms/step - loss: -993.5642 - accuracy: 0.5855 - val_loss: -669.3317 - val_accuracy: 0.5565\n",
      "Epoch 162/1000\n",
      "710/710 [==============================] - 190s 268ms/step - loss: -998.9057 - accuracy: 0.5869 - val_loss: -667.4125 - val_accuracy: 0.5573\n",
      "Epoch 163/1000\n",
      "710/710 [==============================] - 188s 265ms/step - loss: -1006.4863 - accuracy: 0.5853 - val_loss: -672.0831 - val_accuracy: 0.5585\n",
      "Epoch 164/1000\n",
      "710/710 [==============================] - 191s 269ms/step - loss: -1013.5870 - accuracy: 0.5874 - val_loss: -680.9731 - val_accuracy: 0.5583\n",
      "Epoch 165/1000\n",
      "710/710 [==============================] - 191s 269ms/step - loss: -1020.0531 - accuracy: 0.5864 - val_loss: -677.9551 - val_accuracy: 0.5579\n",
      "Epoch 166/1000\n",
      "710/710 [==============================] - 191s 269ms/step - loss: -1027.5897 - accuracy: 0.5880 - val_loss: -683.0681 - val_accuracy: 0.5594\n",
      "Epoch 167/1000\n",
      "710/710 [==============================] - 178s 251ms/step - loss: -1030.0803 - accuracy: 0.5844 - val_loss: -692.9514 - val_accuracy: 0.5598\n",
      "Epoch 168/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -1038.8611 - accuracy: 0.5899 - val_loss: -698.0955 - val_accuracy: 0.5609\n",
      "Epoch 169/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -1046.5751 - accuracy: 0.5905 - val_loss: -705.2985 - val_accuracy: 0.5584\n",
      "Epoch 170/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -1052.8915 - accuracy: 0.5864 - val_loss: -702.4979 - val_accuracy: 0.5586\n",
      "Epoch 171/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -1058.1169 - accuracy: 0.5886 - val_loss: -712.7349 - val_accuracy: 0.5589\n",
      "Epoch 172/1000\n",
      "710/710 [==============================] - 109s 154ms/step - loss: -1066.2722 - accuracy: 0.5867 - val_loss: -713.0918 - val_accuracy: 0.5576\n",
      "Epoch 173/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -1068.0587 - accuracy: 0.5866 - val_loss: -717.5704 - val_accuracy: 0.5594\n",
      "Epoch 174/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -1077.2725 - accuracy: 0.5872 - val_loss: -723.0691 - val_accuracy: 0.5595\n",
      "Epoch 175/1000\n",
      "710/710 [==============================] - 110s 155ms/step - loss: -1082.2859 - accuracy: 0.5854 - val_loss: -726.2136 - val_accuracy: 0.5568\n",
      "Epoch 176/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -1091.6232 - accuracy: 0.5874 - val_loss: -730.2711 - val_accuracy: 0.5576\n",
      "Epoch 177/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -1096.0458 - accuracy: 0.5891 - val_loss: -731.0533 - val_accuracy: 0.5579\n",
      "Epoch 178/1000\n",
      "710/710 [==============================] - 112s 157ms/step - loss: -1101.8838 - accuracy: 0.5887 - val_loss: -731.0865 - val_accuracy: 0.5591\n",
      "Epoch 179/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -1104.5883 - accuracy: 0.5886 - val_loss: -739.0940 - val_accuracy: 0.5576\n",
      "Epoch 180/1000\n",
      "710/710 [==============================] - 125s 176ms/step - loss: -1114.8545 - accuracy: 0.5905 - val_loss: -740.5923 - val_accuracy: 0.5584\n",
      "Epoch 181/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -1118.8713 - accuracy: 0.5901 - val_loss: -745.2079 - val_accuracy: 0.5594\n",
      "Epoch 182/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -1126.4943 - accuracy: 0.5893 - val_loss: -748.5403 - val_accuracy: 0.5613\n",
      "Epoch 183/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -1134.8693 - accuracy: 0.5924 - val_loss: -757.8989 - val_accuracy: 0.5582\n",
      "Epoch 184/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -1142.8873 - accuracy: 0.5884 - val_loss: -759.2828 - val_accuracy: 0.5590\n",
      "Epoch 185/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -1145.2050 - accuracy: 0.5883 - val_loss: -758.8978 - val_accuracy: 0.5580\n",
      "Epoch 186/1000\n",
      "710/710 [==============================] - 117s 164ms/step - loss: -1153.2988 - accuracy: 0.5857 - val_loss: -767.9417 - val_accuracy: 0.5584\n",
      "Epoch 187/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -1159.0330 - accuracy: 0.5903 - val_loss: -775.3173 - val_accuracy: 0.5594\n",
      "Epoch 188/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -1162.7375 - accuracy: 0.5933 - val_loss: -776.8179 - val_accuracy: 0.5597\n",
      "Epoch 189/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -1173.1639 - accuracy: 0.5886 - val_loss: -780.5280 - val_accuracy: 0.5603\n",
      "Epoch 190/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -1179.0311 - accuracy: 0.5899 - val_loss: -782.6523 - val_accuracy: 0.5592\n",
      "Epoch 191/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -1185.3302 - accuracy: 0.5876 - val_loss: -785.3007 - val_accuracy: 0.5591\n",
      "Epoch 192/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -1190.1545 - accuracy: 0.5897 - val_loss: -794.2419 - val_accuracy: 0.5596\n",
      "Epoch 193/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -1193.5107 - accuracy: 0.5927 - val_loss: -791.0067 - val_accuracy: 0.5595\n",
      "Epoch 194/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -1201.9620 - accuracy: 0.5913 - val_loss: -797.8605 - val_accuracy: 0.5613\n",
      "Epoch 195/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -1210.5396 - accuracy: 0.5940 - val_loss: -802.6302 - val_accuracy: 0.5630\n",
      "Epoch 196/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -1219.3954 - accuracy: 0.5931 - val_loss: -804.8107 - val_accuracy: 0.5610\n",
      "Epoch 197/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -1221.3898 - accuracy: 0.5936 - val_loss: -805.8592 - val_accuracy: 0.5558\n",
      "Epoch 198/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -1229.5365 - accuracy: 0.5920 - val_loss: -810.7137 - val_accuracy: 0.5586\n",
      "Epoch 199/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -1237.9896 - accuracy: 0.5924 - val_loss: -817.2350 - val_accuracy: 0.5585\n",
      "Epoch 200/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -1241.9363 - accuracy: 0.5886 - val_loss: -815.6045 - val_accuracy: 0.5583\n",
      "Epoch 201/1000\n",
      "710/710 [==============================] - 111s 157ms/step - loss: -1250.7948 - accuracy: 0.5952 - val_loss: -821.9290 - val_accuracy: 0.5610\n",
      "Epoch 202/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -1253.7046 - accuracy: 0.5950 - val_loss: -827.7656 - val_accuracy: 0.5605\n",
      "Epoch 203/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -1260.6404 - accuracy: 0.5940 - val_loss: -833.2341 - val_accuracy: 0.5606\n",
      "Epoch 204/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -1264.4037 - accuracy: 0.5910 - val_loss: -834.1171 - val_accuracy: 0.5594\n",
      "Epoch 205/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -1273.4446 - accuracy: 0.5939 - val_loss: -843.0165 - val_accuracy: 0.5586\n",
      "Epoch 206/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -1280.1089 - accuracy: 0.5932 - val_loss: -843.5599 - val_accuracy: 0.5613\n",
      "Epoch 207/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -1286.3687 - accuracy: 0.5922 - val_loss: -850.0207 - val_accuracy: 0.5580\n",
      "Epoch 208/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -1291.7195 - accuracy: 0.5940 - val_loss: -856.9571 - val_accuracy: 0.5618\n",
      "Epoch 209/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -1301.0178 - accuracy: 0.5943 - val_loss: -859.2947 - val_accuracy: 0.5598\n",
      "Epoch 210/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -1304.7605 - accuracy: 0.5944 - val_loss: -860.0554 - val_accuracy: 0.5609\n",
      "Epoch 211/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/710 [==============================] - 114s 161ms/step - loss: -1312.7096 - accuracy: 0.5954 - val_loss: -857.7850 - val_accuracy: 0.5605\n",
      "Epoch 212/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -1322.2461 - accuracy: 0.5952 - val_loss: -869.5259 - val_accuracy: 0.5621\n",
      "Epoch 213/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -1325.1942 - accuracy: 0.5975 - val_loss: -875.5401 - val_accuracy: 0.5587\n",
      "Epoch 214/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -1328.1257 - accuracy: 0.5899 - val_loss: -878.2240 - val_accuracy: 0.5601\n",
      "Epoch 215/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -1336.8721 - accuracy: 0.5946 - val_loss: -879.7712 - val_accuracy: 0.5594\n",
      "Epoch 216/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -1343.2340 - accuracy: 0.5962 - val_loss: -891.8561 - val_accuracy: 0.5599\n",
      "Epoch 217/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -1352.2212 - accuracy: 0.5970 - val_loss: -884.1584 - val_accuracy: 0.5598\n",
      "Epoch 218/1000\n",
      "710/710 [==============================] - 118s 167ms/step - loss: -1354.4304 - accuracy: 0.5987 - val_loss: -885.7928 - val_accuracy: 0.5600\n",
      "Epoch 219/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -1361.6487 - accuracy: 0.5948 - val_loss: -896.1558 - val_accuracy: 0.5597\n",
      "Epoch 220/1000\n",
      "710/710 [==============================] - 112s 157ms/step - loss: -1367.8385 - accuracy: 0.5948 - val_loss: -898.4203 - val_accuracy: 0.5591\n",
      "Epoch 221/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -1376.5203 - accuracy: 0.5937 - val_loss: -908.2928 - val_accuracy: 0.5598\n",
      "Epoch 222/1000\n",
      "710/710 [==============================] - 1523s 2s/step - loss: -1382.2780 - accuracy: 0.5949 - val_loss: -907.8381 - val_accuracy: 0.5601\n",
      "Epoch 223/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -1386.2200 - accuracy: 0.5954 - val_loss: -914.9503 - val_accuracy: 0.5589\n",
      "Epoch 224/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -1395.4025 - accuracy: 0.5960 - val_loss: -915.8865 - val_accuracy: 0.5582\n",
      "Epoch 225/1000\n",
      "710/710 [==============================] - 112s 157ms/step - loss: -1402.0518 - accuracy: 0.5960 - val_loss: -919.3882 - val_accuracy: 0.5575\n",
      "Epoch 226/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -1404.8079 - accuracy: 0.5953 - val_loss: -924.2781 - val_accuracy: 0.5586\n",
      "Epoch 227/1000\n",
      "710/710 [==============================] - 109s 154ms/step - loss: -1413.6284 - accuracy: 0.5949 - val_loss: -928.2676 - val_accuracy: 0.5598\n",
      "Epoch 228/1000\n",
      "710/710 [==============================] - 110s 155ms/step - loss: -1416.6456 - accuracy: 0.5932 - val_loss: -933.4189 - val_accuracy: 0.5593\n",
      "Epoch 229/1000\n",
      "710/710 [==============================] - 111s 157ms/step - loss: -1426.6691 - accuracy: 0.5951 - val_loss: -935.8998 - val_accuracy: 0.5586\n",
      "Epoch 230/1000\n",
      "710/710 [==============================] - 50s 70ms/step - loss: -1429.8988 - accuracy: 0.5952 - val_loss: -951.2975 - val_accuracy: 0.5594\n",
      "Epoch 231/1000\n",
      "710/710 [==============================] - 113s 160ms/step - loss: -1438.2426 - accuracy: 0.5940 - val_loss: -948.2081 - val_accuracy: 0.5577\n",
      "Epoch 232/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -1442.1711 - accuracy: 0.5992 - val_loss: -953.6042 - val_accuracy: 0.5582\n",
      "Epoch 233/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -1449.4397 - accuracy: 0.5971 - val_loss: -958.3197 - val_accuracy: 0.5580\n",
      "Epoch 234/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -1457.0555 - accuracy: 0.5961 - val_loss: -958.0630 - val_accuracy: 0.5582\n",
      "Epoch 235/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -1463.1511 - accuracy: 0.5973 - val_loss: -969.2518 - val_accuracy: 0.5592\n",
      "Epoch 236/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -1469.4226 - accuracy: 0.5988 - val_loss: -965.4468 - val_accuracy: 0.5593\n",
      "Epoch 237/1000\n",
      "710/710 [==============================] - 113s 158ms/step - loss: -1477.9102 - accuracy: 0.5984 - val_loss: -966.7791 - val_accuracy: 0.5617\n",
      "Epoch 238/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -1483.3914 - accuracy: 0.5978 - val_loss: -967.8220 - val_accuracy: 0.5580\n",
      "Epoch 239/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -1487.7142 - accuracy: 0.5970 - val_loss: -973.6392 - val_accuracy: 0.5606\n",
      "Epoch 240/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -1494.5554 - accuracy: 0.5978 - val_loss: -982.8582 - val_accuracy: 0.5604\n",
      "Epoch 241/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -1499.9398 - accuracy: 0.5965 - val_loss: -983.7298 - val_accuracy: 0.5587\n",
      "Epoch 242/1000\n",
      "710/710 [==============================] - 125s 176ms/step - loss: -1504.7960 - accuracy: 0.5977 - val_loss: -989.7582 - val_accuracy: 0.5571\n",
      "Epoch 243/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -1516.0009 - accuracy: 0.5992 - val_loss: -993.1409 - val_accuracy: 0.5585\n",
      "Epoch 244/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -1516.7483 - accuracy: 0.5979 - val_loss: -1000.2061 - val_accuracy: 0.5582\n",
      "Epoch 245/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -1523.6946 - accuracy: 0.5928 - val_loss: -999.7181 - val_accuracy: 0.5607\n",
      "Epoch 246/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -1530.2163 - accuracy: 0.5986 - val_loss: -1003.8986 - val_accuracy: 0.5595\n",
      "Epoch 247/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -1540.2136 - accuracy: 0.5985 - val_loss: -1002.3406 - val_accuracy: 0.5593\n",
      "Epoch 248/1000\n",
      "710/710 [==============================] - 112s 157ms/step - loss: -1545.1149 - accuracy: 0.5997 - val_loss: -1008.0963 - val_accuracy: 0.5599\n",
      "Epoch 249/1000\n",
      "710/710 [==============================] - 111s 157ms/step - loss: -1554.3895 - accuracy: 0.6001 - val_loss: -1015.8428 - val_accuracy: 0.5600\n",
      "Epoch 250/1000\n",
      "710/710 [==============================] - 111s 157ms/step - loss: -1555.1637 - accuracy: 0.5975 - val_loss: -1019.3416 - val_accuracy: 0.5568\n",
      "Epoch 251/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -1564.5311 - accuracy: 0.5988 - val_loss: -1028.1337 - val_accuracy: 0.5599\n",
      "Epoch 252/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -1572.0656 - accuracy: 0.6012 - val_loss: -1040.7782 - val_accuracy: 0.5606\n",
      "Epoch 253/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -1578.6565 - accuracy: 0.5989 - val_loss: -1035.2972 - val_accuracy: 0.5586\n",
      "Epoch 254/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -1587.2239 - accuracy: 0.6026 - val_loss: -1041.6445 - val_accuracy: 0.5609\n",
      "Epoch 255/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -1587.5881 - accuracy: 0.6000 - val_loss: -1041.0078 - val_accuracy: 0.5606\n",
      "Epoch 256/1000\n",
      "710/710 [==============================] - 112s 157ms/step - loss: -1600.7458 - accuracy: 0.5997 - val_loss: -1046.3234 - val_accuracy: 0.5617\n",
      "Epoch 257/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -1603.0383 - accuracy: 0.6023 - val_loss: -1046.8424 - val_accuracy: 0.5611\n",
      "Epoch 258/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -1612.1085 - accuracy: 0.5994 - val_loss: -1043.8607 - val_accuracy: 0.5613\n",
      "Epoch 259/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -1614.6160 - accuracy: 0.6012 - val_loss: -1051.2889 - val_accuracy: 0.5615\n",
      "Epoch 260/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -1623.4222 - accuracy: 0.6022 - val_loss: -1056.7245 - val_accuracy: 0.5604\n",
      "Epoch 261/1000\n",
      "710/710 [==============================] - 107s 150ms/step - loss: -1627.9482 - accuracy: 0.6028 - val_loss: -1063.9364 - val_accuracy: 0.5585\n",
      "Epoch 262/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -1634.3939 - accuracy: 0.6035 - val_loss: -1067.7528 - val_accuracy: 0.5584\n",
      "Epoch 263/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/710 [==============================] - 112s 158ms/step - loss: -1649.7346 - accuracy: 0.6003 - val_loss: -1067.0902 - val_accuracy: 0.5570\n",
      "Epoch 264/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -1648.9778 - accuracy: 0.5975 - val_loss: -1069.6532 - val_accuracy: 0.5578\n",
      "Epoch 265/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -1655.1954 - accuracy: 0.5980 - val_loss: -1076.8281 - val_accuracy: 0.5563\n",
      "Epoch 266/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -1657.3333 - accuracy: 0.6011 - val_loss: -1091.6060 - val_accuracy: 0.5601\n",
      "Epoch 267/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -1668.0581 - accuracy: 0.6012 - val_loss: -1092.7479 - val_accuracy: 0.5576\n",
      "Epoch 268/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -1673.2937 - accuracy: 0.6009 - val_loss: -1090.4626 - val_accuracy: 0.5573\n",
      "Epoch 269/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -1680.5177 - accuracy: 0.6038 - val_loss: -1100.2228 - val_accuracy: 0.5595\n",
      "Epoch 270/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -1685.3352 - accuracy: 0.5999 - val_loss: -1102.9712 - val_accuracy: 0.5608\n",
      "Epoch 271/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -1692.2643 - accuracy: 0.6033 - val_loss: -1103.1234 - val_accuracy: 0.5580\n",
      "Epoch 272/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -1694.8965 - accuracy: 0.6022 - val_loss: -1108.7277 - val_accuracy: 0.5592\n",
      "Epoch 273/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -1708.1655 - accuracy: 0.6009 - val_loss: -1111.8394 - val_accuracy: 0.5599\n",
      "Epoch 274/1000\n",
      "710/710 [==============================] - 118s 167ms/step - loss: -1713.4589 - accuracy: 0.6028 - val_loss: -1112.3295 - val_accuracy: 0.5583\n",
      "Epoch 275/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -1718.3373 - accuracy: 0.6029 - val_loss: -1122.4714 - val_accuracy: 0.5571\n",
      "Epoch 276/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -1719.3411 - accuracy: 0.5963 - val_loss: -1128.9421 - val_accuracy: 0.5582\n",
      "Epoch 277/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -1731.6216 - accuracy: 0.5993 - val_loss: -1121.7522 - val_accuracy: 0.5571\n",
      "Epoch 278/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -1734.0585 - accuracy: 0.6009 - val_loss: -1133.2070 - val_accuracy: 0.5584\n",
      "Epoch 279/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -1741.4928 - accuracy: 0.5994 - val_loss: -1131.9756 - val_accuracy: 0.5560\n",
      "Epoch 280/1000\n",
      "710/710 [==============================] - 113s 160ms/step - loss: -1747.8372 - accuracy: 0.6024 - val_loss: -1146.2509 - val_accuracy: 0.5592\n",
      "Epoch 281/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -1753.2633 - accuracy: 0.6021 - val_loss: -1140.9612 - val_accuracy: 0.5597\n",
      "Epoch 282/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -1764.5824 - accuracy: 0.6026 - val_loss: -1138.2233 - val_accuracy: 0.5591\n",
      "Epoch 283/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -1766.5557 - accuracy: 0.6026 - val_loss: -1150.2434 - val_accuracy: 0.5599\n",
      "Epoch 284/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -1772.3254 - accuracy: 0.6012 - val_loss: -1156.4751 - val_accuracy: 0.5579\n",
      "Epoch 285/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -1778.6106 - accuracy: 0.6042 - val_loss: -1162.3107 - val_accuracy: 0.5608\n",
      "Epoch 286/1000\n",
      "710/710 [==============================] - 120s 168ms/step - loss: -1789.1797 - accuracy: 0.6014 - val_loss: -1162.3395 - val_accuracy: 0.5569\n",
      "Epoch 287/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -1796.0558 - accuracy: 0.6036 - val_loss: -1169.1731 - val_accuracy: 0.5576\n",
      "Epoch 288/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -1802.4996 - accuracy: 0.6005 - val_loss: -1169.2408 - val_accuracy: 0.5585\n",
      "Epoch 289/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -1809.4819 - accuracy: 0.6009 - val_loss: -1178.7192 - val_accuracy: 0.5590\n",
      "Epoch 290/1000\n",
      "710/710 [==============================] - 117s 164ms/step - loss: -1811.8973 - accuracy: 0.5998 - val_loss: -1182.0127 - val_accuracy: 0.5606\n",
      "Epoch 291/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -1821.8374 - accuracy: 0.5988 - val_loss: -1187.1615 - val_accuracy: 0.5612\n",
      "Epoch 292/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -1825.2194 - accuracy: 0.6015 - val_loss: -1189.7808 - val_accuracy: 0.5622\n",
      "Epoch 293/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -1832.5032 - accuracy: 0.6027 - val_loss: -1196.1047 - val_accuracy: 0.5626\n",
      "Epoch 294/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -1839.5894 - accuracy: 0.6022 - val_loss: -1194.5576 - val_accuracy: 0.5597\n",
      "Epoch 295/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -1843.4735 - accuracy: 0.6017 - val_loss: -1210.4342 - val_accuracy: 0.5591\n",
      "Epoch 296/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -1852.7168 - accuracy: 0.6008 - val_loss: -1209.3411 - val_accuracy: 0.5577\n",
      "Epoch 297/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -1859.7363 - accuracy: 0.5997 - val_loss: -1220.4080 - val_accuracy: 0.5587\n",
      "Epoch 298/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -1863.7423 - accuracy: 0.6004 - val_loss: -1216.8372 - val_accuracy: 0.5582\n",
      "Epoch 299/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -1872.3307 - accuracy: 0.6010 - val_loss: -1220.2609 - val_accuracy: 0.5595\n",
      "Epoch 300/1000\n",
      "710/710 [==============================] - 110s 155ms/step - loss: -1874.3383 - accuracy: 0.5992 - val_loss: -1217.1807 - val_accuracy: 0.5588\n",
      "Epoch 301/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -1881.7939 - accuracy: 0.5984 - val_loss: -1225.1924 - val_accuracy: 0.5590\n",
      "Epoch 302/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -1886.7671 - accuracy: 0.5990 - val_loss: -1228.0570 - val_accuracy: 0.5608\n",
      "Epoch 303/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -1893.0109 - accuracy: 0.6001 - val_loss: -1234.9268 - val_accuracy: 0.5591\n",
      "Epoch 304/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -1900.0880 - accuracy: 0.6022 - val_loss: -1232.1390 - val_accuracy: 0.5572\n",
      "Epoch 305/1000\n",
      "710/710 [==============================] - 113s 158ms/step - loss: -1908.8462 - accuracy: 0.6032 - val_loss: -1248.7374 - val_accuracy: 0.5603\n",
      "Epoch 306/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -1916.2996 - accuracy: 0.6007 - val_loss: -1244.8142 - val_accuracy: 0.5577\n",
      "Epoch 307/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -1922.2595 - accuracy: 0.6028 - val_loss: -1255.3409 - val_accuracy: 0.5591\n",
      "Epoch 308/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -1928.7284 - accuracy: 0.6022 - val_loss: -1253.9116 - val_accuracy: 0.5584\n",
      "Epoch 309/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -1933.7748 - accuracy: 0.6032 - val_loss: -1261.3931 - val_accuracy: 0.5589\n",
      "Epoch 310/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -1935.6884 - accuracy: 0.6020 - val_loss: -1262.8232 - val_accuracy: 0.5581\n",
      "Epoch 311/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -1947.9897 - accuracy: 0.6023 - val_loss: -1267.9956 - val_accuracy: 0.5588\n",
      "Epoch 312/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -1948.9281 - accuracy: 0.6030 - val_loss: -1272.3589 - val_accuracy: 0.5590\n",
      "Epoch 313/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -1956.6700 - accuracy: 0.6030 - val_loss: -1266.4238 - val_accuracy: 0.5601\n",
      "Epoch 314/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -1967.7501 - accuracy: 0.6055 - val_loss: -1275.3900 - val_accuracy: 0.5584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -1975.1128 - accuracy: 0.6006 - val_loss: -1286.0745 - val_accuracy: 0.5585\n",
      "Epoch 316/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -1979.4606 - accuracy: 0.5999 - val_loss: -1287.6245 - val_accuracy: 0.5581\n",
      "Epoch 317/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -1984.4485 - accuracy: 0.6003 - val_loss: -1297.4895 - val_accuracy: 0.5567\n",
      "Epoch 318/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -1991.1660 - accuracy: 0.6001 - val_loss: -1291.0461 - val_accuracy: 0.5580\n",
      "Epoch 319/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -1997.1108 - accuracy: 0.6008 - val_loss: -1295.9799 - val_accuracy: 0.5594\n",
      "Epoch 320/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -2007.9834 - accuracy: 0.6015 - val_loss: -1291.6615 - val_accuracy: 0.5591\n",
      "Epoch 321/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -2010.3597 - accuracy: 0.5996 - val_loss: -1298.6459 - val_accuracy: 0.5599\n",
      "Epoch 322/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2022.0911 - accuracy: 0.6053 - val_loss: -1296.6996 - val_accuracy: 0.5600\n",
      "Epoch 323/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -2025.6105 - accuracy: 0.6046 - val_loss: -1316.2775 - val_accuracy: 0.5614\n",
      "Epoch 324/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2033.9237 - accuracy: 0.6049 - val_loss: -1315.7007 - val_accuracy: 0.5615\n",
      "Epoch 325/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -2037.8314 - accuracy: 0.6040 - val_loss: -1322.6976 - val_accuracy: 0.5607\n",
      "Epoch 326/1000\n",
      "710/710 [==============================] - 113s 160ms/step - loss: -2037.7732 - accuracy: 0.6037 - val_loss: -1320.3807 - val_accuracy: 0.5587\n",
      "Epoch 327/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2046.5861 - accuracy: 0.6039 - val_loss: -1325.2639 - val_accuracy: 0.5606\n",
      "Epoch 328/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -2055.8154 - accuracy: 0.6041 - val_loss: -1329.6122 - val_accuracy: 0.5606\n",
      "Epoch 329/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -2064.5376 - accuracy: 0.6053 - val_loss: -1341.4617 - val_accuracy: 0.5614\n",
      "Epoch 330/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -2069.7729 - accuracy: 0.6052 - val_loss: -1344.9327 - val_accuracy: 0.5626\n",
      "Epoch 331/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -2078.7200 - accuracy: 0.6052 - val_loss: -1345.9929 - val_accuracy: 0.5609\n",
      "Epoch 332/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2081.9543 - accuracy: 0.6054 - val_loss: -1353.3837 - val_accuracy: 0.5619\n",
      "Epoch 333/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2086.8806 - accuracy: 0.6038 - val_loss: -1357.6908 - val_accuracy: 0.5613\n",
      "Epoch 334/1000\n",
      "710/710 [==============================] - 849s 1s/step - loss: -2096.4053 - accuracy: 0.6025 - val_loss: -1361.5756 - val_accuracy: 0.5606\n",
      "Epoch 335/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -2098.3418 - accuracy: 0.6009 - val_loss: -1363.8562 - val_accuracy: 0.5609\n",
      "Epoch 336/1000\n",
      "710/710 [==============================] - 113s 160ms/step - loss: -2106.4104 - accuracy: 0.6051 - val_loss: -1359.8463 - val_accuracy: 0.5603\n",
      "Epoch 337/1000\n",
      "710/710 [==============================] - 107s 150ms/step - loss: -2107.7947 - accuracy: 0.6035 - val_loss: -1360.7722 - val_accuracy: 0.5613\n",
      "Epoch 338/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -2119.0608 - accuracy: 0.6055 - val_loss: -1381.4391 - val_accuracy: 0.5612\n",
      "Epoch 339/1000\n",
      "710/710 [==============================] - 107s 150ms/step - loss: -2123.8044 - accuracy: 0.6004 - val_loss: -1378.1093 - val_accuracy: 0.5592\n",
      "Epoch 340/1000\n",
      "710/710 [==============================] - 107s 150ms/step - loss: -2126.4636 - accuracy: 0.6029 - val_loss: -1380.1381 - val_accuracy: 0.5585\n",
      "Epoch 341/1000\n",
      "710/710 [==============================] - 106s 150ms/step - loss: -2143.1277 - accuracy: 0.6037 - val_loss: -1379.1665 - val_accuracy: 0.5573\n",
      "Epoch 342/1000\n",
      "710/710 [==============================] - 44s 62ms/step - loss: -2141.2456 - accuracy: 0.6036 - val_loss: -1387.9202 - val_accuracy: 0.5610\n",
      "Epoch 343/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -2151.8911 - accuracy: 0.6048 - val_loss: -1387.5365 - val_accuracy: 0.5593\n",
      "Epoch 344/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -2160.0010 - accuracy: 0.6043 - val_loss: -1393.8475 - val_accuracy: 0.5595\n",
      "Epoch 345/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -2159.2483 - accuracy: 0.6018 - val_loss: -1396.1274 - val_accuracy: 0.5597\n",
      "Epoch 346/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -2169.7690 - accuracy: 0.6031 - val_loss: -1403.5475 - val_accuracy: 0.5580\n",
      "Epoch 347/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -2177.1838 - accuracy: 0.6041 - val_loss: -1407.4106 - val_accuracy: 0.5595\n",
      "Epoch 348/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -2181.6184 - accuracy: 0.6054 - val_loss: -1417.9823 - val_accuracy: 0.5624\n",
      "Epoch 349/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -2191.7175 - accuracy: 0.6048 - val_loss: -1420.1256 - val_accuracy: 0.5587\n",
      "Epoch 350/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2193.8811 - accuracy: 0.6057 - val_loss: -1419.1930 - val_accuracy: 0.5587\n",
      "Epoch 351/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -2205.7380 - accuracy: 0.6047 - val_loss: -1420.3035 - val_accuracy: 0.5607\n",
      "Epoch 352/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2206.1135 - accuracy: 0.6047 - val_loss: -1434.6738 - val_accuracy: 0.5615\n",
      "Epoch 353/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2216.3062 - accuracy: 0.6034 - val_loss: -1434.8611 - val_accuracy: 0.5613\n",
      "Epoch 354/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2219.6912 - accuracy: 0.6091 - val_loss: -1434.0839 - val_accuracy: 0.5607\n",
      "Epoch 355/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -2223.9402 - accuracy: 0.6060 - val_loss: -1438.0140 - val_accuracy: 0.5591\n",
      "Epoch 356/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2233.1111 - accuracy: 0.6000 - val_loss: -1440.1575 - val_accuracy: 0.5587\n",
      "Epoch 357/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -2238.2803 - accuracy: 0.6055 - val_loss: -1446.0100 - val_accuracy: 0.5598\n",
      "Epoch 358/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2244.5654 - accuracy: 0.6063 - val_loss: -1446.2349 - val_accuracy: 0.5571\n",
      "Epoch 359/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -2255.6179 - accuracy: 0.6074 - val_loss: -1453.5239 - val_accuracy: 0.5598\n",
      "Epoch 360/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2263.1743 - accuracy: 0.6031 - val_loss: -1460.1888 - val_accuracy: 0.5591\n",
      "Epoch 361/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2263.0161 - accuracy: 0.6058 - val_loss: -1473.0488 - val_accuracy: 0.5577\n",
      "Epoch 362/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2266.6284 - accuracy: 0.6032 - val_loss: -1470.1224 - val_accuracy: 0.5589\n",
      "Epoch 363/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -2279.4878 - accuracy: 0.6022 - val_loss: -1479.1234 - val_accuracy: 0.5582\n",
      "Epoch 364/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2283.0540 - accuracy: 0.6034 - val_loss: -1483.4210 - val_accuracy: 0.5603\n",
      "Epoch 365/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2288.2087 - accuracy: 0.6041 - val_loss: -1485.0927 - val_accuracy: 0.5596\n",
      "Epoch 366/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2296.7588 - accuracy: 0.6073 - val_loss: -1483.0543 - val_accuracy: 0.5577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -2302.4326 - accuracy: 0.6048 - val_loss: -1487.1918 - val_accuracy: 0.5599\n",
      "Epoch 368/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -2307.0525 - accuracy: 0.6039 - val_loss: -1486.2803 - val_accuracy: 0.5568\n",
      "Epoch 369/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -2318.2512 - accuracy: 0.6074 - val_loss: -1497.0529 - val_accuracy: 0.5599\n",
      "Epoch 370/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -2320.6418 - accuracy: 0.6036 - val_loss: -1514.1348 - val_accuracy: 0.5566\n",
      "Epoch 371/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -2325.7590 - accuracy: 0.6046 - val_loss: -1510.5062 - val_accuracy: 0.5594\n",
      "Epoch 372/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -2330.7061 - accuracy: 0.6077 - val_loss: -1519.5747 - val_accuracy: 0.5596\n",
      "Epoch 373/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2339.8020 - accuracy: 0.6058 - val_loss: -1530.1300 - val_accuracy: 0.5592\n",
      "Epoch 374/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -2348.7668 - accuracy: 0.6036 - val_loss: -1534.4620 - val_accuracy: 0.5609\n",
      "Epoch 375/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2357.0725 - accuracy: 0.6061 - val_loss: -1527.2021 - val_accuracy: 0.5578\n",
      "Epoch 376/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -2364.5898 - accuracy: 0.6033 - val_loss: -1529.2673 - val_accuracy: 0.5581\n",
      "Epoch 377/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -2367.0798 - accuracy: 0.6042 - val_loss: -1535.6852 - val_accuracy: 0.5594\n",
      "Epoch 378/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2370.2554 - accuracy: 0.6029 - val_loss: -1543.0482 - val_accuracy: 0.5596\n",
      "Epoch 379/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2378.6650 - accuracy: 0.6034 - val_loss: -1552.4459 - val_accuracy: 0.5590\n",
      "Epoch 380/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2385.6165 - accuracy: 0.6076 - val_loss: -1543.9730 - val_accuracy: 0.5612\n",
      "Epoch 381/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -2393.5701 - accuracy: 0.6047 - val_loss: -1556.9109 - val_accuracy: 0.5589\n",
      "Epoch 382/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -2397.9731 - accuracy: 0.6045 - val_loss: -1552.4067 - val_accuracy: 0.5582\n",
      "Epoch 383/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -2400.6101 - accuracy: 0.6032 - val_loss: -1563.3658 - val_accuracy: 0.5602\n",
      "Epoch 384/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -2413.8335 - accuracy: 0.6047 - val_loss: -1556.2710 - val_accuracy: 0.5627\n",
      "Epoch 385/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -2418.6431 - accuracy: 0.6060 - val_loss: -1573.2927 - val_accuracy: 0.5592\n",
      "Epoch 386/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -2423.4546 - accuracy: 0.6056 - val_loss: -1574.5044 - val_accuracy: 0.5593\n",
      "Epoch 387/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -2428.0444 - accuracy: 0.6026 - val_loss: -1579.9692 - val_accuracy: 0.5608\n",
      "Epoch 388/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2436.1726 - accuracy: 0.6039 - val_loss: -1581.8252 - val_accuracy: 0.5575\n",
      "Epoch 389/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -2443.1099 - accuracy: 0.6005 - val_loss: -1589.7218 - val_accuracy: 0.5595\n",
      "Epoch 390/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2450.4888 - accuracy: 0.6046 - val_loss: -1586.0765 - val_accuracy: 0.5605\n",
      "Epoch 391/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -2457.8538 - accuracy: 0.6067 - val_loss: -1603.2053 - val_accuracy: 0.5613\n",
      "Epoch 392/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -2456.5847 - accuracy: 0.6047 - val_loss: -1597.3535 - val_accuracy: 0.5590\n",
      "Epoch 393/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2474.8877 - accuracy: 0.6020 - val_loss: -1599.6504 - val_accuracy: 0.5584\n",
      "Epoch 394/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -2479.3525 - accuracy: 0.6014 - val_loss: -1594.5485 - val_accuracy: 0.5597\n",
      "Epoch 395/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -2484.4666 - accuracy: 0.6057 - val_loss: -1614.5934 - val_accuracy: 0.5603\n",
      "Epoch 396/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -2486.7280 - accuracy: 0.6054 - val_loss: -1628.4816 - val_accuracy: 0.5611\n",
      "Epoch 397/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -2490.3247 - accuracy: 0.6038 - val_loss: -1613.0460 - val_accuracy: 0.5583\n",
      "Epoch 398/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2496.2656 - accuracy: 0.6022 - val_loss: -1610.6001 - val_accuracy: 0.5588\n",
      "Epoch 399/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -2502.0247 - accuracy: 0.6051 - val_loss: -1622.2522 - val_accuracy: 0.5615\n",
      "Epoch 400/1000\n",
      "710/710 [==============================] - 117s 164ms/step - loss: -2512.0244 - accuracy: 0.6041 - val_loss: -1625.7035 - val_accuracy: 0.5612\n",
      "Epoch 401/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2522.3372 - accuracy: 0.6046 - val_loss: -1620.3439 - val_accuracy: 0.5601\n",
      "Epoch 402/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2524.2087 - accuracy: 0.6063 - val_loss: -1633.9971 - val_accuracy: 0.5580\n",
      "Epoch 403/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2536.8284 - accuracy: 0.6047 - val_loss: -1633.0692 - val_accuracy: 0.5597\n",
      "Epoch 404/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2539.5764 - accuracy: 0.6040 - val_loss: -1633.3267 - val_accuracy: 0.5592\n",
      "Epoch 405/1000\n",
      "710/710 [==============================] - 115s 163ms/step - loss: -2547.5962 - accuracy: 0.6058 - val_loss: -1646.1207 - val_accuracy: 0.5610\n",
      "Epoch 406/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -2548.1387 - accuracy: 0.6067 - val_loss: -1647.4171 - val_accuracy: 0.5587\n",
      "Epoch 407/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -2557.2483 - accuracy: 0.6045 - val_loss: -1647.1187 - val_accuracy: 0.5600\n",
      "Epoch 408/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -2561.1992 - accuracy: 0.6080 - val_loss: -1661.1058 - val_accuracy: 0.5601\n",
      "Epoch 409/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -2569.9041 - accuracy: 0.6047 - val_loss: -1655.2917 - val_accuracy: 0.5586\n",
      "Epoch 410/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -2575.3845 - accuracy: 0.6039 - val_loss: -1663.3530 - val_accuracy: 0.5576\n",
      "Epoch 411/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2582.2493 - accuracy: 0.6024 - val_loss: -1664.1559 - val_accuracy: 0.5591\n",
      "Epoch 412/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2586.5254 - accuracy: 0.6060 - val_loss: -1664.3473 - val_accuracy: 0.5581\n",
      "Epoch 413/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -2599.1858 - accuracy: 0.6041 - val_loss: -1675.1942 - val_accuracy: 0.5582\n",
      "Epoch 414/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2602.2007 - accuracy: 0.6064 - val_loss: -1674.1556 - val_accuracy: 0.5560\n",
      "Epoch 415/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2606.2954 - accuracy: 0.6063 - val_loss: -1685.1273 - val_accuracy: 0.5591\n",
      "Epoch 416/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -2615.7542 - accuracy: 0.6065 - val_loss: -1689.7671 - val_accuracy: 0.5611\n",
      "Epoch 417/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -2621.7166 - accuracy: 0.6068 - val_loss: -1700.2024 - val_accuracy: 0.5601\n",
      "Epoch 418/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -2635.5818 - accuracy: 0.6038 - val_loss: -1704.8622 - val_accuracy: 0.5604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -2630.4692 - accuracy: 0.6035 - val_loss: -1710.5110 - val_accuracy: 0.5575\n",
      "Epoch 420/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -2641.3293 - accuracy: 0.6027 - val_loss: -1702.8717 - val_accuracy: 0.5580\n",
      "Epoch 421/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -2643.1189 - accuracy: 0.6022 - val_loss: -1711.5839 - val_accuracy: 0.5573\n",
      "Epoch 422/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2654.0408 - accuracy: 0.6034 - val_loss: -1715.2734 - val_accuracy: 0.5598\n",
      "Epoch 423/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -2657.8069 - accuracy: 0.6075 - val_loss: -1709.8220 - val_accuracy: 0.5591\n",
      "Epoch 424/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -2672.3865 - accuracy: 0.6057 - val_loss: -1714.8226 - val_accuracy: 0.5594\n",
      "Epoch 425/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2673.2371 - accuracy: 0.6066 - val_loss: -1728.5667 - val_accuracy: 0.5594\n",
      "Epoch 426/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -2677.9441 - accuracy: 0.6043 - val_loss: -1734.1614 - val_accuracy: 0.5602\n",
      "Epoch 427/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -2681.4397 - accuracy: 0.6050 - val_loss: -1736.1691 - val_accuracy: 0.5594\n",
      "Epoch 428/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2695.4629 - accuracy: 0.6039 - val_loss: -1739.1399 - val_accuracy: 0.5579\n",
      "Epoch 429/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -2695.4314 - accuracy: 0.6042 - val_loss: -1744.3341 - val_accuracy: 0.5593\n",
      "Epoch 430/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -2696.5229 - accuracy: 0.6022 - val_loss: -1746.9260 - val_accuracy: 0.5601\n",
      "Epoch 431/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -2706.7480 - accuracy: 0.6062 - val_loss: -1747.6853 - val_accuracy: 0.5592\n",
      "Epoch 432/1000\n",
      "710/710 [==============================] - 117s 164ms/step - loss: -2714.2761 - accuracy: 0.6041 - val_loss: -1752.0264 - val_accuracy: 0.5588\n",
      "Epoch 433/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -2718.5986 - accuracy: 0.6031 - val_loss: -1762.9794 - val_accuracy: 0.5594\n",
      "Epoch 434/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2729.1816 - accuracy: 0.6046 - val_loss: -1767.7596 - val_accuracy: 0.5596\n",
      "Epoch 435/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2737.1670 - accuracy: 0.6062 - val_loss: -1778.1790 - val_accuracy: 0.5594\n",
      "Epoch 436/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -2737.5713 - accuracy: 0.6053 - val_loss: -1775.7517 - val_accuracy: 0.5583\n",
      "Epoch 437/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -2747.4255 - accuracy: 0.6040 - val_loss: -1772.7406 - val_accuracy: 0.5555\n",
      "Epoch 438/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2753.1440 - accuracy: 0.6054 - val_loss: -1792.1171 - val_accuracy: 0.5568\n",
      "Epoch 439/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2761.6938 - accuracy: 0.6052 - val_loss: -1778.9805 - val_accuracy: 0.5586\n",
      "Epoch 440/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -2767.0068 - accuracy: 0.6086 - val_loss: -1787.7007 - val_accuracy: 0.5571\n",
      "Epoch 441/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2779.0500 - accuracy: 0.6054 - val_loss: -1791.7589 - val_accuracy: 0.5572\n",
      "Epoch 442/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2777.3777 - accuracy: 0.6062 - val_loss: -1794.7087 - val_accuracy: 0.5577\n",
      "Epoch 443/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -2780.0166 - accuracy: 0.6054 - val_loss: -1796.1565 - val_accuracy: 0.5576\n",
      "Epoch 444/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2787.0417 - accuracy: 0.6073 - val_loss: -1789.1323 - val_accuracy: 0.5594\n",
      "Epoch 445/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -2794.7959 - accuracy: 0.6015 - val_loss: -1794.8533 - val_accuracy: 0.5568\n",
      "Epoch 446/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -2803.0330 - accuracy: 0.6056 - val_loss: -1809.3643 - val_accuracy: 0.5589\n",
      "Epoch 447/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2812.3870 - accuracy: 0.6068 - val_loss: -1814.0634 - val_accuracy: 0.5569\n",
      "Epoch 448/1000\n",
      "710/710 [==============================] - 118s 167ms/step - loss: -2815.3909 - accuracy: 0.6043 - val_loss: -1809.0138 - val_accuracy: 0.5563\n",
      "Epoch 449/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -2827.4419 - accuracy: 0.6082 - val_loss: -1802.7855 - val_accuracy: 0.5582\n",
      "Epoch 450/1000\n",
      "710/710 [==============================] - 118s 167ms/step - loss: -2830.6316 - accuracy: 0.6063 - val_loss: -1807.7721 - val_accuracy: 0.5564\n",
      "Epoch 451/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2841.1125 - accuracy: 0.6079 - val_loss: -1836.4620 - val_accuracy: 0.5576\n",
      "Epoch 452/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -2847.4272 - accuracy: 0.6072 - val_loss: -1837.1614 - val_accuracy: 0.5573\n",
      "Epoch 453/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -2845.4658 - accuracy: 0.6050 - val_loss: -1837.0515 - val_accuracy: 0.5576\n",
      "Epoch 454/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -2855.0676 - accuracy: 0.6060 - val_loss: -1846.5128 - val_accuracy: 0.5573\n",
      "Epoch 455/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2865.8076 - accuracy: 0.6023 - val_loss: -1844.5739 - val_accuracy: 0.5576\n",
      "Epoch 456/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -2871.2029 - accuracy: 0.6016 - val_loss: -1857.8561 - val_accuracy: 0.5584\n",
      "Epoch 457/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -2874.7314 - accuracy: 0.6056 - val_loss: -1854.8383 - val_accuracy: 0.5578\n",
      "Epoch 458/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -2876.0142 - accuracy: 0.6044 - val_loss: -1857.8828 - val_accuracy: 0.5561\n",
      "Epoch 459/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2896.2891 - accuracy: 0.6057 - val_loss: -1854.5106 - val_accuracy: 0.5547\n",
      "Epoch 460/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -2882.3459 - accuracy: 0.6031 - val_loss: -1867.8795 - val_accuracy: 0.5580\n",
      "Epoch 461/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2903.1975 - accuracy: 0.6083 - val_loss: -1874.5480 - val_accuracy: 0.5571\n",
      "Epoch 462/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -2899.3738 - accuracy: 0.6066 - val_loss: -1871.4596 - val_accuracy: 0.5591\n",
      "Epoch 463/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -2908.1550 - accuracy: 0.6010 - val_loss: -1872.0350 - val_accuracy: 0.5571\n",
      "Epoch 464/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -2924.3474 - accuracy: 0.6062 - val_loss: -1871.3414 - val_accuracy: 0.5562\n",
      "Epoch 465/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -2928.0886 - accuracy: 0.6082 - val_loss: -1902.7949 - val_accuracy: 0.5609\n",
      "Epoch 466/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -2930.4607 - accuracy: 0.6072 - val_loss: -1910.8737 - val_accuracy: 0.5582\n",
      "Epoch 467/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -2940.3928 - accuracy: 0.6052 - val_loss: -1905.1985 - val_accuracy: 0.5588\n",
      "Epoch 468/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -2950.4290 - accuracy: 0.6064 - val_loss: -1908.5571 - val_accuracy: 0.5584\n",
      "Epoch 469/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -2946.7747 - accuracy: 0.6097 - val_loss: -1910.0957 - val_accuracy: 0.5589\n",
      "Epoch 470/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -2953.9312 - accuracy: 0.6071 - val_loss: -1919.2408 - val_accuracy: 0.5581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -2969.9978 - accuracy: 0.6032 - val_loss: -1923.5452 - val_accuracy: 0.5583\n",
      "Epoch 472/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -2971.9365 - accuracy: 0.6078 - val_loss: -1929.4824 - val_accuracy: 0.5578\n",
      "Epoch 473/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -2975.7451 - accuracy: 0.6080 - val_loss: -1938.2310 - val_accuracy: 0.5617\n",
      "Epoch 474/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -2977.9121 - accuracy: 0.6070 - val_loss: -1932.7153 - val_accuracy: 0.5584\n",
      "Epoch 475/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -2988.3110 - accuracy: 0.6057 - val_loss: -1930.2667 - val_accuracy: 0.5589\n",
      "Epoch 476/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3000.2793 - accuracy: 0.6081 - val_loss: -1941.4385 - val_accuracy: 0.5576\n",
      "Epoch 477/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -3000.9128 - accuracy: 0.6095 - val_loss: -1937.3860 - val_accuracy: 0.5597\n",
      "Epoch 478/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3003.7126 - accuracy: 0.6063 - val_loss: -1943.8899 - val_accuracy: 0.5605\n",
      "Epoch 479/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3016.0549 - accuracy: 0.6065 - val_loss: -1940.6628 - val_accuracy: 0.5597\n",
      "Epoch 480/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -3021.2207 - accuracy: 0.6061 - val_loss: -1953.9028 - val_accuracy: 0.5596\n",
      "Epoch 481/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -3030.3018 - accuracy: 0.6038 - val_loss: -1965.2799 - val_accuracy: 0.5594\n",
      "Epoch 482/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3034.6099 - accuracy: 0.6041 - val_loss: -1979.4976 - val_accuracy: 0.5587\n",
      "Epoch 483/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -3038.6282 - accuracy: 0.6032 - val_loss: -1965.6135 - val_accuracy: 0.5607\n",
      "Epoch 484/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -3046.9419 - accuracy: 0.6059 - val_loss: -1956.1525 - val_accuracy: 0.5605\n",
      "Epoch 485/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3057.4246 - accuracy: 0.6062 - val_loss: -1982.1471 - val_accuracy: 0.5607\n",
      "Epoch 486/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3065.4124 - accuracy: 0.6054 - val_loss: -1978.7189 - val_accuracy: 0.5607\n",
      "Epoch 487/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3068.8225 - accuracy: 0.6028 - val_loss: -1978.0288 - val_accuracy: 0.5602\n",
      "Epoch 488/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -3071.8335 - accuracy: 0.6076 - val_loss: -1980.6700 - val_accuracy: 0.5599\n",
      "Epoch 489/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3080.7415 - accuracy: 0.6096 - val_loss: -1979.0343 - val_accuracy: 0.5605\n",
      "Epoch 490/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3089.4363 - accuracy: 0.6035 - val_loss: -1972.3518 - val_accuracy: 0.5600\n",
      "Epoch 491/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3088.2524 - accuracy: 0.6064 - val_loss: -1985.1814 - val_accuracy: 0.5596\n",
      "Epoch 492/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3098.1875 - accuracy: 0.6057 - val_loss: -2001.9635 - val_accuracy: 0.5606\n",
      "Epoch 493/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -3103.5457 - accuracy: 0.6061 - val_loss: -2006.3141 - val_accuracy: 0.5593\n",
      "Epoch 494/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -3105.9526 - accuracy: 0.6076 - val_loss: -2005.9919 - val_accuracy: 0.5590\n",
      "Epoch 495/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -3113.0623 - accuracy: 0.6051 - val_loss: -1995.1968 - val_accuracy: 0.5567\n",
      "Epoch 496/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -3118.4148 - accuracy: 0.6079 - val_loss: -2017.1862 - val_accuracy: 0.5607\n",
      "Epoch 497/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3133.6704 - accuracy: 0.6062 - val_loss: -2015.0153 - val_accuracy: 0.5585\n",
      "Epoch 498/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -3126.9014 - accuracy: 0.6052 - val_loss: -2024.7129 - val_accuracy: 0.5594\n",
      "Epoch 499/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -3139.1130 - accuracy: 0.6058 - val_loss: -2028.3005 - val_accuracy: 0.5565\n",
      "Epoch 500/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -3144.2419 - accuracy: 0.6044 - val_loss: -2038.4004 - val_accuracy: 0.5560\n",
      "Epoch 501/1000\n",
      "710/710 [==============================] - 125s 177ms/step - loss: -3152.0212 - accuracy: 0.6022 - val_loss: -2035.6013 - val_accuracy: 0.5569\n",
      "Epoch 502/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -3160.2258 - accuracy: 0.6041 - val_loss: -2034.1534 - val_accuracy: 0.5576\n",
      "Epoch 503/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3169.4871 - accuracy: 0.6033 - val_loss: -2049.3167 - val_accuracy: 0.5595\n",
      "Epoch 504/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -3177.7942 - accuracy: 0.6071 - val_loss: -2037.2288 - val_accuracy: 0.5602\n",
      "Epoch 505/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -3179.2773 - accuracy: 0.6067 - val_loss: -2037.6949 - val_accuracy: 0.5620\n",
      "Epoch 506/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -3184.2427 - accuracy: 0.6071 - val_loss: -2061.7837 - val_accuracy: 0.5628\n",
      "Epoch 507/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3197.5264 - accuracy: 0.6054 - val_loss: -2067.8760 - val_accuracy: 0.5619\n",
      "Epoch 508/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -3205.2444 - accuracy: 0.6080 - val_loss: -2071.6780 - val_accuracy: 0.5613\n",
      "Epoch 509/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -3212.1470 - accuracy: 0.6075 - val_loss: -2060.3953 - val_accuracy: 0.5602\n",
      "Epoch 510/1000\n",
      "710/710 [==============================] - 120s 168ms/step - loss: -3214.9067 - accuracy: 0.6051 - val_loss: -2060.7524 - val_accuracy: 0.5608\n",
      "Epoch 511/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3222.9800 - accuracy: 0.6083 - val_loss: -2075.1709 - val_accuracy: 0.5603\n",
      "Epoch 512/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -3223.7520 - accuracy: 0.6074 - val_loss: -2083.9983 - val_accuracy: 0.5603\n",
      "Epoch 513/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3230.9817 - accuracy: 0.6056 - val_loss: -2088.1948 - val_accuracy: 0.5597\n",
      "Epoch 514/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3241.6780 - accuracy: 0.6073 - val_loss: -2104.3572 - val_accuracy: 0.5601\n",
      "Epoch 515/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3253.4902 - accuracy: 0.6038 - val_loss: -2093.2788 - val_accuracy: 0.5587\n",
      "Epoch 516/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3251.0310 - accuracy: 0.6067 - val_loss: -2092.6326 - val_accuracy: 0.5591\n",
      "Epoch 517/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -3263.6667 - accuracy: 0.6065 - val_loss: -2117.3657 - val_accuracy: 0.5602\n",
      "Epoch 518/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -3268.2449 - accuracy: 0.6028 - val_loss: -2107.8682 - val_accuracy: 0.5601\n",
      "Epoch 519/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3274.9949 - accuracy: 0.6055 - val_loss: -2120.7083 - val_accuracy: 0.5600\n",
      "Epoch 520/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -3286.2405 - accuracy: 0.6063 - val_loss: -2116.8408 - val_accuracy: 0.5587\n",
      "Epoch 521/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -3280.1702 - accuracy: 0.6081 - val_loss: -2108.1685 - val_accuracy: 0.5566\n",
      "Epoch 522/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -3295.2061 - accuracy: 0.6050 - val_loss: -2102.6948 - val_accuracy: 0.5572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -3294.3801 - accuracy: 0.6036 - val_loss: -2124.5356 - val_accuracy: 0.5580\n",
      "Epoch 524/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -3292.5452 - accuracy: 0.6052 - val_loss: -2138.3545 - val_accuracy: 0.5600\n",
      "Epoch 525/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -3308.1184 - accuracy: 0.6048 - val_loss: -2119.7488 - val_accuracy: 0.5583\n",
      "Epoch 526/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3323.5593 - accuracy: 0.6057 - val_loss: -2142.3242 - val_accuracy: 0.5599\n",
      "Epoch 527/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -3315.2703 - accuracy: 0.6046 - val_loss: -2144.0601 - val_accuracy: 0.5586\n",
      "Epoch 528/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -3324.8306 - accuracy: 0.6069 - val_loss: -2155.1826 - val_accuracy: 0.5596\n",
      "Epoch 529/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3329.3386 - accuracy: 0.6076 - val_loss: -2146.2566 - val_accuracy: 0.5580\n",
      "Epoch 530/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -3337.2786 - accuracy: 0.6072 - val_loss: -2151.1609 - val_accuracy: 0.5578\n",
      "Epoch 531/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -3348.3169 - accuracy: 0.6048 - val_loss: -2152.8362 - val_accuracy: 0.5581\n",
      "Epoch 532/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3344.5164 - accuracy: 0.6053 - val_loss: -2162.7461 - val_accuracy: 0.5598\n",
      "Epoch 533/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -3361.6086 - accuracy: 0.6053 - val_loss: -2154.0354 - val_accuracy: 0.5582\n",
      "Epoch 534/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3366.6321 - accuracy: 0.6055 - val_loss: -2164.4507 - val_accuracy: 0.5596\n",
      "Epoch 535/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -3365.9131 - accuracy: 0.6029 - val_loss: -2169.1907 - val_accuracy: 0.5599\n",
      "Epoch 536/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -3379.6465 - accuracy: 0.6070 - val_loss: -2174.1970 - val_accuracy: 0.5584\n",
      "Epoch 537/1000\n",
      "710/710 [==============================] - 118s 167ms/step - loss: -3387.9863 - accuracy: 0.6044 - val_loss: -2191.7009 - val_accuracy: 0.5583\n",
      "Epoch 538/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -3390.1802 - accuracy: 0.6091 - val_loss: -2197.8960 - val_accuracy: 0.5569\n",
      "Epoch 539/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3396.2651 - accuracy: 0.6069 - val_loss: -2210.8862 - val_accuracy: 0.5571\n",
      "Epoch 540/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -3408.1177 - accuracy: 0.6081 - val_loss: -2217.2302 - val_accuracy: 0.5576\n",
      "Epoch 541/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -3407.9119 - accuracy: 0.6069 - val_loss: -2204.5398 - val_accuracy: 0.5591\n",
      "Epoch 542/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3418.6736 - accuracy: 0.6064 - val_loss: -2211.6858 - val_accuracy: 0.5586\n",
      "Epoch 543/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3420.5442 - accuracy: 0.6077 - val_loss: -2214.1111 - val_accuracy: 0.5576\n",
      "Epoch 544/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3426.8708 - accuracy: 0.6033 - val_loss: -2210.5454 - val_accuracy: 0.5575\n",
      "Epoch 545/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -3440.2998 - accuracy: 0.6072 - val_loss: -2210.8826 - val_accuracy: 0.5559\n",
      "Epoch 546/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3441.1055 - accuracy: 0.6057 - val_loss: -2211.6768 - val_accuracy: 0.5578\n",
      "Epoch 547/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -3446.9170 - accuracy: 0.6062 - val_loss: -2223.3237 - val_accuracy: 0.5558\n",
      "Epoch 548/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3454.1016 - accuracy: 0.6046 - val_loss: -2240.2202 - val_accuracy: 0.5555\n",
      "Epoch 549/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3456.0022 - accuracy: 0.6040 - val_loss: -2225.1858 - val_accuracy: 0.5579\n",
      "Epoch 550/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -3465.1018 - accuracy: 0.6031 - val_loss: -2219.7224 - val_accuracy: 0.5569\n",
      "Epoch 551/1000\n",
      "710/710 [==============================] - 118s 167ms/step - loss: -3470.3984 - accuracy: 0.6047 - val_loss: -2215.8611 - val_accuracy: 0.5585\n",
      "Epoch 552/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3481.9199 - accuracy: 0.6057 - val_loss: -2230.7712 - val_accuracy: 0.5585\n",
      "Epoch 553/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3480.0017 - accuracy: 0.6053 - val_loss: -2236.9463 - val_accuracy: 0.5572\n",
      "Epoch 554/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -3489.7185 - accuracy: 0.6099 - val_loss: -2248.4097 - val_accuracy: 0.5585\n",
      "Epoch 555/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -3510.0547 - accuracy: 0.6073 - val_loss: -2242.6252 - val_accuracy: 0.5567\n",
      "Epoch 556/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3507.1238 - accuracy: 0.6079 - val_loss: -2246.0444 - val_accuracy: 0.5573\n",
      "Epoch 557/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3516.7896 - accuracy: 0.6054 - val_loss: -2258.9949 - val_accuracy: 0.5562\n",
      "Epoch 558/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -3512.4670 - accuracy: 0.6035 - val_loss: -2260.9585 - val_accuracy: 0.5553\n",
      "Epoch 559/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -3521.0447 - accuracy: 0.6022 - val_loss: -2244.9756 - val_accuracy: 0.5564\n",
      "Epoch 560/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -3530.1152 - accuracy: 0.6045 - val_loss: -2276.2402 - val_accuracy: 0.5578\n",
      "Epoch 561/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -3540.7244 - accuracy: 0.6068 - val_loss: -2276.2366 - val_accuracy: 0.5579\n",
      "Epoch 562/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -3547.0454 - accuracy: 0.6088 - val_loss: -2271.5745 - val_accuracy: 0.5562\n",
      "Epoch 563/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -3548.6892 - accuracy: 0.6057 - val_loss: -2266.8186 - val_accuracy: 0.5571\n",
      "Epoch 564/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3553.4968 - accuracy: 0.6099 - val_loss: -2278.2622 - val_accuracy: 0.5558\n",
      "Epoch 565/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -3555.2861 - accuracy: 0.6097 - val_loss: -2301.7512 - val_accuracy: 0.5573\n",
      "Epoch 566/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3568.1306 - accuracy: 0.6069 - val_loss: -2298.4055 - val_accuracy: 0.5581\n",
      "Epoch 567/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -3563.6147 - accuracy: 0.6097 - val_loss: -2294.3494 - val_accuracy: 0.5587\n",
      "Epoch 568/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3586.5159 - accuracy: 0.6046 - val_loss: -2283.9636 - val_accuracy: 0.5590\n",
      "Epoch 569/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3583.2202 - accuracy: 0.6058 - val_loss: -2296.2742 - val_accuracy: 0.5580\n",
      "Epoch 570/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -3590.9719 - accuracy: 0.6083 - val_loss: -2315.7671 - val_accuracy: 0.5579\n",
      "Epoch 571/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3601.1282 - accuracy: 0.6053 - val_loss: -2321.5378 - val_accuracy: 0.5575\n",
      "Epoch 572/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3606.5447 - accuracy: 0.6034 - val_loss: -2323.8281 - val_accuracy: 0.5566\n",
      "Epoch 573/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -3611.6692 - accuracy: 0.6040 - val_loss: -2321.4111 - val_accuracy: 0.5577\n",
      "Epoch 574/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -3618.4412 - accuracy: 0.6057 - val_loss: -2326.4138 - val_accuracy: 0.5591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 575/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3623.9736 - accuracy: 0.6124 - val_loss: -2325.8540 - val_accuracy: 0.5576\n",
      "Epoch 576/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -3633.6211 - accuracy: 0.6071 - val_loss: -2323.4421 - val_accuracy: 0.5568\n",
      "Epoch 577/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -3623.5168 - accuracy: 0.6055 - val_loss: -2335.2922 - val_accuracy: 0.5548\n",
      "Epoch 578/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3641.3545 - accuracy: 0.6034 - val_loss: -2324.3206 - val_accuracy: 0.5554\n",
      "Epoch 579/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3642.1541 - accuracy: 0.6058 - val_loss: -2317.7908 - val_accuracy: 0.5540\n",
      "Epoch 580/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -3657.8125 - accuracy: 0.6046 - val_loss: -2344.5652 - val_accuracy: 0.5571\n",
      "Epoch 581/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -3657.2947 - accuracy: 0.6132 - val_loss: -2340.7524 - val_accuracy: 0.5563\n",
      "Epoch 582/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -3666.1318 - accuracy: 0.6082 - val_loss: -2357.3564 - val_accuracy: 0.5564\n",
      "Epoch 583/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -3673.0574 - accuracy: 0.6047 - val_loss: -2364.7698 - val_accuracy: 0.5578\n",
      "Epoch 584/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -3686.6489 - accuracy: 0.6117 - val_loss: -2357.0815 - val_accuracy: 0.5579\n",
      "Epoch 585/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -3680.4893 - accuracy: 0.6104 - val_loss: -2367.5823 - val_accuracy: 0.5564\n",
      "Epoch 586/1000\n",
      "710/710 [==============================] - 113s 160ms/step - loss: -3698.3186 - accuracy: 0.6081 - val_loss: -2376.0962 - val_accuracy: 0.5567\n",
      "Epoch 587/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -3692.9373 - accuracy: 0.6074 - val_loss: -2383.0779 - val_accuracy: 0.5551\n",
      "Epoch 588/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3710.3179 - accuracy: 0.6065 - val_loss: -2375.1360 - val_accuracy: 0.5559\n",
      "Epoch 589/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3721.7935 - accuracy: 0.6091 - val_loss: -2393.6345 - val_accuracy: 0.5547\n",
      "Epoch 590/1000\n",
      "710/710 [==============================] - 125s 175ms/step - loss: -3723.2361 - accuracy: 0.6075 - val_loss: -2382.3967 - val_accuracy: 0.5552\n",
      "Epoch 591/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3730.2224 - accuracy: 0.6065 - val_loss: -2382.5488 - val_accuracy: 0.5547\n",
      "Epoch 592/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -3732.2600 - accuracy: 0.6048 - val_loss: -2376.2815 - val_accuracy: 0.5553\n",
      "Epoch 593/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -3745.1201 - accuracy: 0.6075 - val_loss: -2396.4761 - val_accuracy: 0.5579\n",
      "Epoch 594/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3737.3557 - accuracy: 0.6068 - val_loss: -2378.3127 - val_accuracy: 0.5560\n",
      "Epoch 595/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3746.8550 - accuracy: 0.6068 - val_loss: -2390.6084 - val_accuracy: 0.5563\n",
      "Epoch 596/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -3755.3420 - accuracy: 0.6090 - val_loss: -2400.4663 - val_accuracy: 0.5584\n",
      "Epoch 597/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -3785.0430 - accuracy: 0.6092 - val_loss: -2434.4290 - val_accuracy: 0.5573\n",
      "Epoch 598/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -3769.6748 - accuracy: 0.6052 - val_loss: -2420.9165 - val_accuracy: 0.5550\n",
      "Epoch 599/1000\n",
      "710/710 [==============================] - 120s 168ms/step - loss: -3776.3169 - accuracy: 0.6071 - val_loss: -2427.2681 - val_accuracy: 0.5542\n",
      "Epoch 600/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -3780.6936 - accuracy: 0.6071 - val_loss: -2423.1443 - val_accuracy: 0.5537\n",
      "Epoch 601/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -3794.0691 - accuracy: 0.6074 - val_loss: -2428.2122 - val_accuracy: 0.5551\n",
      "Epoch 602/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -3799.8081 - accuracy: 0.6072 - val_loss: -2432.9385 - val_accuracy: 0.5542\n",
      "Epoch 603/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3801.9319 - accuracy: 0.6036 - val_loss: -2433.8809 - val_accuracy: 0.5551\n",
      "Epoch 604/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -3812.3745 - accuracy: 0.6068 - val_loss: -2445.0056 - val_accuracy: 0.5556\n",
      "Epoch 605/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3815.0085 - accuracy: 0.6038 - val_loss: -2435.4861 - val_accuracy: 0.5556\n",
      "Epoch 606/1000\n",
      "710/710 [==============================] - 120s 168ms/step - loss: -3830.1221 - accuracy: 0.6084 - val_loss: -2454.8276 - val_accuracy: 0.5547\n",
      "Epoch 607/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3834.1140 - accuracy: 0.6031 - val_loss: -2465.4617 - val_accuracy: 0.5545\n",
      "Epoch 608/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -3833.9670 - accuracy: 0.6077 - val_loss: -2461.0684 - val_accuracy: 0.5548\n",
      "Epoch 609/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3850.3481 - accuracy: 0.6061 - val_loss: -2453.8611 - val_accuracy: 0.5567\n",
      "Epoch 610/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3844.0271 - accuracy: 0.6082 - val_loss: -2461.3594 - val_accuracy: 0.5570\n",
      "Epoch 611/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -3855.2368 - accuracy: 0.6067 - val_loss: -2477.6189 - val_accuracy: 0.5562\n",
      "Epoch 612/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -3859.9541 - accuracy: 0.6092 - val_loss: -2462.1040 - val_accuracy: 0.5556\n",
      "Epoch 613/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3870.1770 - accuracy: 0.6079 - val_loss: -2490.3494 - val_accuracy: 0.5564\n",
      "Epoch 614/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -3876.6255 - accuracy: 0.6052 - val_loss: -2486.5413 - val_accuracy: 0.5560\n",
      "Epoch 615/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3881.5063 - accuracy: 0.6093 - val_loss: -2482.1985 - val_accuracy: 0.5569\n",
      "Epoch 616/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -3890.3074 - accuracy: 0.6089 - val_loss: -2490.3462 - val_accuracy: 0.5568\n",
      "Epoch 617/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -3894.5388 - accuracy: 0.6099 - val_loss: -2505.6597 - val_accuracy: 0.5553\n",
      "Epoch 618/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -3899.6716 - accuracy: 0.6067 - val_loss: -2493.5872 - val_accuracy: 0.5548\n",
      "Epoch 619/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3915.6809 - accuracy: 0.6054 - val_loss: -2479.2307 - val_accuracy: 0.5557\n",
      "Epoch 620/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -3919.9194 - accuracy: 0.6078 - val_loss: -2492.7996 - val_accuracy: 0.5582\n",
      "Epoch 621/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -3914.8103 - accuracy: 0.6095 - val_loss: -2507.2620 - val_accuracy: 0.5578\n",
      "Epoch 622/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3918.7979 - accuracy: 0.6099 - val_loss: -2504.6743 - val_accuracy: 0.5559\n",
      "Epoch 623/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -3938.6631 - accuracy: 0.6078 - val_loss: -2508.3989 - val_accuracy: 0.5557\n",
      "Epoch 624/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -3934.4446 - accuracy: 0.6082 - val_loss: -2524.0549 - val_accuracy: 0.5569\n",
      "Epoch 625/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -3953.8562 - accuracy: 0.6108 - val_loss: -2512.1172 - val_accuracy: 0.5556\n",
      "Epoch 626/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -3947.1167 - accuracy: 0.6105 - val_loss: -2538.3564 - val_accuracy: 0.5567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 627/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -3957.5029 - accuracy: 0.6057 - val_loss: -2529.8091 - val_accuracy: 0.5565\n",
      "Epoch 628/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -3958.4524 - accuracy: 0.6098 - val_loss: -2545.6423 - val_accuracy: 0.5562\n",
      "Epoch 629/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -3969.6233 - accuracy: 0.6106 - val_loss: -2552.0071 - val_accuracy: 0.5558\n",
      "Epoch 630/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -3983.0022 - accuracy: 0.6099 - val_loss: -2543.7366 - val_accuracy: 0.5557\n",
      "Epoch 631/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -3981.3958 - accuracy: 0.6073 - val_loss: -2550.7119 - val_accuracy: 0.5549\n",
      "Epoch 632/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -3999.5266 - accuracy: 0.6079 - val_loss: -2556.2700 - val_accuracy: 0.5565\n",
      "Epoch 633/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -3994.2893 - accuracy: 0.6112 - val_loss: -2560.0305 - val_accuracy: 0.5555\n",
      "Epoch 634/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -4007.8291 - accuracy: 0.6073 - val_loss: -2561.3928 - val_accuracy: 0.5552\n",
      "Epoch 635/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -4008.8489 - accuracy: 0.6087 - val_loss: -2565.3462 - val_accuracy: 0.5552\n",
      "Epoch 636/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -4015.6958 - accuracy: 0.6099 - val_loss: -2580.5725 - val_accuracy: 0.5565\n",
      "Epoch 637/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -4010.3799 - accuracy: 0.6084 - val_loss: -2587.9517 - val_accuracy: 0.5557\n",
      "Epoch 638/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -4026.1572 - accuracy: 0.6093 - val_loss: -2582.4351 - val_accuracy: 0.5558\n",
      "Epoch 639/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -4038.7292 - accuracy: 0.6093 - val_loss: -2601.7983 - val_accuracy: 0.5567\n",
      "Epoch 640/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4040.6882 - accuracy: 0.6088 - val_loss: -2589.9590 - val_accuracy: 0.5555\n",
      "Epoch 641/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -4051.3079 - accuracy: 0.6099 - val_loss: -2594.5588 - val_accuracy: 0.5570\n",
      "Epoch 642/1000\n",
      "710/710 [==============================] - 106s 150ms/step - loss: -4057.5220 - accuracy: 0.6104 - val_loss: -2620.0825 - val_accuracy: 0.5565\n",
      "Epoch 643/1000\n",
      "710/710 [==============================] - 107s 150ms/step - loss: -4065.7495 - accuracy: 0.6092 - val_loss: -2608.5715 - val_accuracy: 0.5547\n",
      "Epoch 644/1000\n",
      "710/710 [==============================] - 106s 149ms/step - loss: -4061.1091 - accuracy: 0.6087 - val_loss: -2615.9409 - val_accuracy: 0.5571\n",
      "Epoch 645/1000\n",
      "710/710 [==============================] - 106s 150ms/step - loss: -4079.1191 - accuracy: 0.6073 - val_loss: -2619.9141 - val_accuracy: 0.5575\n",
      "Epoch 646/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -4080.4565 - accuracy: 0.6097 - val_loss: -2631.0134 - val_accuracy: 0.5573\n",
      "Epoch 647/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -4096.9937 - accuracy: 0.6056 - val_loss: -2615.7026 - val_accuracy: 0.5563\n",
      "Epoch 648/1000\n",
      "710/710 [==============================] - 113s 160ms/step - loss: -4093.9255 - accuracy: 0.6064 - val_loss: -2606.7698 - val_accuracy: 0.5546\n",
      "Epoch 649/1000\n",
      "710/710 [==============================] - 106s 150ms/step - loss: -4090.1665 - accuracy: 0.6083 - val_loss: -2629.7678 - val_accuracy: 0.5573\n",
      "Epoch 650/1000\n",
      "710/710 [==============================] - 109s 153ms/step - loss: -4107.5903 - accuracy: 0.6078 - val_loss: -2620.6602 - val_accuracy: 0.5559\n",
      "Epoch 651/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -4112.7358 - accuracy: 0.6074 - val_loss: -2630.7783 - val_accuracy: 0.5543\n",
      "Epoch 652/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -4111.9253 - accuracy: 0.6096 - val_loss: -2638.8789 - val_accuracy: 0.5567\n",
      "Epoch 653/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -4113.4321 - accuracy: 0.6079 - val_loss: -2638.2666 - val_accuracy: 0.5564\n",
      "Epoch 654/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -4127.1089 - accuracy: 0.6079 - val_loss: -2651.3328 - val_accuracy: 0.5564\n",
      "Epoch 655/1000\n",
      "710/710 [==============================] - 117s 164ms/step - loss: -4141.3555 - accuracy: 0.6086 - val_loss: -2634.6272 - val_accuracy: 0.5576\n",
      "Epoch 656/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -4147.9043 - accuracy: 0.6127 - val_loss: -2638.3179 - val_accuracy: 0.5568\n",
      "Epoch 657/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4138.4751 - accuracy: 0.6084 - val_loss: -2642.6575 - val_accuracy: 0.5568\n",
      "Epoch 658/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -4158.0215 - accuracy: 0.6092 - val_loss: -2645.8125 - val_accuracy: 0.5575\n",
      "Epoch 659/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -4165.3354 - accuracy: 0.6073 - val_loss: -2655.1411 - val_accuracy: 0.5559\n",
      "Epoch 660/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4165.6055 - accuracy: 0.6071 - val_loss: -2667.7300 - val_accuracy: 0.5545\n",
      "Epoch 661/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4172.0073 - accuracy: 0.6063 - val_loss: -2668.5408 - val_accuracy: 0.5575\n",
      "Epoch 662/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -4177.0444 - accuracy: 0.6076 - val_loss: -2673.9902 - val_accuracy: 0.5569\n",
      "Epoch 663/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -4179.4863 - accuracy: 0.6055 - val_loss: -2669.5054 - val_accuracy: 0.5569\n",
      "Epoch 664/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4193.7437 - accuracy: 0.6084 - val_loss: -2694.0544 - val_accuracy: 0.5584\n",
      "Epoch 665/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4197.3955 - accuracy: 0.6114 - val_loss: -2676.4023 - val_accuracy: 0.5580\n",
      "Epoch 666/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -4201.0869 - accuracy: 0.6085 - val_loss: -2705.3711 - val_accuracy: 0.5575\n",
      "Epoch 667/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -4216.3721 - accuracy: 0.6089 - val_loss: -2709.4399 - val_accuracy: 0.5583\n",
      "Epoch 668/1000\n",
      "710/710 [==============================] - 125s 175ms/step - loss: -4223.0659 - accuracy: 0.6096 - val_loss: -2701.1421 - val_accuracy: 0.5565\n",
      "Epoch 669/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -4227.7993 - accuracy: 0.6075 - val_loss: -2712.1367 - val_accuracy: 0.5579\n",
      "Epoch 670/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -4220.7832 - accuracy: 0.6041 - val_loss: -2697.7639 - val_accuracy: 0.5561\n",
      "Epoch 671/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -4241.2949 - accuracy: 0.6045 - val_loss: -2701.4302 - val_accuracy: 0.5597\n",
      "Epoch 672/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4246.1504 - accuracy: 0.6069 - val_loss: -2714.8279 - val_accuracy: 0.5592\n",
      "Epoch 673/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -4254.5063 - accuracy: 0.6060 - val_loss: -2705.9382 - val_accuracy: 0.5581\n",
      "Epoch 674/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4262.2612 - accuracy: 0.6092 - val_loss: -2716.1978 - val_accuracy: 0.5590\n",
      "Epoch 675/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -4261.7148 - accuracy: 0.6107 - val_loss: -2728.8728 - val_accuracy: 0.5584\n",
      "Epoch 676/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -4280.2842 - accuracy: 0.6057 - val_loss: -2732.7007 - val_accuracy: 0.5575\n",
      "Epoch 677/1000\n",
      "710/710 [==============================] - 2837s 4s/step - loss: -4275.9741 - accuracy: 0.6049 - val_loss: -2717.8250 - val_accuracy: 0.5581\n",
      "Epoch 678/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -4288.5127 - accuracy: 0.6054 - val_loss: -2731.9680 - val_accuracy: 0.5573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 679/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -4282.9360 - accuracy: 0.6088 - val_loss: -2745.7180 - val_accuracy: 0.5596\n",
      "Epoch 680/1000\n",
      "710/710 [==============================] - 111s 157ms/step - loss: -4297.0347 - accuracy: 0.6110 - val_loss: -2727.6562 - val_accuracy: 0.5585\n",
      "Epoch 681/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -4302.8062 - accuracy: 0.6094 - val_loss: -2746.9990 - val_accuracy: 0.5583\n",
      "Epoch 682/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -4313.0249 - accuracy: 0.6070 - val_loss: -2755.0405 - val_accuracy: 0.5554\n",
      "Epoch 683/1000\n",
      "710/710 [==============================] - 113s 160ms/step - loss: -4316.9946 - accuracy: 0.6081 - val_loss: -2735.8367 - val_accuracy: 0.5560\n",
      "Epoch 684/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -4316.5225 - accuracy: 0.6085 - val_loss: -2761.5322 - val_accuracy: 0.5563\n",
      "Epoch 685/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -4322.5464 - accuracy: 0.6010 - val_loss: -2758.5015 - val_accuracy: 0.5563\n",
      "Epoch 686/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -4330.7646 - accuracy: 0.6092 - val_loss: -2764.6287 - val_accuracy: 0.5567\n",
      "Epoch 687/1000\n",
      "710/710 [==============================] - 106s 149ms/step - loss: -4343.8027 - accuracy: 0.6094 - val_loss: -2772.8906 - val_accuracy: 0.5540\n",
      "Epoch 688/1000\n",
      "710/710 [==============================] - 110s 155ms/step - loss: -4336.4663 - accuracy: 0.6079 - val_loss: -2767.6355 - val_accuracy: 0.5555\n",
      "Epoch 689/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -4358.6597 - accuracy: 0.6085 - val_loss: -2787.2747 - val_accuracy: 0.5567\n",
      "Epoch 690/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -4359.6333 - accuracy: 0.6090 - val_loss: -2788.5386 - val_accuracy: 0.5545\n",
      "Epoch 691/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -4355.2231 - accuracy: 0.6093 - val_loss: -2803.9688 - val_accuracy: 0.5558\n",
      "Epoch 692/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -4364.8667 - accuracy: 0.6057 - val_loss: -2790.9219 - val_accuracy: 0.5552\n",
      "Epoch 693/1000\n",
      "710/710 [==============================] - 50s 70ms/step - loss: -4371.3315 - accuracy: 0.6098 - val_loss: -2813.0630 - val_accuracy: 0.5555\n",
      "Epoch 694/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -4380.8726 - accuracy: 0.6049 - val_loss: -2793.7708 - val_accuracy: 0.5558\n",
      "Epoch 695/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -4388.6978 - accuracy: 0.6112 - val_loss: -2806.1755 - val_accuracy: 0.5558\n",
      "Epoch 696/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -4389.8232 - accuracy: 0.6057 - val_loss: -2810.2620 - val_accuracy: 0.5570\n",
      "Epoch 697/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -4405.9546 - accuracy: 0.6069 - val_loss: -2801.9253 - val_accuracy: 0.5570\n",
      "Epoch 698/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -4395.5371 - accuracy: 0.6104 - val_loss: -2808.9570 - val_accuracy: 0.5554\n",
      "Epoch 699/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -4415.4668 - accuracy: 0.6108 - val_loss: -2826.3586 - val_accuracy: 0.5560\n",
      "Epoch 700/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4423.2222 - accuracy: 0.6064 - val_loss: -2827.0391 - val_accuracy: 0.5559\n",
      "Epoch 701/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -4418.4248 - accuracy: 0.6063 - val_loss: -2840.4006 - val_accuracy: 0.5556\n",
      "Epoch 702/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4432.1216 - accuracy: 0.6048 - val_loss: -2816.7441 - val_accuracy: 0.5543\n",
      "Epoch 703/1000\n",
      "710/710 [==============================] - 122s 173ms/step - loss: -4440.6094 - accuracy: 0.6050 - val_loss: -2849.8633 - val_accuracy: 0.5578\n",
      "Epoch 704/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -4447.6162 - accuracy: 0.6081 - val_loss: -2835.3892 - val_accuracy: 0.5577\n",
      "Epoch 705/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -4453.0015 - accuracy: 0.6098 - val_loss: -2828.2683 - val_accuracy: 0.5545\n",
      "Epoch 706/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -4457.8047 - accuracy: 0.6100 - val_loss: -2842.2161 - val_accuracy: 0.5571\n",
      "Epoch 707/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -4465.8154 - accuracy: 0.6111 - val_loss: -2863.2915 - val_accuracy: 0.5562\n",
      "Epoch 708/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4478.7710 - accuracy: 0.6076 - val_loss: -2868.8979 - val_accuracy: 0.5563\n",
      "Epoch 709/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -4484.0659 - accuracy: 0.6060 - val_loss: -2857.6187 - val_accuracy: 0.5549\n",
      "Epoch 710/1000\n",
      "710/710 [==============================] - 117s 164ms/step - loss: -4482.1108 - accuracy: 0.6087 - val_loss: -2870.9604 - val_accuracy: 0.5541\n",
      "Epoch 711/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -4487.9600 - accuracy: 0.6088 - val_loss: -2877.9082 - val_accuracy: 0.5557\n",
      "Epoch 712/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -4496.3560 - accuracy: 0.6032 - val_loss: -2857.5625 - val_accuracy: 0.5547\n",
      "Epoch 713/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4506.0718 - accuracy: 0.6109 - val_loss: -2880.1260 - val_accuracy: 0.5558\n",
      "Epoch 714/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -4508.3569 - accuracy: 0.6107 - val_loss: -2886.0767 - val_accuracy: 0.5566\n",
      "Epoch 715/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -4518.1846 - accuracy: 0.6082 - val_loss: -2885.2280 - val_accuracy: 0.5569\n",
      "Epoch 716/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4532.6846 - accuracy: 0.6089 - val_loss: -2892.0620 - val_accuracy: 0.5557\n",
      "Epoch 717/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4517.2949 - accuracy: 0.6071 - val_loss: -2911.3350 - val_accuracy: 0.5567\n",
      "Epoch 718/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -4541.0498 - accuracy: 0.6060 - val_loss: -2896.4172 - val_accuracy: 0.5554\n",
      "Epoch 719/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -4537.9673 - accuracy: 0.6091 - val_loss: -2902.9016 - val_accuracy: 0.5547\n",
      "Epoch 720/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4547.0552 - accuracy: 0.6089 - val_loss: -2922.2639 - val_accuracy: 0.5559\n",
      "Epoch 721/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -4552.7690 - accuracy: 0.6087 - val_loss: -2897.7310 - val_accuracy: 0.5562\n",
      "Epoch 722/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -4552.3296 - accuracy: 0.6099 - val_loss: -2904.4741 - val_accuracy: 0.5545\n",
      "Epoch 723/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4566.5034 - accuracy: 0.6086 - val_loss: -2918.7329 - val_accuracy: 0.5556\n",
      "Epoch 724/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -4576.7222 - accuracy: 0.6106 - val_loss: -2904.3259 - val_accuracy: 0.5566\n",
      "Epoch 725/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -4576.0322 - accuracy: 0.6099 - val_loss: -2919.9438 - val_accuracy: 0.5569\n",
      "Epoch 726/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -4587.3335 - accuracy: 0.6073 - val_loss: -2927.1013 - val_accuracy: 0.5562\n",
      "Epoch 727/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -4602.9814 - accuracy: 0.6087 - val_loss: -2922.5825 - val_accuracy: 0.5561\n",
      "Epoch 728/1000\n",
      "710/710 [==============================] - 115s 161ms/step - loss: -4595.9956 - accuracy: 0.6081 - val_loss: -2930.0100 - val_accuracy: 0.5571\n",
      "Epoch 729/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -4611.9805 - accuracy: 0.6080 - val_loss: -2935.7786 - val_accuracy: 0.5563\n",
      "Epoch 730/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -4606.0737 - accuracy: 0.6110 - val_loss: -2947.3367 - val_accuracy: 0.5562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 731/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -4617.8813 - accuracy: 0.6086 - val_loss: -2945.6438 - val_accuracy: 0.5563\n",
      "Epoch 732/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -4631.5820 - accuracy: 0.6115 - val_loss: -2953.0483 - val_accuracy: 0.5559\n",
      "Epoch 733/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -4639.8745 - accuracy: 0.6075 - val_loss: -2948.1157 - val_accuracy: 0.5559\n",
      "Epoch 734/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -4637.7739 - accuracy: 0.6078 - val_loss: -2962.2148 - val_accuracy: 0.5565\n",
      "Epoch 735/1000\n",
      "710/710 [==============================] - 120s 168ms/step - loss: -4647.7539 - accuracy: 0.6078 - val_loss: -2977.3105 - val_accuracy: 0.5577\n",
      "Epoch 736/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -4649.7695 - accuracy: 0.6102 - val_loss: -2955.6279 - val_accuracy: 0.5596\n",
      "Epoch 737/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -4648.1797 - accuracy: 0.6063 - val_loss: -2965.3430 - val_accuracy: 0.5577\n",
      "Epoch 738/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -4667.5835 - accuracy: 0.6105 - val_loss: -2985.2039 - val_accuracy: 0.5595\n",
      "Epoch 739/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4678.6211 - accuracy: 0.6114 - val_loss: -2967.7986 - val_accuracy: 0.5575\n",
      "Epoch 740/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4680.7095 - accuracy: 0.6092 - val_loss: -2986.7500 - val_accuracy: 0.5561\n",
      "Epoch 741/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -4683.2827 - accuracy: 0.6087 - val_loss: -2991.1621 - val_accuracy: 0.5547\n",
      "Epoch 742/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4691.9771 - accuracy: 0.6077 - val_loss: -2973.0049 - val_accuracy: 0.5534\n",
      "Epoch 743/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -4702.8179 - accuracy: 0.6075 - val_loss: -3008.8250 - val_accuracy: 0.5571\n",
      "Epoch 744/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4708.1030 - accuracy: 0.6053 - val_loss: -2990.8901 - val_accuracy: 0.5551\n",
      "Epoch 745/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4690.2461 - accuracy: 0.6085 - val_loss: -2988.9578 - val_accuracy: 0.5542\n",
      "Epoch 746/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -4710.7090 - accuracy: 0.6103 - val_loss: -3001.9734 - val_accuracy: 0.5562\n",
      "Epoch 747/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -4723.2314 - accuracy: 0.6098 - val_loss: -3018.7478 - val_accuracy: 0.5558\n",
      "Epoch 748/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -4728.2085 - accuracy: 0.6062 - val_loss: -3007.3911 - val_accuracy: 0.5537\n",
      "Epoch 749/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -4726.9810 - accuracy: 0.6127 - val_loss: -3012.9148 - val_accuracy: 0.5541\n",
      "Epoch 750/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -4738.6978 - accuracy: 0.6083 - val_loss: -2989.8411 - val_accuracy: 0.5556\n",
      "Epoch 751/1000\n",
      "710/710 [==============================] - 112s 157ms/step - loss: -4759.6772 - accuracy: 0.6111 - val_loss: -3004.8438 - val_accuracy: 0.5550\n",
      "Epoch 752/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -4742.8389 - accuracy: 0.6106 - val_loss: -3028.4946 - val_accuracy: 0.5566\n",
      "Epoch 753/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -4743.4824 - accuracy: 0.6081 - val_loss: -3020.2302 - val_accuracy: 0.5547\n",
      "Epoch 754/1000\n",
      "710/710 [==============================] - 109s 154ms/step - loss: -4755.6343 - accuracy: 0.6028 - val_loss: -3004.8494 - val_accuracy: 0.5562\n",
      "Epoch 755/1000\n",
      "710/710 [==============================] - 111s 157ms/step - loss: -4773.7944 - accuracy: 0.6065 - val_loss: -3022.5491 - val_accuracy: 0.5562\n",
      "Epoch 756/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -4780.7222 - accuracy: 0.6072 - val_loss: -3050.9412 - val_accuracy: 0.5569\n",
      "Epoch 757/1000\n",
      "710/710 [==============================] - 115s 163ms/step - loss: -4784.3760 - accuracy: 0.6113 - val_loss: -3039.9302 - val_accuracy: 0.5565\n",
      "Epoch 758/1000\n",
      "710/710 [==============================] - 131s 185ms/step - loss: -4796.0581 - accuracy: 0.6104 - val_loss: -3067.6643 - val_accuracy: 0.5570\n",
      "Epoch 759/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4801.6973 - accuracy: 0.6079 - val_loss: -3053.3435 - val_accuracy: 0.5558\n",
      "Epoch 760/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -4803.5273 - accuracy: 0.6099 - val_loss: -3041.5520 - val_accuracy: 0.5545\n",
      "Epoch 761/1000\n",
      "710/710 [==============================] - 127s 178ms/step - loss: -4820.8550 - accuracy: 0.6104 - val_loss: -3064.0837 - val_accuracy: 0.5526\n",
      "Epoch 762/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -4823.8818 - accuracy: 0.6059 - val_loss: -3043.8423 - val_accuracy: 0.5542\n",
      "Epoch 763/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -4814.6899 - accuracy: 0.6071 - val_loss: -3080.2952 - val_accuracy: 0.5545\n",
      "Epoch 764/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -4839.5894 - accuracy: 0.6094 - val_loss: -3072.6414 - val_accuracy: 0.5560\n",
      "Epoch 765/1000\n",
      "710/710 [==============================] - 131s 185ms/step - loss: -4834.8755 - accuracy: 0.6091 - val_loss: -3059.9094 - val_accuracy: 0.5566\n",
      "Epoch 766/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -4849.5981 - accuracy: 0.6106 - val_loss: -3057.6218 - val_accuracy: 0.5552\n",
      "Epoch 767/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -4848.9541 - accuracy: 0.6111 - val_loss: -3054.8962 - val_accuracy: 0.5558\n",
      "Epoch 768/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -4840.1660 - accuracy: 0.6108 - val_loss: -3084.7844 - val_accuracy: 0.5554\n",
      "Epoch 769/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -4861.4438 - accuracy: 0.6129 - val_loss: -3093.1533 - val_accuracy: 0.5565\n",
      "Epoch 770/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -4868.7236 - accuracy: 0.6103 - val_loss: -3074.5718 - val_accuracy: 0.5555\n",
      "Epoch 771/1000\n",
      "710/710 [==============================] - 107s 150ms/step - loss: -4880.9644 - accuracy: 0.6106 - val_loss: -3095.2129 - val_accuracy: 0.5574\n",
      "Epoch 772/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -4886.3682 - accuracy: 0.6109 - val_loss: -3071.2637 - val_accuracy: 0.5548\n",
      "Epoch 773/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -4885.6025 - accuracy: 0.6110 - val_loss: -3088.7681 - val_accuracy: 0.5551\n",
      "Epoch 774/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -4899.4058 - accuracy: 0.6089 - val_loss: -3101.9646 - val_accuracy: 0.5559\n",
      "Epoch 775/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -4894.3809 - accuracy: 0.6115 - val_loss: -3117.3540 - val_accuracy: 0.5569\n",
      "Epoch 776/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -4903.3130 - accuracy: 0.6096 - val_loss: -3096.1423 - val_accuracy: 0.5562\n",
      "Epoch 777/1000\n",
      "710/710 [==============================] - 117s 164ms/step - loss: -4911.8423 - accuracy: 0.6106 - val_loss: -3124.5823 - val_accuracy: 0.5573\n",
      "Epoch 778/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -4905.9092 - accuracy: 0.6118 - val_loss: -3101.9548 - val_accuracy: 0.5569\n",
      "Epoch 779/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4918.0146 - accuracy: 0.6117 - val_loss: -3122.9077 - val_accuracy: 0.5580\n",
      "Epoch 780/1000\n",
      "710/710 [==============================] - 120s 168ms/step - loss: -4930.3135 - accuracy: 0.6095 - val_loss: -3147.4011 - val_accuracy: 0.5569\n",
      "Epoch 781/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -4932.6826 - accuracy: 0.6114 - val_loss: -3142.8706 - val_accuracy: 0.5567\n",
      "Epoch 782/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -4940.8003 - accuracy: 0.6159 - val_loss: -3126.4707 - val_accuracy: 0.5561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 783/1000\n",
      "710/710 [==============================] - 129s 182ms/step - loss: -4938.8457 - accuracy: 0.6074 - val_loss: -3142.9766 - val_accuracy: 0.5553\n",
      "Epoch 784/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -4966.0786 - accuracy: 0.6109 - val_loss: -3150.6533 - val_accuracy: 0.5552\n",
      "Epoch 785/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -4961.4629 - accuracy: 0.6126 - val_loss: -3139.8538 - val_accuracy: 0.5541\n",
      "Epoch 786/1000\n",
      "710/710 [==============================] - 105s 147ms/step - loss: -4957.4702 - accuracy: 0.6092 - val_loss: -3158.4719 - val_accuracy: 0.5557\n",
      "Epoch 787/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -4978.9722 - accuracy: 0.6076 - val_loss: -3155.2212 - val_accuracy: 0.5543\n",
      "Epoch 788/1000\n",
      "710/710 [==============================] - 123s 173ms/step - loss: -4977.7275 - accuracy: 0.6080 - val_loss: -3164.2773 - val_accuracy: 0.5544\n",
      "Epoch 789/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -4985.9883 - accuracy: 0.6132 - val_loss: -3167.9954 - val_accuracy: 0.5549\n",
      "Epoch 790/1000\n",
      "710/710 [==============================] - 131s 185ms/step - loss: -4994.7402 - accuracy: 0.6101 - val_loss: -3167.5828 - val_accuracy: 0.5549\n",
      "Epoch 791/1000\n",
      "710/710 [==============================] - 129s 182ms/step - loss: -4992.3848 - accuracy: 0.6108 - val_loss: -3199.4189 - val_accuracy: 0.5574\n",
      "Epoch 792/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -5001.5952 - accuracy: 0.6083 - val_loss: -3166.4277 - val_accuracy: 0.5560\n",
      "Epoch 793/1000\n",
      "710/710 [==============================] - 130s 184ms/step - loss: -5012.4580 - accuracy: 0.6119 - val_loss: -3206.6934 - val_accuracy: 0.5563\n",
      "Epoch 794/1000\n",
      "710/710 [==============================] - 128s 181ms/step - loss: -5008.7676 - accuracy: 0.6099 - val_loss: -3181.1648 - val_accuracy: 0.5550\n",
      "Epoch 795/1000\n",
      "710/710 [==============================] - 121s 171ms/step - loss: -5024.0400 - accuracy: 0.6089 - val_loss: -3172.1738 - val_accuracy: 0.5535\n",
      "Epoch 796/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -5036.6919 - accuracy: 0.6090 - val_loss: -3185.1880 - val_accuracy: 0.5537\n",
      "Epoch 797/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -5047.3032 - accuracy: 0.6062 - val_loss: -3186.7957 - val_accuracy: 0.5532\n",
      "Epoch 798/1000\n",
      "710/710 [==============================] - 129s 181ms/step - loss: -5043.5674 - accuracy: 0.6071 - val_loss: -3202.8503 - val_accuracy: 0.5533\n",
      "Epoch 799/1000\n",
      "710/710 [==============================] - 134s 189ms/step - loss: -5042.4033 - accuracy: 0.6101 - val_loss: -3197.2434 - val_accuracy: 0.5528\n",
      "Epoch 800/1000\n",
      "710/710 [==============================] - 134s 188ms/step - loss: -5063.9966 - accuracy: 0.6095 - val_loss: -3217.1282 - val_accuracy: 0.5536\n",
      "Epoch 801/1000\n",
      "710/710 [==============================] - 128s 180ms/step - loss: -5066.8804 - accuracy: 0.6078 - val_loss: -3198.0542 - val_accuracy: 0.5542\n",
      "Epoch 802/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -5068.5405 - accuracy: 0.6109 - val_loss: -3215.2942 - val_accuracy: 0.5552\n",
      "Epoch 803/1000\n",
      "710/710 [==============================] - 117s 164ms/step - loss: -5071.0874 - accuracy: 0.6127 - val_loss: -3244.5151 - val_accuracy: 0.5552\n",
      "Epoch 804/1000\n",
      "710/710 [==============================] - 110s 154ms/step - loss: -5081.4575 - accuracy: 0.6091 - val_loss: -3245.7449 - val_accuracy: 0.5554\n",
      "Epoch 805/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -5097.8247 - accuracy: 0.6077 - val_loss: -3256.8206 - val_accuracy: 0.5547\n",
      "Epoch 806/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -5092.7241 - accuracy: 0.6108 - val_loss: -3234.6174 - val_accuracy: 0.5543\n",
      "Epoch 807/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -5108.7612 - accuracy: 0.6096 - val_loss: -3241.6321 - val_accuracy: 0.5547\n",
      "Epoch 808/1000\n",
      "710/710 [==============================] - 114s 160ms/step - loss: -5097.6802 - accuracy: 0.6107 - val_loss: -3227.4395 - val_accuracy: 0.5563\n",
      "Epoch 809/1000\n",
      "710/710 [==============================] - 115s 163ms/step - loss: -5123.2817 - accuracy: 0.6129 - val_loss: -3244.4785 - val_accuracy: 0.5539\n",
      "Epoch 810/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -5137.4116 - accuracy: 0.6137 - val_loss: -3253.2163 - val_accuracy: 0.5552\n",
      "Epoch 811/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -5119.5000 - accuracy: 0.6200 - val_loss: -3247.6865 - val_accuracy: 0.5547\n",
      "Epoch 812/1000\n",
      "710/710 [==============================] - 117s 164ms/step - loss: -5133.9561 - accuracy: 0.6135 - val_loss: -3270.5073 - val_accuracy: 0.5548\n",
      "Epoch 813/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -5144.6826 - accuracy: 0.6123 - val_loss: -3268.5725 - val_accuracy: 0.5522\n",
      "Epoch 814/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -5130.5933 - accuracy: 0.6070 - val_loss: -3267.0759 - val_accuracy: 0.5547\n",
      "Epoch 815/1000\n",
      "710/710 [==============================] - 125s 176ms/step - loss: -5156.1289 - accuracy: 0.6098 - val_loss: -3291.8677 - val_accuracy: 0.5547\n",
      "Epoch 816/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -5162.9976 - accuracy: 0.6094 - val_loss: -3299.1436 - val_accuracy: 0.5555\n",
      "Epoch 817/1000\n",
      "710/710 [==============================] - 300s 422ms/step - loss: -5171.7744 - accuracy: 0.6130 - val_loss: -3298.7932 - val_accuracy: 0.5551\n",
      "Epoch 818/1000\n",
      "710/710 [==============================] - 137s 193ms/step - loss: -5189.0254 - accuracy: 0.6086 - val_loss: -3311.0999 - val_accuracy: 0.5566\n",
      "Epoch 819/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -5172.3306 - accuracy: 0.6122 - val_loss: -3292.7859 - val_accuracy: 0.5567\n",
      "Epoch 820/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -5202.3013 - accuracy: 0.6082 - val_loss: -3281.0981 - val_accuracy: 0.5563\n",
      "Epoch 821/1000\n",
      "710/710 [==============================] - 125s 176ms/step - loss: -5188.5811 - accuracy: 0.6103 - val_loss: -3279.8708 - val_accuracy: 0.5571\n",
      "Epoch 822/1000\n",
      "710/710 [==============================] - 130s 184ms/step - loss: -5185.5288 - accuracy: 0.6143 - val_loss: -3318.0615 - val_accuracy: 0.5558\n",
      "Epoch 823/1000\n",
      "710/710 [==============================] - 129s 181ms/step - loss: -5196.4751 - accuracy: 0.6093 - val_loss: -3298.2729 - val_accuracy: 0.5558\n",
      "Epoch 824/1000\n",
      "710/710 [==============================] - 54s 76ms/step - loss: -5208.3813 - accuracy: 0.6113 - val_loss: -3296.5315 - val_accuracy: 0.5532\n",
      "Epoch 825/1000\n",
      "710/710 [==============================] - 178s 251ms/step - loss: -5215.9653 - accuracy: 0.6073 - val_loss: -3320.1489 - val_accuracy: 0.5545\n",
      "Epoch 826/1000\n",
      "710/710 [==============================] - 147s 207ms/step - loss: -5221.1040 - accuracy: 0.6095 - val_loss: -3302.4180 - val_accuracy: 0.5540\n",
      "Epoch 827/1000\n",
      "710/710 [==============================] - 155s 218ms/step - loss: -5233.6792 - accuracy: 0.6127 - val_loss: -3321.2734 - val_accuracy: 0.5551\n",
      "Epoch 828/1000\n",
      "710/710 [==============================] - 151s 212ms/step - loss: -5239.5649 - accuracy: 0.6121 - val_loss: -3351.4961 - val_accuracy: 0.5562\n",
      "Epoch 829/1000\n",
      "710/710 [==============================] - 147s 207ms/step - loss: -5246.0479 - accuracy: 0.6119 - val_loss: -3312.3232 - val_accuracy: 0.5537\n",
      "Epoch 830/1000\n",
      "710/710 [==============================] - 153s 216ms/step - loss: -5233.6133 - accuracy: 0.6122 - val_loss: -3348.3149 - val_accuracy: 0.5548\n",
      "Epoch 831/1000\n",
      "710/710 [==============================] - 158s 222ms/step - loss: -5251.5488 - accuracy: 0.6109 - val_loss: -3347.9822 - val_accuracy: 0.5549\n",
      "Epoch 832/1000\n",
      "710/710 [==============================] - 143s 201ms/step - loss: -5269.2808 - accuracy: 0.6118 - val_loss: -3357.0842 - val_accuracy: 0.5541\n",
      "Epoch 833/1000\n",
      "710/710 [==============================] - 162s 228ms/step - loss: -5260.6528 - accuracy: 0.6107 - val_loss: -3332.5996 - val_accuracy: 0.5533\n",
      "Epoch 834/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/710 [==============================] - 153s 215ms/step - loss: -5269.5186 - accuracy: 0.6066 - val_loss: -3326.1831 - val_accuracy: 0.5541\n",
      "Epoch 835/1000\n",
      "710/710 [==============================] - 179s 252ms/step - loss: -5269.3721 - accuracy: 0.6102 - val_loss: -3339.8518 - val_accuracy: 0.5536\n",
      "Epoch 836/1000\n",
      "710/710 [==============================] - 139s 196ms/step - loss: -5279.5483 - accuracy: 0.6098 - val_loss: -3340.9468 - val_accuracy: 0.5558\n",
      "Epoch 837/1000\n",
      "710/710 [==============================] - 171s 241ms/step - loss: -5302.7583 - accuracy: 0.6104 - val_loss: -3352.1013 - val_accuracy: 0.5559\n",
      "Epoch 838/1000\n",
      "710/710 [==============================] - 156s 219ms/step - loss: -5304.8228 - accuracy: 0.6130 - val_loss: -3336.5635 - val_accuracy: 0.5543\n",
      "Epoch 839/1000\n",
      "710/710 [==============================] - 149s 209ms/step - loss: -5291.4116 - accuracy: 0.6100 - val_loss: -3355.0837 - val_accuracy: 0.5553\n",
      "Epoch 840/1000\n",
      "710/710 [==============================] - 145s 205ms/step - loss: -5318.0781 - accuracy: 0.6129 - val_loss: -3358.7766 - val_accuracy: 0.5536\n",
      "Epoch 841/1000\n",
      "710/710 [==============================] - 141s 198ms/step - loss: -5324.4546 - accuracy: 0.6094 - val_loss: -3369.1421 - val_accuracy: 0.5528\n",
      "Epoch 842/1000\n",
      "710/710 [==============================] - 173s 244ms/step - loss: -5321.9238 - accuracy: 0.6119 - val_loss: -3372.8630 - val_accuracy: 0.5536\n",
      "Epoch 843/1000\n",
      "710/710 [==============================] - 170s 239ms/step - loss: -5343.2749 - accuracy: 0.6135 - val_loss: -3387.0200 - val_accuracy: 0.5542\n",
      "Epoch 844/1000\n",
      "710/710 [==============================] - 140s 197ms/step - loss: -5338.9277 - accuracy: 0.6139 - val_loss: -3399.7271 - val_accuracy: 0.5540\n",
      "Epoch 845/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -5339.1958 - accuracy: 0.6077 - val_loss: -3379.8127 - val_accuracy: 0.5532\n",
      "Epoch 846/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -5359.1499 - accuracy: 0.6111 - val_loss: -3382.4951 - val_accuracy: 0.5534\n",
      "Epoch 847/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -5353.0586 - accuracy: 0.6103 - val_loss: -3382.2920 - val_accuracy: 0.5526\n",
      "Epoch 848/1000\n",
      "710/710 [==============================] - 108s 153ms/step - loss: -5350.4536 - accuracy: 0.6114 - val_loss: -3378.5522 - val_accuracy: 0.5530\n",
      "Epoch 849/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -5360.9497 - accuracy: 0.6101 - val_loss: -3398.9363 - val_accuracy: 0.5542\n",
      "Epoch 850/1000\n",
      "710/710 [==============================] - 128s 181ms/step - loss: -5370.1641 - accuracy: 0.6126 - val_loss: -3405.7827 - val_accuracy: 0.5547\n",
      "Epoch 851/1000\n",
      "710/710 [==============================] - 128s 180ms/step - loss: -5391.8730 - accuracy: 0.6099 - val_loss: -3399.3022 - val_accuracy: 0.5561\n",
      "Epoch 852/1000\n",
      "710/710 [==============================] - 498s 701ms/step - loss: -5397.5938 - accuracy: 0.6131 - val_loss: -3405.0437 - val_accuracy: 0.5541\n",
      "Epoch 853/1000\n",
      "710/710 [==============================] - 127s 178ms/step - loss: -5389.5703 - accuracy: 0.6127 - val_loss: -3416.3047 - val_accuracy: 0.5550\n",
      "Epoch 854/1000\n",
      "710/710 [==============================] - 137s 192ms/step - loss: -5417.0181 - accuracy: 0.6111 - val_loss: -3440.1567 - val_accuracy: 0.5554\n",
      "Epoch 855/1000\n",
      "710/710 [==============================] - 126s 178ms/step - loss: -5407.6401 - accuracy: 0.6111 - val_loss: -3454.9192 - val_accuracy: 0.5560\n",
      "Epoch 856/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -5406.5537 - accuracy: 0.6083 - val_loss: -3430.7061 - val_accuracy: 0.5540\n",
      "Epoch 857/1000\n",
      "710/710 [==============================] - 134s 188ms/step - loss: -5432.4658 - accuracy: 0.6082 - val_loss: -3425.9680 - val_accuracy: 0.5532\n",
      "Epoch 858/1000\n",
      "710/710 [==============================] - 126s 178ms/step - loss: -5426.4653 - accuracy: 0.6085 - val_loss: -3429.0681 - val_accuracy: 0.5532\n",
      "Epoch 859/1000\n",
      "710/710 [==============================] - 46s 64ms/step - loss: -5442.0117 - accuracy: 0.6115 - val_loss: -3469.0276 - val_accuracy: 0.5544\n",
      "Epoch 860/1000\n",
      "710/710 [==============================] - 109s 154ms/step - loss: -5455.1567 - accuracy: 0.6100 - val_loss: -3465.6992 - val_accuracy: 0.5532\n",
      "Epoch 861/1000\n",
      "710/710 [==============================] - 105s 148ms/step - loss: -5445.2705 - accuracy: 0.6117 - val_loss: -3430.5588 - val_accuracy: 0.5538\n",
      "Epoch 862/1000\n",
      "710/710 [==============================] - 112s 158ms/step - loss: -5455.2603 - accuracy: 0.6128 - val_loss: -3449.9360 - val_accuracy: 0.5542\n",
      "Epoch 863/1000\n",
      "710/710 [==============================] - 110s 155ms/step - loss: -5461.6245 - accuracy: 0.6097 - val_loss: -3461.7549 - val_accuracy: 0.5554\n",
      "Epoch 864/1000\n",
      "710/710 [==============================] - 110s 155ms/step - loss: -5466.3569 - accuracy: 0.6082 - val_loss: -3441.7866 - val_accuracy: 0.5552\n",
      "Epoch 865/1000\n",
      "710/710 [==============================] - 468s 659ms/step - loss: -5479.1133 - accuracy: 0.6141 - val_loss: -3452.4189 - val_accuracy: 0.5554\n",
      "Epoch 866/1000\n",
      "710/710 [==============================] - 116s 163ms/step - loss: -5467.2754 - accuracy: 0.6114 - val_loss: -3465.7769 - val_accuracy: 0.5558\n",
      "Epoch 867/1000\n",
      "710/710 [==============================] - 119s 168ms/step - loss: -5475.0415 - accuracy: 0.6099 - val_loss: -3469.9954 - val_accuracy: 0.5561\n",
      "Epoch 868/1000\n",
      "710/710 [==============================] - 149s 210ms/step - loss: -5483.0684 - accuracy: 0.6131 - val_loss: -3478.3081 - val_accuracy: 0.5558\n",
      "Epoch 869/1000\n",
      "710/710 [==============================] - 126s 177ms/step - loss: -5489.8848 - accuracy: 0.6159 - val_loss: -3502.2161 - val_accuracy: 0.5570\n",
      "Epoch 870/1000\n",
      "710/710 [==============================] - 131s 185ms/step - loss: -5501.6270 - accuracy: 0.6099 - val_loss: -3495.7766 - val_accuracy: 0.5551\n",
      "Epoch 871/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -5508.9458 - accuracy: 0.6097 - val_loss: -3486.1724 - val_accuracy: 0.5554\n",
      "Epoch 872/1000\n",
      "710/710 [==============================] - 125s 175ms/step - loss: -5522.1831 - accuracy: 0.6134 - val_loss: -3502.0686 - val_accuracy: 0.5557\n",
      "Epoch 873/1000\n",
      "710/710 [==============================] - 142s 200ms/step - loss: -5520.8765 - accuracy: 0.6083 - val_loss: -3503.7471 - val_accuracy: 0.5552\n",
      "Epoch 874/1000\n",
      "710/710 [==============================] - 130s 184ms/step - loss: -5531.5747 - accuracy: 0.6104 - val_loss: -3524.3115 - val_accuracy: 0.5557\n",
      "Epoch 875/1000\n",
      "710/710 [==============================] - 126s 178ms/step - loss: -5530.3330 - accuracy: 0.6102 - val_loss: -3500.7864 - val_accuracy: 0.5545\n",
      "Epoch 876/1000\n",
      "710/710 [==============================] - 117s 164ms/step - loss: -5537.7485 - accuracy: 0.6123 - val_loss: -3508.4604 - val_accuracy: 0.5547\n",
      "Epoch 877/1000\n",
      "710/710 [==============================] - 130s 183ms/step - loss: -5550.7759 - accuracy: 0.6132 - val_loss: -3507.3796 - val_accuracy: 0.5554\n",
      "Epoch 878/1000\n",
      "710/710 [==============================] - 134s 188ms/step - loss: -5554.1030 - accuracy: 0.6140 - val_loss: -3543.1252 - val_accuracy: 0.5547\n",
      "Epoch 879/1000\n",
      "710/710 [==============================] - 60s 84ms/step - loss: -5565.4541 - accuracy: 0.6124 - val_loss: -3531.2156 - val_accuracy: 0.5538\n",
      "Epoch 880/1000\n",
      "710/710 [==============================] - 135s 190ms/step - loss: -5572.4375 - accuracy: 0.6156 - val_loss: -3528.7666 - val_accuracy: 0.5529\n",
      "Epoch 881/1000\n",
      "710/710 [==============================] - 132s 185ms/step - loss: -5576.0054 - accuracy: 0.6090 - val_loss: -3536.6086 - val_accuracy: 0.5539\n",
      "Epoch 882/1000\n",
      "710/710 [==============================] - 118s 167ms/step - loss: -5575.0732 - accuracy: 0.6107 - val_loss: -3563.5208 - val_accuracy: 0.5530\n",
      "Epoch 883/1000\n",
      "710/710 [==============================] - 133s 187ms/step - loss: -5585.0635 - accuracy: 0.6083 - val_loss: -3546.9868 - val_accuracy: 0.5546\n",
      "Epoch 884/1000\n",
      "710/710 [==============================] - 131s 184ms/step - loss: -5596.4858 - accuracy: 0.6102 - val_loss: -3547.7344 - val_accuracy: 0.5544\n",
      "Epoch 885/1000\n",
      "710/710 [==============================] - 109s 153ms/step - loss: -5597.1494 - accuracy: 0.6102 - val_loss: -3558.5986 - val_accuracy: 0.5560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/1000\n",
      "710/710 [==============================] - 127s 179ms/step - loss: -5591.0146 - accuracy: 0.6111 - val_loss: -3562.9841 - val_accuracy: 0.5552\n",
      "Epoch 887/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -5613.3447 - accuracy: 0.6117 - val_loss: -3574.8682 - val_accuracy: 0.5566\n",
      "Epoch 888/1000\n",
      "710/710 [==============================] - 127s 178ms/step - loss: -5621.6108 - accuracy: 0.6087 - val_loss: -3565.1326 - val_accuracy: 0.5530\n",
      "Epoch 889/1000\n",
      "710/710 [==============================] - 126s 177ms/step - loss: -5622.4956 - accuracy: 0.6115 - val_loss: -3564.6428 - val_accuracy: 0.5535\n",
      "Epoch 890/1000\n",
      "710/710 [==============================] - 1125s 2s/step - loss: -5626.5566 - accuracy: 0.6105 - val_loss: -3586.5974 - val_accuracy: 0.5537\n",
      "Epoch 891/1000\n",
      "710/710 [==============================] - 125s 176ms/step - loss: -5639.4692 - accuracy: 0.6099 - val_loss: -3572.0540 - val_accuracy: 0.5547\n",
      "Epoch 892/1000\n",
      "710/710 [==============================] - 138s 194ms/step - loss: -5646.1084 - accuracy: 0.6071 - val_loss: -3565.3984 - val_accuracy: 0.5534\n",
      "Epoch 893/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -5647.0322 - accuracy: 0.6092 - val_loss: -3578.8303 - val_accuracy: 0.5550\n",
      "Epoch 894/1000\n",
      "710/710 [==============================] - 179s 252ms/step - loss: -5658.5054 - accuracy: 0.6121 - val_loss: -3590.8308 - val_accuracy: 0.5540\n",
      "Epoch 895/1000\n",
      "710/710 [==============================] - 158s 223ms/step - loss: -5651.4253 - accuracy: 0.6111 - val_loss: -3578.2559 - val_accuracy: 0.5522\n",
      "Epoch 896/1000\n",
      "710/710 [==============================] - 139s 196ms/step - loss: -5650.7495 - accuracy: 0.6100 - val_loss: -3591.4790 - val_accuracy: 0.5559\n",
      "Epoch 897/1000\n",
      "710/710 [==============================] - 129s 182ms/step - loss: -5669.9141 - accuracy: 0.6093 - val_loss: -3588.0842 - val_accuracy: 0.5536\n",
      "Epoch 898/1000\n",
      "710/710 [==============================] - 134s 188ms/step - loss: -5691.4561 - accuracy: 0.6106 - val_loss: -3602.2825 - val_accuracy: 0.5541\n",
      "Epoch 899/1000\n",
      "710/710 [==============================] - 137s 193ms/step - loss: -5695.1411 - accuracy: 0.6103 - val_loss: -3603.4639 - val_accuracy: 0.5543\n",
      "Epoch 900/1000\n",
      "710/710 [==============================] - 142s 200ms/step - loss: -5690.6382 - accuracy: 0.6114 - val_loss: -3597.3931 - val_accuracy: 0.5510\n",
      "Epoch 901/1000\n",
      "710/710 [==============================] - 142s 200ms/step - loss: -5708.3774 - accuracy: 0.6127 - val_loss: -3609.3496 - val_accuracy: 0.5532\n",
      "Epoch 902/1000\n",
      "710/710 [==============================] - 128s 181ms/step - loss: -5707.5190 - accuracy: 0.6125 - val_loss: -3626.5288 - val_accuracy: 0.5547\n",
      "Epoch 903/1000\n",
      "710/710 [==============================] - 76s 107ms/step - loss: -5713.6196 - accuracy: 0.6129 - val_loss: -3632.1074 - val_accuracy: 0.5521\n",
      "Epoch 904/1000\n",
      "710/710 [==============================] - 153s 215ms/step - loss: -5728.3999 - accuracy: 0.6135 - val_loss: -3647.9204 - val_accuracy: 0.5539\n",
      "Epoch 905/1000\n",
      "710/710 [==============================] - 2159s 3s/step - loss: -5728.0059 - accuracy: 0.6110 - val_loss: -3643.7061 - val_accuracy: 0.5529\n",
      "Epoch 906/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -5739.3726 - accuracy: 0.6113 - val_loss: -3635.4084 - val_accuracy: 0.5516\n",
      "Epoch 907/1000\n",
      "710/710 [==============================] - 139s 196ms/step - loss: -5736.7251 - accuracy: 0.6082 - val_loss: -3639.4690 - val_accuracy: 0.5521\n",
      "Epoch 908/1000\n",
      "710/710 [==============================] - 134s 189ms/step - loss: -5736.7476 - accuracy: 0.6094 - val_loss: -3627.8628 - val_accuracy: 0.5527\n",
      "Epoch 909/1000\n",
      "710/710 [==============================] - 141s 199ms/step - loss: -5755.3120 - accuracy: 0.6098 - val_loss: -3663.6230 - val_accuracy: 0.5545\n",
      "Epoch 910/1000\n",
      "710/710 [==============================] - 147s 207ms/step - loss: -5753.7485 - accuracy: 0.6114 - val_loss: -3674.4683 - val_accuracy: 0.5571\n",
      "Epoch 911/1000\n",
      "710/710 [==============================] - 139s 196ms/step - loss: -5765.9932 - accuracy: 0.6100 - val_loss: -3640.5127 - val_accuracy: 0.5549\n",
      "Epoch 912/1000\n",
      "710/710 [==============================] - 131s 185ms/step - loss: -5763.2188 - accuracy: 0.6087 - val_loss: -3658.5664 - val_accuracy: 0.5559\n",
      "Epoch 913/1000\n",
      "710/710 [==============================] - 129s 181ms/step - loss: -5782.8457 - accuracy: 0.6136 - val_loss: -3674.0522 - val_accuracy: 0.5549\n",
      "Epoch 914/1000\n",
      "710/710 [==============================] - 129s 182ms/step - loss: -5773.8770 - accuracy: 0.6126 - val_loss: -3676.0818 - val_accuracy: 0.5537\n",
      "Epoch 915/1000\n",
      "710/710 [==============================] - 2676s 4s/step - loss: -5780.1763 - accuracy: 0.6095 - val_loss: -3664.6780 - val_accuracy: 0.5539\n",
      "Epoch 916/1000\n",
      "710/710 [==============================] - 110s 156ms/step - loss: -5798.7876 - accuracy: 0.6078 - val_loss: -3661.0000 - val_accuracy: 0.5531\n",
      "Epoch 917/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -5787.4058 - accuracy: 0.6110 - val_loss: -3670.5781 - val_accuracy: 0.5544\n",
      "Epoch 918/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -5799.9155 - accuracy: 0.6085 - val_loss: -3667.8843 - val_accuracy: 0.5540\n",
      "Epoch 919/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -5806.5283 - accuracy: 0.6135 - val_loss: -3679.8108 - val_accuracy: 0.5554\n",
      "Epoch 920/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -5815.4888 - accuracy: 0.6126 - val_loss: -3700.3171 - val_accuracy: 0.5552\n",
      "Epoch 921/1000\n",
      "710/710 [==============================] - 113s 160ms/step - loss: -5824.2944 - accuracy: 0.6123 - val_loss: -3681.6221 - val_accuracy: 0.5547\n",
      "Epoch 922/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -5849.4819 - accuracy: 0.6078 - val_loss: -3695.0491 - val_accuracy: 0.5559\n",
      "Epoch 923/1000\n",
      "710/710 [==============================] - -14s -20419us/step - loss: -5831.0415 - accuracy: 0.6098 - val_loss: -3686.0239 - val_accuracy: 0.5543\n",
      "Epoch 924/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -5832.2471 - accuracy: 0.6084 - val_loss: -3681.9868 - val_accuracy: 0.5528\n",
      "Epoch 925/1000\n",
      "710/710 [==============================] - 109s 154ms/step - loss: -5855.8843 - accuracy: 0.6117 - val_loss: -3670.7122 - val_accuracy: 0.5544\n",
      "Epoch 926/1000\n",
      "710/710 [==============================] - 111s 157ms/step - loss: -5851.7681 - accuracy: 0.6132 - val_loss: -3704.2881 - val_accuracy: 0.5546\n",
      "Epoch 927/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -5865.1606 - accuracy: 0.6131 - val_loss: -3723.3906 - val_accuracy: 0.5548\n",
      "Epoch 928/1000\n",
      "710/710 [==============================] - 109s 153ms/step - loss: -5869.8813 - accuracy: 0.6092 - val_loss: -3727.5808 - val_accuracy: 0.5531\n",
      "Epoch 929/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -5879.9785 - accuracy: 0.6117 - val_loss: -3724.3352 - val_accuracy: 0.5544\n",
      "Epoch 930/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -5875.2124 - accuracy: 0.6122 - val_loss: -3716.9053 - val_accuracy: 0.5543\n",
      "Epoch 931/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -5890.1855 - accuracy: 0.6106 - val_loss: -3742.6670 - val_accuracy: 0.5526\n",
      "Epoch 932/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -5909.2104 - accuracy: 0.6080 - val_loss: -3727.0203 - val_accuracy: 0.5537\n",
      "Epoch 933/1000\n",
      "710/710 [==============================] - 127s 179ms/step - loss: -5897.3657 - accuracy: 0.6066 - val_loss: -3742.6343 - val_accuracy: 0.5529\n",
      "Epoch 934/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -5922.0371 - accuracy: 0.6104 - val_loss: -3735.7173 - val_accuracy: 0.5527\n",
      "Epoch 935/1000\n",
      "710/710 [==============================] - 125s 176ms/step - loss: -5919.7236 - accuracy: 0.6090 - val_loss: -3758.6926 - val_accuracy: 0.5534\n",
      "Epoch 936/1000\n",
      "710/710 [==============================] - 126s 178ms/step - loss: -5924.7061 - accuracy: 0.6051 - val_loss: -3740.1987 - val_accuracy: 0.5536\n",
      "Epoch 937/1000\n",
      "710/710 [==============================] - 121s 170ms/step - loss: -5922.8921 - accuracy: 0.6088 - val_loss: -3745.2937 - val_accuracy: 0.5530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 938/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -5940.4512 - accuracy: 0.6123 - val_loss: -3776.2944 - val_accuracy: 0.5522\n",
      "Epoch 939/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -5961.3086 - accuracy: 0.6109 - val_loss: -3759.4324 - val_accuracy: 0.5518\n",
      "Epoch 940/1000\n",
      "710/710 [==============================] - 122s 171ms/step - loss: -5948.2231 - accuracy: 0.6103 - val_loss: -3783.8352 - val_accuracy: 0.5524\n",
      "Epoch 941/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -5980.4443 - accuracy: 0.6106 - val_loss: -3767.5928 - val_accuracy: 0.5514\n",
      "Epoch 942/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -5950.5322 - accuracy: 0.6127 - val_loss: -3778.0833 - val_accuracy: 0.5521\n",
      "Epoch 943/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -5958.3145 - accuracy: 0.6116 - val_loss: -3789.2026 - val_accuracy: 0.5536\n",
      "Epoch 944/1000\n",
      "710/710 [==============================] - 120s 170ms/step - loss: -5974.9390 - accuracy: 0.6106 - val_loss: -3768.6201 - val_accuracy: 0.5517\n",
      "Epoch 945/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -5971.5430 - accuracy: 0.6095 - val_loss: -3769.0552 - val_accuracy: 0.5520\n",
      "Epoch 946/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -5991.5640 - accuracy: 0.6139 - val_loss: -3776.4602 - val_accuracy: 0.5496\n",
      "Epoch 947/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -5987.4375 - accuracy: 0.6117 - val_loss: -3784.1792 - val_accuracy: 0.5525\n",
      "Epoch 948/1000\n",
      "710/710 [==============================] - 128s 180ms/step - loss: -5998.6919 - accuracy: 0.6062 - val_loss: -3799.9634 - val_accuracy: 0.5529\n",
      "Epoch 949/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -6011.0107 - accuracy: 0.6085 - val_loss: -3807.1511 - val_accuracy: 0.5523\n",
      "Epoch 950/1000\n",
      "710/710 [==============================] - 112s 157ms/step - loss: -5998.5435 - accuracy: 0.6084 - val_loss: -3837.3296 - val_accuracy: 0.5522\n",
      "Epoch 951/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -6017.0503 - accuracy: 0.6059 - val_loss: -3819.3201 - val_accuracy: 0.5505\n",
      "Epoch 952/1000\n",
      "710/710 [==============================] - 116s 164ms/step - loss: -6012.6343 - accuracy: 0.6083 - val_loss: -3827.2573 - val_accuracy: 0.5499\n",
      "Epoch 953/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -6031.6831 - accuracy: 0.6084 - val_loss: -3826.0833 - val_accuracy: 0.5497\n",
      "Epoch 954/1000\n",
      "710/710 [==============================] - 111s 156ms/step - loss: -6029.9673 - accuracy: 0.6068 - val_loss: -3831.2517 - val_accuracy: 0.5506\n",
      "Epoch 955/1000\n",
      "710/710 [==============================] - 40812s 57s/step - loss: -6039.1528 - accuracy: 0.6118 - val_loss: -3815.3020 - val_accuracy: 0.5513\n",
      "Epoch 956/1000\n",
      "710/710 [==============================] - 146s 206ms/step - loss: -6046.7446 - accuracy: 0.6119 - val_loss: -3819.8267 - val_accuracy: 0.5498\n",
      "Epoch 957/1000\n",
      "710/710 [==============================] - 136s 191ms/step - loss: -6062.2876 - accuracy: 0.6087 - val_loss: -3834.1167 - val_accuracy: 0.5512\n",
      "Epoch 958/1000\n",
      "710/710 [==============================] - 125s 177ms/step - loss: -6057.5630 - accuracy: 0.6087 - val_loss: -3846.1833 - val_accuracy: 0.5505\n",
      "Epoch 959/1000\n",
      "710/710 [==============================] - 126s 177ms/step - loss: -6076.8789 - accuracy: 0.6084 - val_loss: -3814.0190 - val_accuracy: 0.5539\n",
      "Epoch 960/1000\n",
      "710/710 [==============================] - 202s 285ms/step - loss: -6058.5498 - accuracy: 0.6159 - val_loss: -3832.5083 - val_accuracy: 0.5554\n",
      "Epoch 961/1000\n",
      "710/710 [==============================] - 194s 273ms/step - loss: -6086.6841 - accuracy: 0.6121 - val_loss: -3858.9875 - val_accuracy: 0.5523\n",
      "Epoch 962/1000\n",
      "710/710 [==============================] - 207s 292ms/step - loss: -6102.2666 - accuracy: 0.6114 - val_loss: -3831.5295 - val_accuracy: 0.5518\n",
      "Epoch 963/1000\n",
      "710/710 [==============================] - 184s 259ms/step - loss: -6097.7500 - accuracy: 0.6104 - val_loss: -3855.2034 - val_accuracy: 0.5520\n",
      "Epoch 964/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -6098.0254 - accuracy: 0.6104 - val_loss: -3885.2368 - val_accuracy: 0.5526\n",
      "Epoch 965/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -6096.9761 - accuracy: 0.6135 - val_loss: -3869.0081 - val_accuracy: 0.5514\n",
      "Epoch 966/1000\n",
      "710/710 [==============================] - 130s 183ms/step - loss: -6108.8647 - accuracy: 0.6102 - val_loss: -3903.3181 - val_accuracy: 0.5520\n",
      "Epoch 967/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -6131.3550 - accuracy: 0.6091 - val_loss: -3871.7756 - val_accuracy: 0.5515\n",
      "Epoch 968/1000\n",
      "710/710 [==============================] - 127s 179ms/step - loss: -6116.5796 - accuracy: 0.6107 - val_loss: -3881.7300 - val_accuracy: 0.5511\n",
      "Epoch 969/1000\n",
      "710/710 [==============================] - 135s 191ms/step - loss: -6128.1035 - accuracy: 0.6121 - val_loss: -3871.4316 - val_accuracy: 0.5497\n",
      "Epoch 970/1000\n",
      "710/710 [==============================] - 147s 207ms/step - loss: -6138.0747 - accuracy: 0.6107 - val_loss: -3892.2319 - val_accuracy: 0.5510\n",
      "Epoch 971/1000\n",
      "710/710 [==============================] - 234s 330ms/step - loss: -6144.0562 - accuracy: 0.6088 - val_loss: -3893.8496 - val_accuracy: 0.5516\n",
      "Epoch 972/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -6146.4375 - accuracy: 0.6099 - val_loss: -3898.2388 - val_accuracy: 0.5517\n",
      "Epoch 973/1000\n",
      "710/710 [==============================] - 157s 221ms/step - loss: -6166.4058 - accuracy: 0.6118 - val_loss: -3897.9824 - val_accuracy: 0.5509\n",
      "Epoch 974/1000\n",
      "710/710 [==============================] - 138s 194ms/step - loss: -6169.9331 - accuracy: 0.6105 - val_loss: -3906.6365 - val_accuracy: 0.5506\n",
      "Epoch 975/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -6184.7749 - accuracy: 0.6124 - val_loss: -3914.5481 - val_accuracy: 0.5533\n",
      "Epoch 976/1000\n",
      "710/710 [==============================] - 119s 167ms/step - loss: -6161.6377 - accuracy: 0.6129 - val_loss: -3917.6262 - val_accuracy: 0.5522\n",
      "Epoch 977/1000\n",
      "710/710 [==============================] - 114s 161ms/step - loss: -6174.7368 - accuracy: 0.6102 - val_loss: -3918.5984 - val_accuracy: 0.5500\n",
      "Epoch 978/1000\n",
      "710/710 [==============================] - 112s 157ms/step - loss: -6185.8652 - accuracy: 0.6059 - val_loss: -3896.9009 - val_accuracy: 0.5503\n",
      "Epoch 979/1000\n",
      "710/710 [==============================] - 110s 155ms/step - loss: -6200.4316 - accuracy: 0.6097 - val_loss: -3905.2302 - val_accuracy: 0.5519\n",
      "Epoch 980/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -6202.2983 - accuracy: 0.6128 - val_loss: -3906.8809 - val_accuracy: 0.5514\n",
      "Epoch 981/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -6208.8877 - accuracy: 0.6119 - val_loss: -3968.8347 - val_accuracy: 0.5520\n",
      "Epoch 982/1000\n",
      "710/710 [==============================] - 113s 159ms/step - loss: -6218.8252 - accuracy: 0.6053 - val_loss: -3935.2124 - val_accuracy: 0.5521\n",
      "Epoch 983/1000\n",
      "710/710 [==============================] - 115s 162ms/step - loss: -6223.0518 - accuracy: 0.6126 - val_loss: -3946.5227 - val_accuracy: 0.5504\n",
      "Epoch 984/1000\n",
      "710/710 [==============================] - 113s 160ms/step - loss: -6213.2437 - accuracy: 0.6089 - val_loss: -3949.1646 - val_accuracy: 0.5523\n",
      "Epoch 985/1000\n",
      "710/710 [==============================] - 107s 151ms/step - loss: -6226.2583 - accuracy: 0.6058 - val_loss: -3934.0669 - val_accuracy: 0.5524\n",
      "Epoch 986/1000\n",
      "710/710 [==============================] - 108s 152ms/step - loss: -6241.9634 - accuracy: 0.6092 - val_loss: -3939.3159 - val_accuracy: 0.5514\n",
      "Epoch 987/1000\n",
      "710/710 [==============================] - 128s 180ms/step - loss: -6239.8184 - accuracy: 0.6078 - val_loss: -3962.4995 - val_accuracy: 0.5523\n",
      "Epoch 988/1000\n",
      "710/710 [==============================] - 128s 180ms/step - loss: -6253.4922 - accuracy: 0.6077 - val_loss: -3946.1965 - val_accuracy: 0.5516\n",
      "Epoch 989/1000\n",
      "710/710 [==============================] - 118s 166ms/step - loss: -6252.9160 - accuracy: 0.6101 - val_loss: -3979.6121 - val_accuracy: 0.5539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "710/710 [==============================] - 120s 169ms/step - loss: -6265.6450 - accuracy: 0.6089 - val_loss: -3963.8088 - val_accuracy: 0.5525\n",
      "Epoch 991/1000\n",
      "710/710 [==============================] - 124s 174ms/step - loss: -6288.9341 - accuracy: 0.6109 - val_loss: -3951.2019 - val_accuracy: 0.5516\n",
      "Epoch 992/1000\n",
      "710/710 [==============================] - 125s 176ms/step - loss: -6276.9888 - accuracy: 0.6107 - val_loss: -3952.3706 - val_accuracy: 0.5501\n",
      "Epoch 993/1000\n",
      "710/710 [==============================] - 122s 172ms/step - loss: -6291.3423 - accuracy: 0.6101 - val_loss: -3958.1724 - val_accuracy: 0.5515\n",
      "Epoch 994/1000\n",
      "710/710 [==============================] - 124s 175ms/step - loss: -6297.0898 - accuracy: 0.6075 - val_loss: -3949.9905 - val_accuracy: 0.5505\n",
      "Epoch 995/1000\n",
      "710/710 [==============================] - 129s 181ms/step - loss: -6310.0723 - accuracy: 0.6115 - val_loss: -3982.3994 - val_accuracy: 0.5502\n",
      "Epoch 996/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -6301.8867 - accuracy: 0.6116 - val_loss: -4011.9670 - val_accuracy: 0.5533\n",
      "Epoch 997/1000\n",
      "710/710 [==============================] - 117s 165ms/step - loss: -6302.8403 - accuracy: 0.6095 - val_loss: -3988.6575 - val_accuracy: 0.5529\n",
      "Epoch 998/1000\n",
      "710/710 [==============================] - 123s 174ms/step - loss: -6302.1460 - accuracy: 0.6110 - val_loss: -3973.2109 - val_accuracy: 0.5517\n",
      "Epoch 999/1000\n",
      "710/710 [==============================] - 127s 179ms/step - loss: -6313.1660 - accuracy: 0.6142 - val_loss: -3992.6318 - val_accuracy: 0.5516\n",
      "Epoch 1000/1000\n",
      "710/710 [==============================] - 142s 199ms/step - loss: -6335.9248 - accuracy: 0.6120 - val_loss: -4000.6074 - val_accuracy: 0.5529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a511d2128>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "embedding_vector_length = 256\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(TOP_K, embedding_vector_length, input_length=max_length),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_test), epochs=1000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6413 2392    0]\n",
      " [1191 6145    0]\n",
      " [ 455 6119    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4752953629774532"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "y_pred = [1 if a > 0.5 else 0 for a in y_pred]\n",
    "\n",
    "print(confusion_matrix(list(y_test), list(y_pred)))\n",
    "\n",
    "f1_score(list(y_test), y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6413 2392    0]\n",
      " [1191 6145    0]\n",
      " [ 455 6119    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      8805\n",
      "           1       0.42      0.84      0.56      7336\n",
      "           2       0.00      0.00      0.00      6574\n",
      "\n",
      "    accuracy                           0.55     22715\n",
      "   macro avg       0.41      0.52      0.44     22715\n",
      "weighted avg       0.44      0.55      0.48     22715\n",
      "\n",
      "0.5528505392912173\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
