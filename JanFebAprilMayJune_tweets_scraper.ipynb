{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import tweepy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import GetOldTweets3 as got\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from nltk import word_tokenize\n",
    "stopwords = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "withLoc_df = pd.read_csv('corona_april_may_withLoc.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanFeb_df = pd.read_csv('tweets_with_loc_JanFeb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "June_df = pd.read_csv('tweets_with_loc_June.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "June_df['Tweet_text'] = June_df['tweet_txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "June_df = June_df[['Tweet_text','location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "noLocJune_df = June_df[(June_df['location'].isnull() == True)  | (June_df['location'] == None) | (June_df['location'] == \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51433</th>\n",
       "      <td>RT @Comparativist: ðŸš¨ðŸš¨ðŸš¨ðŸš¨\\n\\n\"There is something...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56882</th>\n",
       "      <td>And yet there is a group of people making so m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweet_text location\n",
       "51433  RT @Comparativist: ðŸš¨ðŸš¨ðŸš¨ðŸš¨\\n\\n\"There is something...      NaN\n",
       "56882  And yet there is a group of people making so m...      NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noLocJune_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "withLocJune_df = June_df.drop(noLocJune_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanFeb_df = JanFeb_df[['Tweet_text','location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noLocJanFeb_df = JanFeb_df[(JanFeb_df['location'].isnull() == True)  | (JanFeb_df['location'] == None) | (JanFeb_df['location'] == \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "withLocJanFeb_df = JanFeb_df.drop(noLocJanFeb_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Tweet_text, location]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noLocJanFeb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "withLoc_df = withLoc_df[['Tweet_text','location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [withLoc_df,withLocJanFeb_df,withLocJune_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTweets = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "noLocAllTweets = allTweets[(allTweets['location'].isnull() == True)  | (allTweets['location'] == None) | (allTweets['location'] == \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTweetsWithLoc = allTweets.drop(noLocAllTweets.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv('cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ([str(word).lower() for word in list(cities['country'])])\n",
    "country_tweets = {}\n",
    "for country in countries:\n",
    "    country_tweets[country] = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "locations = list(allTweetsWithLoc['location'])\n",
    "tweets = list(allTweetsWithLoc['Tweet_text'])\n",
    "\n",
    "\n",
    "def getCountryTweets():\n",
    "    global locations,tweets,country_tweets\n",
    "    countries = [str(word).lower() for word in list(cities['country'])]\n",
    "    subcountries = [str(word).lower() for word in list(cities['subcountry'])]\n",
    "    citiess = [str(word).lower() for word in list(cities['name'])]\n",
    "    abb1 = [str(word).lower() for word in list(cities['abb1'])]\n",
    "    abb2 = [str(word).lower() for word in list(cities['abb2'])]\n",
    "    \n",
    "    \n",
    "    for i in range(len(locations)):\n",
    "        \n",
    "        location = locations[i]\n",
    "        words = location.split(', ')\n",
    "        word = words[-1].lower()\n",
    "        flag = 0\n",
    "        if word == \"bangalore\":\n",
    "            word = \"bengaluru\"\n",
    "        if word in countries or word in abb1 or word in abb2:\n",
    "            \n",
    "\n",
    "            if word not in countries:\n",
    "                if word in abb1:\n",
    "                    country = countries[abb1.index(word)]\n",
    "                else:\n",
    "                    country = countries[abb2.index(word)]\n",
    "            else:\n",
    "                country = word\n",
    "#                 locations = list(withLoc_df['location'])\n",
    "\n",
    "            tweet = tweets[i]\n",
    "            country_tweets[country].append(tweet)\n",
    "            #print(country,tweet)\n",
    "            flag = 0\n",
    "            \n",
    "        elif word in subcountries:\n",
    "            country = countries[subcountries.index(word)]\n",
    "            \n",
    "            tweet = tweets[i]\n",
    "            country_tweets[country].append(tweet)\n",
    "            #print(country,tweet)\n",
    "            flag = 0\n",
    "            \n",
    "\n",
    "        elif word in citiess:\n",
    "            country = countries[citiess.index(word)]\n",
    "            \n",
    "            tweet = tweets[i]\n",
    "            country_tweets[country].append(tweet)\n",
    "            #print(country,tweet)\n",
    "            flag = 0\n",
    "             \n",
    "        else:\n",
    "            flag = 1\n",
    "        \n",
    "        if flag:\n",
    "            word = words[0].lower()\n",
    "\n",
    "            if word == \"bangalore\":\n",
    "                word = \"bengaluru\"\n",
    "            if word in countries or word in abb1 or word in abb2:\n",
    "              \n",
    "                if word not in countries:\n",
    "                    if word in abb1:\n",
    "                        country = countries[abb1.index(word)]\n",
    "                    else:\n",
    "                        country = countries[abb2.index(word)]\n",
    "                else:\n",
    "                    country = word\n",
    "#                 locations = list(withLoc_df['location'])\n",
    "\n",
    "                tweet = tweets[i]\n",
    "                country_tweets[country].append(tweet)\n",
    "                #print(country,tweet)\n",
    "                flag = 0\n",
    "                \n",
    "            elif word in subcountries:\n",
    "                country = countries[subcountries.index(word)]\n",
    "                \n",
    "                tweet = tweets[i]\n",
    "                country_tweets[country].append(tweet)\n",
    "                #print(country,tweet)\n",
    "                flag = 0\n",
    "                \n",
    "\n",
    "            elif word in citiess:\n",
    "                country = countries[citiess.index(word)]\n",
    "                \n",
    "                tweet = tweets[i]\n",
    "                country_tweets[country].append(tweet)\n",
    "                #print(country,tweet)\n",
    "                flag = 0\n",
    "                  \n",
    "            else:\n",
    "                flag = 1\n",
    "        \n",
    "        if flag:\n",
    "            words = word_tokenize(location)\n",
    "            flag = 0\n",
    "\n",
    "            for w in words:\n",
    "                word = w.lower()\n",
    "                if word == \"bangalore\":\n",
    "                    word = \"bengaluru\"\n",
    "                if word in countries or word in abb1 or word in abb2:\n",
    "                    \n",
    "                    if word not in countries:\n",
    "                        if word in abb1:\n",
    "                            country = countries[abb1.index(word)]\n",
    "                        else:\n",
    "                            country = countries[abb2.index(word)]\n",
    "                    else:\n",
    "                        country = word\n",
    "    #                 locations = list(withLoc_df['location'])\n",
    "\n",
    "                    tweet = tweets[i]\n",
    "#                     print(country,tweet)\n",
    "                    #country_tweets[country].append(tweet)\n",
    "\n",
    "                    flag = 0\n",
    "                    break\n",
    "                elif word in subcountries:\n",
    "                    country = countries[subcountries.index(word)]\n",
    "                    \n",
    "                    tweet = tweets[i]\n",
    "                    country_tweets[country].append(tweet)\n",
    "                    #print(country,tweet)\n",
    "                    flag = 0\n",
    "                    break\n",
    "\n",
    "                elif word in citiess:\n",
    "                    country = countries[citiess.index(word)]\n",
    "                    \n",
    "                    tweet = tweets[i]\n",
    "                    country_tweets[country].append(tweet)\n",
    "                    #print(country,tweet)\n",
    "                    flag = 0\n",
    "                    break  \n",
    "                else:\n",
    "                    flag = 1\n",
    "\n",
    "            if flag:\n",
    "                country = location + \"(not in csv)\"\n",
    "                if country not in country_tweets:\n",
    "                    country_tweets[country] = list()\n",
    "                tweet = tweets[i]\n",
    "                country_tweets[country].append(tweet)\n",
    "                #print(country,tweet)\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "getCountryTweets()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6655"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(country_tweets['united kingdom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anguilla\n",
      "aland islands\n",
      "saint barthelemy\n",
      "bonaire, saint eustatius and saba\n",
      "cocos islands\n",
      "christmas island\n",
      "micronesia\n",
      "grenada\n",
      "french guiana\n",
      "south georgia and the south sandwich islands\n",
      "kiribati\n",
      "comoros\n",
      "laos\n",
      "saint martin\n",
      "madagascar\n",
      "martinique\n",
      "mauritania\n",
      "mauritius\n",
      "norfolk island\n",
      "nauru\n",
      "niue\n",
      "saint pierre and miquelon\n",
      "pitcairn\n",
      "palau\n",
      "reunion\n",
      "solomon islands\n",
      "san marino\n",
      "sao tome and principe\n",
      "sint maarten\n",
      "turks and caicos islands\n",
      "french southern territories\n",
      "tuvalu\n",
      "saint vincent and the grenadines\n",
      "vanuatu\n",
      "wallis and futuna\n",
      "kosovo\n",
      "mayotte\n"
     ]
    }
   ],
   "source": [
    "for key,value in country_tweets.items():\n",
    "    if len(value) > 0:\n",
    "        if \"(not in csv)\" not in key:\n",
    "            file = open(\"Countries_TweetsJanFebAprilMayJune/\"+key+'.csv', 'w+', newline ='') \n",
    "            data = [[tweet] for tweet in value]\n",
    "            # writing the data into the file \n",
    "            with file:     \n",
    "                write = csv.writer(file) \n",
    "                write.writerows(data) \n",
    "    else:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in country_tweets.items():\n",
    "    if \"(not in csv)\" in key:\n",
    "        name = key.split('/')\n",
    "        name = ' '.join(name)\n",
    "        file = open(\"CountriesUnknown_TweetsJanFebAprilMayJune/\"+name+'.csv', 'w+', newline ='') \n",
    "        data = [[tweet] for tweet in value]\n",
    "        # writing the data into the file \n",
    "        with file:     \n",
    "            write = csv.writer(file) \n",
    "            write.writerows(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "June_df = pd.read_csv('tweets_with_loc_June.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(June_df['location'].isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
