{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import treebank\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('deceptive-opinion.csv')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"was'nt\") in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df,test_size):\n",
    "    if isinstance(test_size,float):\n",
    "        test_size = round(test_size * len(df))\n",
    "        \n",
    "    if(test_size > len(df)):\n",
    "        return 0, df\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices,k = test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df\n",
    "train_df,test_df = train_test_split(dataset,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vaderSentimentValue(review):\n",
    "    sid_obj =  SentimentIntensityAnalyzer()\n",
    "    \n",
    "    sentiment_dict = sid_obj.polarity_scores(review)\n",
    "    return sentiment_dict['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words_list = set(opinion_lexicon.positive())\n",
    "negative_words_list = set(opinion_lexicon.negative())\n",
    "tokenizer = treebank.TreebankWordTokenizer()\n",
    "def getSentimentValue(review):\n",
    "    senti = 0\n",
    "    words = [word.lower() for word in tokenizer.tokenize(review)]\n",
    "    for word in words:\n",
    "        if word in positive_words_list:\n",
    "            senti += 1\n",
    "        elif word in negative_words_list:\n",
    "            senti -= 1\n",
    "    return senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_vocab = {}\n",
    "notfake_vocab = {}\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('bad.n.01.badness')"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(wn.synsets(\"bad\")[0]).lemmas()[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(dataset)):\n",
    "    review = dataset['text'][i]\n",
    "    words = word_tokenize(review)\n",
    "    for word in words:\n",
    "        if word.lower() not in stop_words and len(word) != 1:\n",
    "            if dataset['deceptive'][i] == \"truthful\":\n",
    "                if lemmatizer.lemmatize(word.lower()) not in notfake_vocab:\n",
    "                    notfake_vocab[lemmatizer.lemmatize(word.lower())] = 1\n",
    "                    for synset in wn.synsets(lemmatizer.lemmatize(word.lower())):\n",
    "                        for lemma in synset.lemmas():\n",
    "                            if lemma.name() not in notfake_vocab:\n",
    "                                notfake_vocab[lemma.name()] = 1\n",
    "                            else:\n",
    "                                notfake_vocab[lemma.name()] += 1\n",
    "                else:\n",
    "                    notfake_vocab[lemmatizer.lemmatize(word.lower())] += 1\n",
    "                    for synset in wn.synsets(lemmatizer.lemmatize(word.lower())):\n",
    "                        for lemma in synset.lemmas():\n",
    "                            if lemma.name() not in notfake_vocab:\n",
    "                                notfake_vocab[lemma.name()] = 1\n",
    "                            else:\n",
    "                                notfake_vocab[lemma.name()] += 1\n",
    "            elif lemmatizer.lemmatize(word.lower()) not in fake_vocab:\n",
    "                fake_vocab[lemmatizer.lemmatize(word.lower())] = 1\n",
    "                for synset in wn.synsets(lemmatizer.lemmatize(word.lower())):\n",
    "                        for lemma in synset.lemmas():\n",
    "                            if lemma.name() not in fake_vocab:\n",
    "                                fake_vocab[lemma.name()] = 1\n",
    "                            else:\n",
    "                                fake_vocab[lemma.name()] += 1\n",
    "            else:\n",
    "                fake_vocab[lemmatizer.lemmatize(word.lower())] += 1\n",
    "                for synset in wn.synsets(lemmatizer.lemmatize(word.lower())):\n",
    "                        for lemma in synset.lemmas():\n",
    "                            if lemma.name() not in fake_vocab:\n",
    "                                fake_vocab[lemma.name()] = 1\n",
    "                            else:\n",
    "                                fake_vocab[lemma.name()] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stayed': 349,\n",
       " 'one': 366,\n",
       " 'night': 434,\n",
       " 'getaway': 14,\n",
       " 'family': 50,\n",
       " 'thursday': 5,\n",
       " 'triple': 3,\n",
       " 'aaa': 3,\n",
       " 'rate': 104,\n",
       " '173': 1,\n",
       " 'steal': 5,\n",
       " '7th': 5,\n",
       " 'floor': 229,\n",
       " 'room': 1716,\n",
       " 'complete': 16,\n",
       " '44in': 1,\n",
       " 'plasma': 12,\n",
       " 'tv': 82,\n",
       " 'bose': 4,\n",
       " 'stereo': 2,\n",
       " 'voss': 1,\n",
       " 'evian': 2,\n",
       " 'water': 118,\n",
       " 'gorgeous': 15,\n",
       " 'bathroom': 254,\n",
       " 'tub': 49,\n",
       " 'fine': 33,\n",
       " 'u': 339,\n",
       " 'concierge': 90,\n",
       " 'helpful': 140,\n",
       " 'beat': 18,\n",
       " 'location': 355,\n",
       " '...': 313,\n",
       " 'flaw': 2,\n",
       " 'breakfast': 170,\n",
       " 'pricey': 11,\n",
       " 'service': 397,\n",
       " 'slow': 32,\n",
       " '2hours': 1,\n",
       " 'four': 40,\n",
       " 'kid': 21,\n",
       " 'adult': 13,\n",
       " 'friday': 7,\n",
       " 'morning': 120,\n",
       " 'even': 228,\n",
       " 'though': 81,\n",
       " 'two': 192,\n",
       " 'table': 27,\n",
       " 'restaurant': 181,\n",
       " 'food': 87,\n",
       " 'good': 253,\n",
       " 'worth': 57,\n",
       " 'wait': 59,\n",
       " 'would': 483,\n",
       " 'return': 49,\n",
       " 'heartbeat': 2,\n",
       " 'gem': 5,\n",
       " 'chicago': 484,\n",
       " 'upgrade': 35,\n",
       " 'view': 199,\n",
       " 'le': 40,\n",
       " '200': 14,\n",
       " 'also': 222,\n",
       " 'included': 26,\n",
       " 'voucher': 5,\n",
       " 'great': 545,\n",
       " 'river': 64,\n",
       " 'lake': 43,\n",
       " 'wrigley': 5,\n",
       " 'bldg': 2,\n",
       " 'tribune': 7,\n",
       " 'major': 23,\n",
       " 'shopping': 88,\n",
       " 'sightseeing': 9,\n",
       " 'attraction': 17,\n",
       " 'within': 60,\n",
       " 'walking': 82,\n",
       " 'distance': 63,\n",
       " 'large': 105,\n",
       " 'comfortable': 176,\n",
       " 'bed': 371,\n",
       " 'come': 65,\n",
       " 'little': 91,\n",
       " 'late': 50,\n",
       " \"'m\": 60,\n",
       " 'finally': 53,\n",
       " 'catching': 2,\n",
       " 'review': 106,\n",
       " 'past': 27,\n",
       " 'several': 57,\n",
       " 'month': 22,\n",
       " 'dear': 3,\n",
       " 'friend': 59,\n",
       " 'hyatt': 46,\n",
       " 'regency': 8,\n",
       " 'october': 5,\n",
       " '2007': 8,\n",
       " 'visiting': 20,\n",
       " 'husband': 62,\n",
       " 'town': 33,\n",
       " 'hotel': 1651,\n",
       " 'perfect': 61,\n",
       " 'imo': 2,\n",
       " 'easy': 43,\n",
       " 'check': 124,\n",
       " 'lovely': 39,\n",
       " 'clean': 210,\n",
       " 'city': 120,\n",
       " 'know': 61,\n",
       " 'area': 143,\n",
       " 'pretty': 38,\n",
       " 'well': 173,\n",
       " \"'s\": 328,\n",
       " 'convenient': 32,\n",
       " 'many': 112,\n",
       " 'downtown': 79,\n",
       " 'dinner': 49,\n",
       " 'went': 88,\n",
       " 'clubing': 1,\n",
       " 'around': 85,\n",
       " 'division': 4,\n",
       " 'st..': 1,\n",
       " 'problem': 100,\n",
       " 'getting': 38,\n",
       " 'cab': 47,\n",
       " 'back': 182,\n",
       " 'forth': 4,\n",
       " 'public': 20,\n",
       " 'transportation': 13,\n",
       " 'right': 105,\n",
       " 'near': 39,\n",
       " \"n't\": 569,\n",
       " 'bother': 13,\n",
       " 'since': 68,\n",
       " 'needed': 36,\n",
       " 'parking': 78,\n",
       " 'usual': 10,\n",
       " 'expensive': 42,\n",
       " 'able': 56,\n",
       " 'get': 285,\n",
       " 'car': 55,\n",
       " 'quickly': 17,\n",
       " 'however': 72,\n",
       " 'left': 72,\n",
       " 'sunday': 19,\n",
       " 'exactly': 10,\n",
       " 'high': 56,\n",
       " 'traffic': 9,\n",
       " 'time': 282,\n",
       " 'although': 54,\n",
       " 'bear': 3,\n",
       " 'homegame': 1,\n",
       " 'day': 244,\n",
       " 'bit': 75,\n",
       " 'busier': 1,\n",
       " 'think': 79,\n",
       " 'best': 104,\n",
       " 'part': 50,\n",
       " 'got': 206,\n",
       " '100': 19,\n",
       " 'hotwire': 15,\n",
       " 'downright': 1,\n",
       " 'quality': 47,\n",
       " 'omni': 45,\n",
       " 'really': 155,\n",
       " 'delivers': 2,\n",
       " 'front': 202,\n",
       " 'spaciousness': 1,\n",
       " 'staff': 437,\n",
       " 'prized': 1,\n",
       " 'michigan': 136,\n",
       " 'avenue': 43,\n",
       " 'address': 5,\n",
       " 'requires': 1,\n",
       " 'level': 26,\n",
       " 'whole': 23,\n",
       " 'group': 18,\n",
       " 'people': 110,\n",
       " 'minute': 121,\n",
       " 'plentiful': 3,\n",
       " 'recommendation': 10,\n",
       " 'dining': 19,\n",
       " 'event': 18,\n",
       " 'largest': 6,\n",
       " \"'ll\": 33,\n",
       " 'find': 79,\n",
       " 'price': 133,\n",
       " 'range': 6,\n",
       " \"'standard\": 1,\n",
       " 'separate': 23,\n",
       " 'living': 14,\n",
       " 'work': 89,\n",
       " 'desk': 260,\n",
       " 'fitness': 26,\n",
       " 'center': 38,\n",
       " 'free': 138,\n",
       " 'weight': 5,\n",
       " 'machine': 21,\n",
       " 'row': 4,\n",
       " 'cardio': 2,\n",
       " 'equipment': 6,\n",
       " 'shared': 5,\n",
       " 'others': 32,\n",
       " 'feel': 67,\n",
       " 'cramped': 12,\n",
       " 'way': 92,\n",
       " 'property': 51,\n",
       " 'asked': 107,\n",
       " 'away': 94,\n",
       " 'elevator': 115,\n",
       " 'pleasantly': 8,\n",
       " 'decorated': 23,\n",
       " 'functional': 3,\n",
       " 'need': 91,\n",
       " 'lot': 85,\n",
       " 'pleasant': 30,\n",
       " 'prompt': 7,\n",
       " 'used': 54,\n",
       " 'equipped': 6,\n",
       " 'everything': 108,\n",
       " 'working': 33,\n",
       " 'order': 31,\n",
       " 'end': 38,\n",
       " 'district': 6,\n",
       " 'following': 10,\n",
       " 'business': 125,\n",
       " 'meeting': 22,\n",
       " 'another': 102,\n",
       " 'completely': 23,\n",
       " 'impressed': 34,\n",
       " 'personnel': 6,\n",
       " 'stay': 610,\n",
       " 'absolutely': 38,\n",
       " 'outstanding': 9,\n",
       " 'checked': 74,\n",
       " 'quite': 76,\n",
       " 'early': 42,\n",
       " 'efficiently': 1,\n",
       " 'somewhat': 13,\n",
       " 'heavy': 6,\n",
       " 'scent': 2,\n",
       " 'air': 34,\n",
       " 'freshener': 1,\n",
       " 'negative': 24,\n",
       " 'entire': 29,\n",
       " 'managed': 4,\n",
       " 'reasonably': 7,\n",
       " 'opening': 9,\n",
       " 'window': 78,\n",
       " 'generally': 14,\n",
       " 'require': 2,\n",
       " 'much': 129,\n",
       " 'suffice': 2,\n",
       " 'say': 103,\n",
       " 'doorman': 47,\n",
       " 'housekeeping': 48,\n",
       " 'manager': 78,\n",
       " 'bartender': 11,\n",
       " '676': 3,\n",
       " 'waiter': 10,\n",
       " 'amazing': 37,\n",
       " 'never': 163,\n",
       " 'waited': 20,\n",
       " '30': 25,\n",
       " 'second': 59,\n",
       " 'anything': 44,\n",
       " 'comfy': 25,\n",
       " 'amenity': 44,\n",
       " 'superior': 9,\n",
       " 'tiny': 44,\n",
       " 'complaint': 36,\n",
       " 'wastebasket': 3,\n",
       " 'sink': 23,\n",
       " 'wet': 6,\n",
       " 'bar': 149,\n",
       " 'walk': 98,\n",
       " 'sitting': 18,\n",
       " 'dispose': 1,\n",
       " 'kleenex/coffee': 1,\n",
       " 'paraphernalia': 1,\n",
       " 'make': 98,\n",
       " 'difference': 9,\n",
       " 'said': 99,\n",
       " 'thanks': 12,\n",
       " 'conrad': 39,\n",
       " 'thanksgiving': 3,\n",
       " 'corner': 45,\n",
       " 'overlooking': 6,\n",
       " 'av': 3,\n",
       " 'building': 59,\n",
       " 'star': 72,\n",
       " 'damn': 3,\n",
       " 'place': 184,\n",
       " 'faint': 1,\n",
       " 'praise': 1,\n",
       " 'wonderful': 94,\n",
       " 'unbelievably': 1,\n",
       " 'standard': 25,\n",
       " 'superb': 17,\n",
       " 'hd': 3,\n",
       " 'screen': 25,\n",
       " 'luxury': 9,\n",
       " 'bedlinens': 1,\n",
       " 'ipod': 10,\n",
       " 'radio': 6,\n",
       " 'huge': 62,\n",
       " 'unbeatable': 3,\n",
       " 'heart': 12,\n",
       " 'watched': 6,\n",
       " 'light': 29,\n",
       " 'festival': 5,\n",
       " 'parade': 2,\n",
       " 'excellent': 110,\n",
       " 'help': 38,\n",
       " 'buffet': 30,\n",
       " 'full': 54,\n",
       " 'attentive': 18,\n",
       " 'hesitation': 7,\n",
       " 'recommending': 1,\n",
       " 'staying': 91,\n",
       " 'girlfriend': 8,\n",
       " 'first': 160,\n",
       " 'saw': 37,\n",
       " '129.00': 1,\n",
       " '25.00': 2,\n",
       " 'travelzoo': 11,\n",
       " 'three': 55,\n",
       " '55': 3,\n",
       " 'year': 98,\n",
       " 'old': 90,\n",
       " 'suite': 114,\n",
       " 'double': 40,\n",
       " 'pull': 12,\n",
       " 'sofa': 22,\n",
       " 'plenty': 26,\n",
       " 'everone': 1,\n",
       " 'came': 78,\n",
       " 'contact': 8,\n",
       " 'delivery': 5,\n",
       " 'coffee': 97,\n",
       " 'juice': 10,\n",
       " 'hot': 47,\n",
       " 'chocolate': 14,\n",
       " 'fabulous': 26,\n",
       " 'eat': 31,\n",
       " 'movie': 10,\n",
       " 'etc': 58,\n",
       " 'mention': 13,\n",
       " 'simply': 22,\n",
       " 'decided': 41,\n",
       " 'new': 65,\n",
       " 'favorite': 15,\n",
       " 'arrived': 99,\n",
       " '2nd': 7,\n",
       " 'september': 9,\n",
       " 'took': 81,\n",
       " 'ill': 2,\n",
       " 'plane': 2,\n",
       " 'travelling': 5,\n",
       " 'manchester': 1,\n",
       " 'anticipated': 3,\n",
       " 'could': 262,\n",
       " 'go': 163,\n",
       " 'spacious': 64,\n",
       " 'extremely': 63,\n",
       " 'ask': 28,\n",
       " 'outside': 40,\n",
       " 'door': 143,\n",
       " 'every': 93,\n",
       " 'requested': 51,\n",
       " '5th': 12,\n",
       " 'see': 62,\n",
       " 'sun': 4,\n",
       " 'terrace': 7,\n",
       " 'gym': 31,\n",
       " 'idea': 11,\n",
       " 'grim': 1,\n",
       " 'sunbeds': 1,\n",
       " 'concrete': 5,\n",
       " 'noise': 71,\n",
       " 'conditioning': 7,\n",
       " 'unit': 7,\n",
       " 'cheering': 1,\n",
       " 'pleasing': 4,\n",
       " 'something': 47,\n",
       " 'everyone': 44,\n",
       " 'yes': 27,\n",
       " 'visit': 52,\n",
       " 'chose': 21,\n",
       " 'due': 23,\n",
       " 'sears': 5,\n",
       " 'tower': 66,\n",
       " 'magnificent': 41,\n",
       " 'mile': 71,\n",
       " 'grant/millenium': 1,\n",
       " 'park': 65,\n",
       " 'subway': 12,\n",
       " 'bus': 16,\n",
       " 'stop': 27,\n",
       " 'close': 96,\n",
       " 'travel': 55,\n",
       " 'overall': 62,\n",
       " 'nice': 282,\n",
       " 'safe': 17,\n",
       " 'beautiful': 86,\n",
       " 'field': 9,\n",
       " 'soldier': 4,\n",
       " 'team': 5,\n",
       " 'play': 5,\n",
       " 'love': 42,\n",
       " 'defenitely': 1,\n",
       " 'fairmont': 42,\n",
       " 'frequent': 12,\n",
       " 'traveler': 24,\n",
       " 'familiar': 1,\n",
       " 'ritual': 1,\n",
       " 'almost': 44,\n",
       " '10pm': 2,\n",
       " 'flight': 13,\n",
       " 'cancellation': 9,\n",
       " 'home': 52,\n",
       " 'airport': 23,\n",
       " '--': 149,\n",
       " 'atlanta': 1,\n",
       " 'shuttle': 8,\n",
       " 'option': 27,\n",
       " 'lieu': 1,\n",
       " 'priced': 7,\n",
       " 'taxi': 17,\n",
       " 'upon': 52,\n",
       " 'arrival': 31,\n",
       " 'immediately': 29,\n",
       " 'noticed': 19,\n",
       " 'entrance': 17,\n",
       " 'appeared': 15,\n",
       " 'welcoming': 12,\n",
       " 'warm': 25,\n",
       " 'person': 51,\n",
       " \"'d\": 52,\n",
       " 'prefer': 10,\n",
       " 'king': 73,\n",
       " 'reconfirming': 1,\n",
       " 'reservation': 120,\n",
       " 'preference': 5,\n",
       " 'always': 66,\n",
       " 'take': 104,\n",
       " 'fantastic': 42,\n",
       " 'suited': 3,\n",
       " 'linen': 23,\n",
       " 'incredible': 14,\n",
       " 'feather': 4,\n",
       " 'pillow': 53,\n",
       " 'named': 6,\n",
       " 'encompass': 1,\n",
       " 'made': 127,\n",
       " 'factory': 4,\n",
       " 'tag': 4,\n",
       " 'plan': 19,\n",
       " 'buy': 6,\n",
       " 'ate': 17,\n",
       " 'aria': 8,\n",
       " 'like': 228,\n",
       " 'considered': 5,\n",
       " 'stand': 11,\n",
       " 'asian': 2,\n",
       " 'fusion': 1,\n",
       " 'truly': 21,\n",
       " 'gourmand': 1,\n",
       " 'life-long': 1,\n",
       " 'foodie': 1,\n",
       " 'appreciate': 6,\n",
       " 'taste': 7,\n",
       " 'drawback': 3,\n",
       " 'seems': 19,\n",
       " 'stick': 2,\n",
       " 'theme': 5,\n",
       " 'solely': 2,\n",
       " 'missed': 9,\n",
       " 'mark': 6,\n",
       " 'relatively': 5,\n",
       " 'thing': 107,\n",
       " 'scrambled': 1,\n",
       " 'egg': 8,\n",
       " 'tasted': 6,\n",
       " \"'metallic\": 1,\n",
       " 'special': 35,\n",
       " 'passed': 5,\n",
       " 'highly': 51,\n",
       " 'recommend': 116,\n",
       " 'atmosphere': 13,\n",
       " 'pas': 7,\n",
       " 'ok': 34,\n",
       " 'trip': 101,\n",
       " 'litlle': 1,\n",
       " 'worried': 7,\n",
       " 'wath': 1,\n",
       " 'experience': 118,\n",
       " 'booked': 134,\n",
       " 'deluxe': 7,\n",
       " '6th': 10,\n",
       " 'coplaint': 1,\n",
       " 'bath': 30,\n",
       " 'appliance': 2,\n",
       " 'size': 55,\n",
       " 'internet': 87,\n",
       " 'breaksfast': 1,\n",
       " 'aroufn': 1,\n",
       " '220': 1,\n",
       " 'surprise': 13,\n",
       " 'locating': 1,\n",
       " 'block': 86,\n",
       " 'quiet': 63,\n",
       " '10:30': 2,\n",
       " 'ready': 30,\n",
       " '11:30': 2,\n",
       " 'mind': 16,\n",
       " '3:00pm': 1,\n",
       " 'priceline': 44,\n",
       " '65.00': 1,\n",
       " 'per': 42,\n",
       " 'upgraded': 30,\n",
       " 'blown': 5,\n",
       " 'forgot': 7,\n",
       " 'thank': 17,\n",
       " 'check-in': 62,\n",
       " 'fridge': 19,\n",
       " 'sized': 14,\n",
       " 'closet': 38,\n",
       " 'hanger': 3,\n",
       " 'knew': 18,\n",
       " 'previous': 21,\n",
       " 'touch': 31,\n",
       " 'mini-bar': 7,\n",
       " 'employee': 35,\n",
       " 'friendly': 169,\n",
       " '25th': 4,\n",
       " 'east': 28,\n",
       " 'hear': 53,\n",
       " 'hallway': 38,\n",
       " 'rude': 49,\n",
       " 'yelling': 6,\n",
       " 'child': 15,\n",
       " 'complains': 1,\n",
       " '48': 4,\n",
       " 'charged': 39,\n",
       " 'without': 58,\n",
       " 'in/out': 2,\n",
       " 'privledges': 1,\n",
       " 'use': 77,\n",
       " 'health': 7,\n",
       " 'club': 31,\n",
       " 'tried': 35,\n",
       " 'bakery': 3,\n",
       " 'crowded': 6,\n",
       " 'nearby': 24,\n",
       " 'houlihan': 1,\n",
       " '9.99': 2,\n",
       " 'grocery': 5,\n",
       " 'store': 17,\n",
       " 'behind': 17,\n",
       " '7-11': 3,\n",
       " 'far': 33,\n",
       " 'bad': 72,\n",
       " 'big': 62,\n",
       " 'want': 82,\n",
       " 'busy': 18,\n",
       " 'lobby': 174,\n",
       " '2,000': 1,\n",
       " 'plus': 30,\n",
       " 'loved': 65,\n",
       " 'anyone': 36,\n",
       " 'wife': 60,\n",
       " 'spend': 15,\n",
       " 'weekend': 99,\n",
       " 'found': 88,\n",
       " 'located': 48,\n",
       " 'lost': 21,\n",
       " 'convention': 18,\n",
       " 'world': 15,\n",
       " 'feeling': 15,\n",
       " 'larger': 19,\n",
       " 'professional': 15,\n",
       " 'making': 25,\n",
       " '50': 13,\n",
       " 'priceline.com': 4,\n",
       " 'hard': 66,\n",
       " 'complain': 18,\n",
       " 'paid': 70,\n",
       " 'impression': 8,\n",
       " 'sliding': 4,\n",
       " 'wow': 9,\n",
       " 'upscale': 12,\n",
       " 'mall': 11,\n",
       " 'type': 16,\n",
       " 'look': 64,\n",
       " 'open': 70,\n",
       " 'couch': 16,\n",
       " 'seat': 14,\n",
       " 'watch': 9,\n",
       " 'fountain': 4,\n",
       " 'escalator': 1,\n",
       " 'concierge/directory/check': 1,\n",
       " 'let': 45,\n",
       " '12pm': 1,\n",
       " '3pm': 4,\n",
       " 'suggest': 4,\n",
       " 'call': 111,\n",
       " 'ahead': 8,\n",
       " 'coming': 22,\n",
       " 'early.the': 1,\n",
       " 'woman': 18,\n",
       " 'higher': 15,\n",
       " 'happy': 29,\n",
       " 'told': 131,\n",
       " '18th': 2,\n",
       " 'veiw': 1,\n",
       " 'thought': 47,\n",
       " 'give': 48,\n",
       " 'information': 12,\n",
       " 'wouldnt': 4,\n",
       " 'stuck': 13,\n",
       " 'wall': 85,\n",
       " 'blanket': 16,\n",
       " 'headboard': 2,\n",
       " 'alarm': 5,\n",
       " 'clock': 5,\n",
       " '21st': 3,\n",
       " 'century': 3,\n",
       " 'plug': 3,\n",
       " 'listen': 4,\n",
       " 'music': 20,\n",
       " 'relaxing': 11,\n",
       " 'long': 64,\n",
       " 'touring': 3,\n",
       " 'spotless': 8,\n",
       " 'toiletry': 12,\n",
       " 'feature': 10,\n",
       " 'computer': 12,\n",
       " 'access': 44,\n",
       " 'printing': 4,\n",
       " 'boarding': 6,\n",
       " 'click': 1,\n",
       " 'airline': 7,\n",
       " 'icon': 1,\n",
       " 'instruction': 2,\n",
       " 'pass': 8,\n",
       " 'handy': 7,\n",
       " 'ohare': 2,\n",
       " 'skip': 2,\n",
       " 'line': 65,\n",
       " 'frustrated': 5,\n",
       " 'passenger': 2,\n",
       " 'better': 131,\n",
       " 'alot': 3,\n",
       " 'definitely': 81,\n",
       " 'choice': 35,\n",
       " 'couple': 39,\n",
       " 'im': 4,\n",
       " 'passing': 3,\n",
       " 'including': 33,\n",
       " 'luxurious': 12,\n",
       " 'complimentary': 38,\n",
       " 'hilton': 60,\n",
       " 'honor': 16,\n",
       " 'member': 30,\n",
       " 'connected': 6,\n",
       " 'imagine': 13,\n",
       " 'asset': 1,\n",
       " 'winter': 7,\n",
       " 'next': 152,\n",
       " 'sure': 53,\n",
       " 'reunion': 2,\n",
       " 'bottled': 5,\n",
       " 'breeze': 5,\n",
       " 'hour': 94,\n",
       " 'please': 14,\n",
       " 'aesthetically': 1,\n",
       " 'date': 11,\n",
       " 'attached': 15,\n",
       " 'nordstrom': 4,\n",
       " 'northbridge': 1,\n",
       " 'ca': 57,\n",
       " 'boyfriend': 11,\n",
       " 'anniversary': 16,\n",
       " 'walked': 36,\n",
       " 'white': 20,\n",
       " 'luxurous': 1,\n",
       " 'bedding': 15,\n",
       " 't.v./': 1,\n",
       " 'subroofer/': 1,\n",
       " 'surround': 1,\n",
       " 'sound': 20,\n",
       " 'speaker': 5,\n",
       " 'reminded': 3,\n",
       " 'w/': 6,\n",
       " 'stand-in': 1,\n",
       " 'shower': 104,\n",
       " 'granite': 2,\n",
       " 'countertop': 2,\n",
       " 'his/': 1,\n",
       " 'robe': 11,\n",
       " 'slipper': 8,\n",
       " 'enough': 58,\n",
       " 'side': 42,\n",
       " 'mean': 13,\n",
       " 'prefect': 1,\n",
       " 'amount': 12,\n",
       " 'actually': 42,\n",
       " '140': 1,\n",
       " 'hotels.com': 3,\n",
       " 'going': 75,\n",
       " 'usually': 18,\n",
       " 'closer': 9,\n",
       " 'mid': 3,\n",
       " \"'ve\": 87,\n",
       " 'none': 13,\n",
       " 'ever': 69,\n",
       " 'deal': 70,\n",
       " 'pacage': 1,\n",
       " 'nicest': 4,\n",
       " 'dozen': 6,\n",
       " 'extra': 55,\n",
       " 'turn': 29,\n",
       " 'beverage': 9,\n",
       " 'delivered': 26,\n",
       " 'attended': 12,\n",
       " 'intruded': 1,\n",
       " 'definately': 15,\n",
       " 'given': 46,\n",
       " 'central': 9,\n",
       " 'wished': 1,\n",
       " 'pool': 72,\n",
       " 'felt': 55,\n",
       " 'swim': 8,\n",
       " 'evening': 35,\n",
       " 'spent': 35,\n",
       " 'recommended': 19,\n",
       " 'base': 8,\n",
       " 'exploring': 3,\n",
       " 'exhibit': 3,\n",
       " 'art': 29,\n",
       " 'institute': 11,\n",
       " 'selected': 3,\n",
       " 'still': 84,\n",
       " 'renovated': 19,\n",
       " 'uniformly': 2,\n",
       " 'positive': 16,\n",
       " 'nicely': 12,\n",
       " 'newly': 4,\n",
       " 'remodeled': 3,\n",
       " 'immaculate': 8,\n",
       " 'glitch': 2,\n",
       " 'involved': 3,\n",
       " 'replenished': 5,\n",
       " 'maid': 22,\n",
       " 'bedtime': 1,\n",
       " 'called': 147,\n",
       " 'fresh': 23,\n",
       " 'supply': 7,\n",
       " 'underwhelming': 3,\n",
       " 'probably': 22,\n",
       " 'eaten': 4,\n",
       " 'different': 48,\n",
       " 'may': 35,\n",
       " 'whenever': 1,\n",
       " 'phone': 82,\n",
       " 'lower': 13,\n",
       " 'beautifully': 5,\n",
       " 'appointed': 20,\n",
       " 'wanted': 35,\n",
       " '50.00': 2,\n",
       " 'buck': 8,\n",
       " 'crisp': 3,\n",
       " 'sheet': 33,\n",
       " 'flat': 22,\n",
       " 'carpet': 35,\n",
       " 'short': 35,\n",
       " 'prepared': 8,\n",
       " 'pay': 54,\n",
       " '40.00': 1,\n",
       " 'hey': 1,\n",
       " 'charge': 87,\n",
       " '5.00': 2,\n",
       " 'bottle': 36,\n",
       " 'normally': 10,\n",
       " 'total': 10,\n",
       " '100.00': 1,\n",
       " 'nightly': 4,\n",
       " 'drink': 54,\n",
       " 'fast': 11,\n",
       " 'big-city': 1,\n",
       " 'imaginable': 1,\n",
       " 'one-night': 1,\n",
       " 'money': 56,\n",
       " 'exorbitant': 3,\n",
       " 'absurd': 2,\n",
       " 'fee': 19,\n",
       " 'wireless': 19,\n",
       " 'bored': 3,\n",
       " 'routine': 2,\n",
       " 'fare': 6,\n",
       " 'gourmet': 4,\n",
       " 'pantry': 2,\n",
       " '155': 2,\n",
       " 'n.': 4,\n",
       " 'refreshing': 3,\n",
       " 'change': 29,\n",
       " '06/04/05': 1,\n",
       " 'greeted': 21,\n",
       " 'zipped': 1,\n",
       " 'reception': 46,\n",
       " '12th': 2,\n",
       " 'restful': 3,\n",
       " 'sleep': 42,\n",
       " 'glass': 21,\n",
       " 'stall': 3,\n",
       " 'furnished': 12,\n",
       " 'hook-up': 1,\n",
       " 'thru': 15,\n",
       " 'fl': 1,\n",
       " 'westfield': 1,\n",
       " 'north': 31,\n",
       " 'bridge': 2,\n",
       " 'enjoy': 21,\n",
       " 'course': 22,\n",
       " \"'re\": 55,\n",
       " 'step': 9,\n",
       " 'ave.': 21,\n",
       " 'cta': 5,\n",
       " 'grand': 3,\n",
       " 'red': 21,\n",
       " 'helped': 9,\n",
       " 'print': 6,\n",
       " 'frustrating': 5,\n",
       " 'nowadays': 1,\n",
       " 'loud': 22,\n",
       " 'neighbor': 8,\n",
       " 'liked': 18,\n",
       " 'longer': 16,\n",
       " '9th': 5,\n",
       " 'super': 27,\n",
       " 'system': 21,\n",
       " 'ihome': 1,\n",
       " 'bring': 25,\n",
       " 'week': 69,\n",
       " 'pleased': 20,\n",
       " 'described': 2,\n",
       " 'televison': 1,\n",
       " 'particularly': 11,\n",
       " 'especially': 43,\n",
       " 'bedside': 3,\n",
       " 'bellmen/women': 1,\n",
       " 'knowledgeable': 5,\n",
       " 'satisfactory': 1,\n",
       " 'overpriced': 20,\n",
       " 'maintained': 6,\n",
       " 'treadmill': 8,\n",
       " 'elipitical': 1,\n",
       " 'stepper': 1,\n",
       " 'might': 31,\n",
       " 'story': 10,\n",
       " 'dead': 4,\n",
       " 'minor': 10,\n",
       " 'quibble': 1,\n",
       " 'in-room': 16,\n",
       " 'maker': 14,\n",
       " 'offered': 34,\n",
       " \"'to-go\": 1,\n",
       " 'eight': 1,\n",
       " 'attractive': 9,\n",
       " 'reasonable': 18,\n",
       " 'value': 29,\n",
       " '45/night': 1,\n",
       " 'wrong': 21,\n",
       " 'contain': 2,\n",
       " 'amenties': 1,\n",
       " 'fallen': 6,\n",
       " 'chain': 18,\n",
       " 'customer': 63,\n",
       " 'often': 18,\n",
       " 'self-check': 1,\n",
       " 'smoothly': 2,\n",
       " 'changed': 15,\n",
       " 'small': 161,\n",
       " 'indoors': 2,\n",
       " 'website': 35,\n",
       " 'saks': 2,\n",
       " 'nordstroms': 3,\n",
       " 'filenes': 1,\n",
       " 'basement': 6,\n",
       " 'macys': 3,\n",
       " 'la': 6,\n",
       " 'perla': 1,\n",
       " 'apple': 2,\n",
       " 'bloomingdates': 1,\n",
       " '..i': 1,\n",
       " 'wi-fi': 17,\n",
       " 'clicked': 1,\n",
       " 'joining': 2,\n",
       " 'guest': 120,\n",
       " 'program': 15,\n",
       " 'sign-on': 1,\n",
       " 'email': 20,\n",
       " 'completing': 1,\n",
       " 'registration': 7,\n",
       " '214/night': 1,\n",
       " 'terrific': 12,\n",
       " 'junior': 5,\n",
       " 'seen': 15,\n",
       " 'excuse': 9,\n",
       " 'catch': 5,\n",
       " 'served': 15,\n",
       " 'atrium': 1,\n",
       " 'top': 68,\n",
       " 'notch': 15,\n",
       " 'empty': 8,\n",
       " 'shed': 1,\n",
       " 'aquarium': 4,\n",
       " 'waste': 8,\n",
       " 'musium': 1,\n",
       " 'remains': 1,\n",
       " 'tied': 2,\n",
       " 'london': 3,\n",
       " 'favourite': 3,\n",
       " 'keep': 29,\n",
       " 'daughter': 28,\n",
       " 'vacation': 10,\n",
       " 'easily': 15,\n",
       " 'accessible': 7,\n",
       " '2x': 1,\n",
       " 'daily': 10,\n",
       " 'cleaning': 15,\n",
       " 'turndown': 7,\n",
       " 'encountered': 11,\n",
       " 'kind': 27,\n",
       " 'someone': 49,\n",
       " 'greeting': 7,\n",
       " 'smile': 13,\n",
       " 'milk': 6,\n",
       " 'cooky': 5,\n",
       " 'waiting': 33,\n",
       " 'sometimes': 4,\n",
       " 'pushed': 3,\n",
       " 'button': 4,\n",
       " 'shortage': 1,\n",
       " 'conplaint': 1,\n",
       " 'congierge': 1,\n",
       " 'tough': 5,\n",
       " 'shouuld': 1,\n",
       " 'carried': 1,\n",
       " 'plate': 8,\n",
       " 'addition': 10,\n",
       " 'hit': 7,\n",
       " 'changing': 4,\n",
       " 'sunny': 1,\n",
       " '400': 7,\n",
       " 'sq': 3,\n",
       " 'ft.': 2,\n",
       " 'chair': 34,\n",
       " 'shape': 4,\n",
       " 'aspect': 4,\n",
       " 'hesitate': 9,\n",
       " 'nothing': 71,\n",
       " 'miss': 8,\n",
       " 'formula': 1,\n",
       " 'welcomed': 6,\n",
       " 'opposed': 3,\n",
       " 'nuisance': 1,\n",
       " 'number': 18,\n",
       " 'cornered': 1,\n",
       " 'market': 3,\n",
       " 'recently': 39,\n",
       " 'conference': 63,\n",
       " 'updated': 14,\n",
       " 'product': 15,\n",
       " 'pristine': 1,\n",
       " 'downstairs': 21,\n",
       " 'consistently': 3,\n",
       " 'responsive': 2,\n",
       " 'evident': 4,\n",
       " 'well-trained': 1,\n",
       " 'term': 8,\n",
       " 'comfort': 13,\n",
       " 'exceptional': 7,\n",
       " 'single': 10,\n",
       " 'accommodation': 8,\n",
       " 'conveniently': 7,\n",
       " 'situated': 6,\n",
       " 'last': 77,\n",
       " 'evidently': 1,\n",
       " 'popular': 4,\n",
       " 'bright': 11,\n",
       " 'magnificant': 4,\n",
       " 'returned': 45,\n",
       " 'everthing': 1,\n",
       " 'class': 14,\n",
       " 'centre': 10,\n",
       " 'nestled': 1,\n",
       " 'beaten': 2,\n",
       " 'path': 2,\n",
       " ...}"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notfake_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_vocab = sorted(fake_vocab.items(), key = \n",
    "             lambda kv:(-kv[1], kv[0]))   \n",
    "notfake_vocab =sorted(notfake_vocab.items(), key = \n",
    "             lambda kv:(-kv[1], kv[0]))  \n",
    "finalFakeVocab = []\n",
    "finalNotFakeVocab = []\n",
    "for i in range(2000):\n",
    "    finalFakeVocab.append(fake_vocab[i][0])\n",
    "    finalNotFakeVocab.append(notfake_vocab[i][0])\n",
    "fake_vocab = finalFakeVocab\n",
    "notfake_vocab = finalNotFakeVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in notfake_vocab:\n",
    "    for synset in wn.synsets(lemmatizer.lemmatize(word.lower())):\n",
    "                        for lemma in synset.lemmas():\n",
    "                            if lemma.name() not in notfake_vocab:\n",
    "                                notfake_vocab.append(lemma.name())\n",
    "\n",
    "                              \n",
    "\n",
    "for word in fake_vocab:\n",
    "    for synset in wn.synsets(lemmatizer.lemmatize(word.lower())):\n",
    "                        for lemma in synset.lemmas():\n",
    "                            if lemma.name() not in fake_vocab:\n",
    "                                fake_vocab.append(lemma.name())\n",
    "                            \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFakenessValue(review):\n",
    "    senti = 0\n",
    "    words = [word.lower() for word in tokenizer.tokenize(review)]\n",
    "    for word in words:\n",
    "        if lemmatizer.lemmatize(word) in notfake_vocab:\n",
    "            senti += 1\n",
    "        if lemmatizer.lemmatize(word) in fake_vocab:\n",
    "            senti -= 1\n",
    "    return senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['fakescore'] = dataset['text'].apply(getFakenessValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['vader_sent_score'] = dataset['text'].apply(vaderSentimentValue)\n",
    "dataset['sentiment_score'] = dataset['text'].apply(getSentimentValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceptive</th>\n",
       "      <th>hotel</th>\n",
       "      <th>polarity</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>fakescore</th>\n",
       "      <th>vader_sent_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>true_label</th>\n",
       "      <th>index</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>truthful</td>\n",
       "      <td>conrad</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>We stayed for a one night getaway with family ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9297</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>Triple A rate with upgrade to view room was le...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>This comes a little late as I'm finally catchi...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>truthful</td>\n",
       "      <td>omni</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9564</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>I asked for a high floor away from the elevato...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>deceptive</td>\n",
       "      <td>intercontinental</td>\n",
       "      <td>negative</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>Problems started when I booked the InterContin...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.7312</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1595</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>deceptive</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>negative</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>The Amalfi Hotel has a beautiful website and i...</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.9788</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>deceptive</td>\n",
       "      <td>intercontinental</td>\n",
       "      <td>negative</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>The Intercontinental Chicago Magnificent Mile ...</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>deceptive</td>\n",
       "      <td>palmer</td>\n",
       "      <td>negative</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>The Palmer House Hilton, while it looks good i...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1598</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>deceptive</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>negative</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>As a former Chicagoan, I'm appalled at the Ama...</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      deceptive             hotel  polarity       source  \\\n",
       "0      truthful            conrad  positive  TripAdvisor   \n",
       "1      truthful             hyatt  positive  TripAdvisor   \n",
       "2      truthful             hyatt  positive  TripAdvisor   \n",
       "3      truthful              omni  positive  TripAdvisor   \n",
       "4      truthful             hyatt  positive  TripAdvisor   \n",
       "...         ...               ...       ...          ...   \n",
       "1595  deceptive  intercontinental  negative        MTurk   \n",
       "1596  deceptive            amalfi  negative        MTurk   \n",
       "1597  deceptive  intercontinental  negative        MTurk   \n",
       "1598  deceptive            palmer  negative        MTurk   \n",
       "1599  deceptive            amalfi  negative        MTurk   \n",
       "\n",
       "                                                   text  fakescore  \\\n",
       "0     We stayed for a one night getaway with family ...          2   \n",
       "1     Triple A rate with upgrade to view room was le...          2   \n",
       "2     This comes a little late as I'm finally catchi...          6   \n",
       "3     The Omni Chicago really delivers on all fronts...          3   \n",
       "4     I asked for a high floor away from the elevato...          0   \n",
       "...                                                 ...        ...   \n",
       "1595  Problems started when I booked the InterContin...          1   \n",
       "1596  The Amalfi Hotel has a beautiful website and i...         -5   \n",
       "1597  The Intercontinental Chicago Magnificent Mile ...         -4   \n",
       "1598  The Palmer House Hilton, while it looks good i...         -2   \n",
       "1599  As a former Chicagoan, I'm appalled at the Ama...         -4   \n",
       "\n",
       "      vader_sent_score  sentiment_score  true_label  index  predicted_label  \n",
       "0               0.9297                2          -1      0                1  \n",
       "1               0.8883                2          -1      1                1  \n",
       "2               0.9807                6          -1      2                1  \n",
       "3               0.9564                5          -1      3                1  \n",
       "4               0.9609                4          -1      4                1  \n",
       "...                ...              ...         ...    ...              ...  \n",
       "1595           -0.7312               -3           1   1595               -1  \n",
       "1596            0.9788                7           1   1596                1  \n",
       "1597            0.9712                4           1   1597                1  \n",
       "1598           -0.3612               -1           1   1598               -1  \n",
       "1599            0.8818                6           1   1599                1  \n",
       "\n",
       "[1600 rows x 11 columns]"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = 54\n",
    "P2 = 1393 \n",
    "#for these 2 values the below two classifiers gave 94 and 73% accuracy respectively\n",
    "#1203,76   1161,150 (1163, 1399) (662, 1476) (1542, 194) (78, 28) (699, 44) (1384, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    p1 = random.randrange(len(dataset))\n",
    "    p2 = random.randrange(len(dataset))\n",
    "    if(p1 != p2):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1384, 192)"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p1 = P1\n",
    "# p2=P2\n",
    "p1,p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "point11 = dataset['vader_sent_score'][p1]\n",
    "point12 = dataset['fakescore'][p1]\n",
    "point21 = dataset['vader_sent_score'][p2]\n",
    "point22 = dataset['fakescore'][p2]\n",
    "\n",
    "def Distance(x1,y1,x2,y2):\n",
    "    return (x1-x2)**2 + (y1-y2)**2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster11 = {p1:point11}\n",
    "cluster12 = {p1:point12}\n",
    "cluster21 = {p2:point21}\n",
    "cluster22 = {p2:point22}\n",
    "old_centroid11 = new_centroid11 = point11\n",
    "old_centroid12 = new_centroid12 = point12\n",
    "old_centroid21 = new_centroid21 = point21\n",
    "old_centroid22 = new_centroid22 = point22\n",
    "\n",
    "\n",
    "while(True):\n",
    "    old_centroid11 = new_centroid11\n",
    "    old_centroid12 = new_centroid12\n",
    "    old_centroid21 = new_centroid21\n",
    "    old_centroid22 = new_centroid22\n",
    "    for i in range(len(dataset)):\n",
    "        point1 = dataset['vader_sent_score'][i]\n",
    "        point2 = dataset['fakescore'][i]\n",
    "        \n",
    "        if(Distance(old_centroid11,old_centroid12,point1,point2) > Distance(old_centroid21,old_centroid22,point1,point2)):\n",
    "            if(i not in cluster21):\n",
    "                cluster21[i] = point1\n",
    "                cluster22[i] = point2\n",
    "        else:\n",
    "            if(i not in cluster11):\n",
    "                cluster11[i] = point1\n",
    "                cluster12[i] = point2\n",
    "        \n",
    "        new_centroid11 = sum(cluster11.values())/len(cluster11)\n",
    "        new_centroid12 = sum(cluster12.values())/len(cluster12)\n",
    "        new_centroid21 = sum(cluster21.values())/len(cluster21)\n",
    "        new_centroid22 = sum(cluster22.values())/len(cluster22)\n",
    "    if(old_centroid11 == new_centroid11 and old_centroid12 == new_centroid12 and old_centroid21 == new_centroid21 and old_centroid22 == new_centroid22):\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(Distance(old_centroid11,old_centroid12,-0.2,0) < Distance(old_centroid21,old_centroid22,-0.2,0)):\n",
    "    label1 = 1 #fake\n",
    "    label2 = -1 #real\n",
    "else:\n",
    "    label1 = -1\n",
    "    label2 = 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGivenLabel(value):\n",
    "    if( value == \"truthful\"):\n",
    "        return -1 #notfake\n",
    "    else:\n",
    "        return 1 #fake\n",
    "\n",
    "dataset['true_label'] = dataset['deceptive'].apply(getGivenLabel)\n",
    "\n",
    "dataset['index'] = list(range(len(dataset)))\n",
    "\n",
    "def getPredictedLabel(value):  \n",
    "    if(value in cluster11):\n",
    "        return label1\n",
    "    else:\n",
    "        return label2\n",
    "    \n",
    "dataset['predicted_label'] = dataset['index'].apply(getPredictedLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8325"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(dataset)):\n",
    "    if(dataset['true_label'][i] == dataset['predicted_label'][i]):\n",
    "        count += 1\n",
    "            \n",
    "count/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "truePositive = trueNegative = falsePositive = falseNegative = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    if(dataset['true_label'][i] == dataset['predicted_label'][i] == 1):\n",
    "        truePositive += 1\n",
    "    elif dataset['true_label'][i] == dataset['predicted_label'][i] == -1:\n",
    "        trueNegative += 1\n",
    "    elif dataset['true_label'][i] == -1 and dataset['predicted_label'][i] == 1:\n",
    "        falsePositive += 1\n",
    "    elif dataset['true_label'][i] == 1 and dataset['predicted_label'][i] == -1 :\n",
    "        falseNegative += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8325, 0.815914489311164, 0.85875)"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (truePositive + trueNegative)/(truePositive + trueNegative + falsePositive + falseNegative)\n",
    "precision = truePositive/(truePositive + falsePositive)\n",
    "recall =truePositive/(truePositive + falseNegative) \n",
    "\n",
    "accuracy,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8572469045884924, 0.9954128440366973, 0.6910828025477707)"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truePositive = trueNegative = falsePositive = falseNegative = 0\n",
    "for i in range(len(dataset)):\n",
    "    if(dataset['true_label'][i] == 1 and dataset['fakescore'][i] < 0):\n",
    "        truePositive += 1\n",
    "    elif dataset['true_label'][i] == -1 and dataset['fakescore'][i] > 0:\n",
    "        trueNegative += 1\n",
    "    elif dataset['true_label'][i] == -1 and dataset['fakescore'][i] < 0:\n",
    "        falsePositive += 1\n",
    "    elif dataset['true_label'][i] == 1 and dataset['fakescore'][i] > 0 :\n",
    "        falseNegative += 1\n",
    "        \n",
    "accuracy = (truePositive + trueNegative)/(truePositive + trueNegative + falsePositive + falseNegative)\n",
    "precision = truePositive/(truePositive + falsePositive)\n",
    "recall =truePositive/(truePositive + falseNegative) \n",
    "\n",
    "accuracy,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    p1 = random.randrange(len(dataset))\n",
    "    p2 = random.randrange(len(dataset))\n",
    "    if(p1 != p2):\n",
    "        break\n",
    "point1 = dataset['vader_sent_score'][p1]\n",
    "\n",
    "point2 = dataset['vader_sent_score'][p2]\n",
    "\n",
    "def Distance(x1,x2):\n",
    "    return (x1-x2)**2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = {p1:point1}\n",
    "\n",
    "cluster2 = {p2:point2}\n",
    "\n",
    "old_centroid1 = new_centroid1 = point1\n",
    "\n",
    "old_centroid2 = new_centroid2 = point2\n",
    "\n",
    "\n",
    "\n",
    "while(True):\n",
    "    old_centroid1 = new_centroid1\n",
    "\n",
    "    old_centroid2 = new_centroid2\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "       \n",
    "        point = dataset['vader_sent_score'][i]\n",
    "        \n",
    "        if(Distance(old_centroid1,point) > Distance(old_centroid2,point)):\n",
    "            if(i not in cluster2):\n",
    "                cluster2[i] = point\n",
    "        else:\n",
    "            if(i not in cluster11):\n",
    "                cluster1[i] = point\n",
    "               \n",
    "        \n",
    "        new_centroid1 = sum(cluster1.values())/len(cluster1)\n",
    "        \n",
    "        new_centroid2 = sum(cluster2.values())/len(cluster2)\n",
    "    if(old_centroid1 == new_centroid1 and old_centroid2 == new_centroid2):\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(Distance(old_centroid1,0) < Distance(old_centroid2,0)):\n",
    "    label1 = -1\n",
    "    label2 = 1\n",
    "else:\n",
    "    label1 = 1\n",
    "    label2 = -1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def getPredictedLabel(value):  \n",
    "#     if(value in cluster1):\n",
    "#         return label1\n",
    "#     else:\n",
    "#         return label2\n",
    "    \n",
    "# dataset['predicted_label'] = dataset['index'].apply(getPredictedLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-772-fa873747fd4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vader_sent_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'polarity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'positive'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'deceptive'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'truthful'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'polarity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'negative'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'deceptive'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'deceptive'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1479\u001b[0;31m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(dataset)):\n",
    "    if(dataset['vader_sent_score'][i] > 0):\n",
    "        if dataset['polarity'] == 'positive' and dataset['deceptive'] == 'truthful':\n",
    "            count += 1\n",
    "        elif dataset['polarity'] == 'negative' and dataset['deceptive'] == 'deceptive':\n",
    "            count += 1\n",
    "    elif dataset['vader_sent_score'][i] < 0:\n",
    "        if dataset['polarity'] == 'negative' and dataset['deceptive'] == 'truthful':\n",
    "            count += 1\n",
    "        elif dataset['polarity'] == 'positive' and dataset['deceptive'] == 'deceptive':\n",
    "            count += 1\n",
    "             \n",
    "count/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for p1=274 and p2=453 the accuracy given by this is 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import tweepy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import GetOldTweets3 as got\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import treebank\n",
    "from nltk.corpus import words\n",
    "words_list = words.words()\n",
    "words_list = list((set(words_list)))\n",
    "stopwords = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drumline',\n",
       " 'metapolitical',\n",
       " 'phosphoric',\n",
       " 'indorse',\n",
       " 'notification',\n",
       " 'farmhousey',\n",
       " 'royalet',\n",
       " 'noctambulation',\n",
       " 'magneta',\n",
       " 'nitrophilous',\n",
       " 'taxonomy',\n",
       " 'hemiphrase',\n",
       " 'unspecialized',\n",
       " 'preiotize',\n",
       " 'allelocatalytic',\n",
       " 'epicentrum',\n",
       " 'subbroker',\n",
       " 'lubricity',\n",
       " 'pterygoidean',\n",
       " 'amotion',\n",
       " 'maremmatic',\n",
       " 'Isatis',\n",
       " 'khedival',\n",
       " 'pelotherapy',\n",
       " 'rejector',\n",
       " 'Beaverboard',\n",
       " 'harakeke',\n",
       " 'huller',\n",
       " 'Tabellaria',\n",
       " 'diplocephaly',\n",
       " 'tinselweaver',\n",
       " 'hypersusceptibility',\n",
       " 'countercompony',\n",
       " 'Teletype',\n",
       " 'dechemicalize',\n",
       " 'paleomammalogy',\n",
       " 'aeroscope',\n",
       " 'boltstrake',\n",
       " 'comforter',\n",
       " 'theoktonic',\n",
       " 'Cornulites',\n",
       " 'recurse',\n",
       " 'humbly',\n",
       " 'sommaite',\n",
       " 'antidotary',\n",
       " 'phalangigrady',\n",
       " 'ulcerous',\n",
       " 'gastrohydrorrhea',\n",
       " 'Diaspora',\n",
       " 'lovesome',\n",
       " 'despoticly',\n",
       " 'metricist',\n",
       " 'Tzendal',\n",
       " 'Machiavel',\n",
       " 'acromastitis',\n",
       " 'christener',\n",
       " 'pokiness',\n",
       " 'trilamellar',\n",
       " 'overdrape',\n",
       " 'unbandaged',\n",
       " 'Islamite',\n",
       " 'matelessness',\n",
       " 'interdependable',\n",
       " 'coxcombical',\n",
       " 'preintercourse',\n",
       " 'anhaline',\n",
       " 'reassent',\n",
       " 'miliolite',\n",
       " 'lapidist',\n",
       " 'icterine',\n",
       " 'sacerdotalize',\n",
       " 'fourpence',\n",
       " 'antipodagron',\n",
       " 'interpretorial',\n",
       " 'Roccella',\n",
       " 'starets',\n",
       " 'paranoidism',\n",
       " 'overstrength',\n",
       " 'Jingbai',\n",
       " 'pitchpoll',\n",
       " 'sadness',\n",
       " 'accident',\n",
       " 'creatively',\n",
       " 'espalier',\n",
       " 'earringed',\n",
       " 'flaxdrop',\n",
       " 'scruplesomeness',\n",
       " 'swanmarking',\n",
       " 'agrobiology',\n",
       " 'wiring',\n",
       " 'seminarize',\n",
       " 'accolade',\n",
       " 'disguisal',\n",
       " 'inoffending',\n",
       " 'togetherness',\n",
       " 'depreciable',\n",
       " 'drumbler',\n",
       " 'magnifier',\n",
       " 'trilinolenate',\n",
       " 'Gorgosaurus',\n",
       " 'irreligion',\n",
       " 'sportiveness',\n",
       " 'dummel',\n",
       " 'badness',\n",
       " 'Dictyopteris',\n",
       " 'Chrysippus',\n",
       " 'typhloempyema',\n",
       " 'Hemipodius',\n",
       " 'cuboides',\n",
       " 'weening',\n",
       " 'bipersonal',\n",
       " 'diwata',\n",
       " 'prill',\n",
       " 'pseudocentrum',\n",
       " 'unidirectional',\n",
       " 'itacism',\n",
       " 'elasmothere',\n",
       " 'gaspiness',\n",
       " 'heroner',\n",
       " 'duledge',\n",
       " 'superinclusive',\n",
       " 'deaspirate',\n",
       " 'endogastritis',\n",
       " 'radiotherapeutic',\n",
       " 'subangulated',\n",
       " 'disher',\n",
       " 'mellowy',\n",
       " 'Vascons',\n",
       " 'sarcogenic',\n",
       " 'squarewise',\n",
       " 'wicky',\n",
       " 'sunken',\n",
       " 'bossy',\n",
       " 'heterokaryon',\n",
       " 'hureek',\n",
       " 'guttide',\n",
       " 'cephalotrocha',\n",
       " 'anammonid',\n",
       " 'monolayer',\n",
       " 'cornloft',\n",
       " 'Miki',\n",
       " 'remittee',\n",
       " 'psalmodize',\n",
       " 'Bal',\n",
       " 'typifier',\n",
       " 'quadrimetallic',\n",
       " 'gatherer',\n",
       " 'iatromathematics',\n",
       " 'oppositionist',\n",
       " 'erogenesis',\n",
       " 'itaconate',\n",
       " 'unscathedly',\n",
       " 'humble',\n",
       " 'racketer',\n",
       " 'carnivorously',\n",
       " 'Kuar',\n",
       " 'battleship',\n",
       " 'hatbrush',\n",
       " 'vizard',\n",
       " 'diazonium',\n",
       " 'confidingness',\n",
       " 'pylethrombophlebitis',\n",
       " 'interconfound',\n",
       " 'aftermeal',\n",
       " 'bedare',\n",
       " 'ruinate',\n",
       " 'hardfern',\n",
       " 'periurethral',\n",
       " 'tanbur',\n",
       " 'encephalomyelitis',\n",
       " 'appulsive',\n",
       " 'autoecism',\n",
       " 'warriorhood',\n",
       " 'kakar',\n",
       " 'Aselline',\n",
       " 'macrocosmos',\n",
       " 'pinchedness',\n",
       " 'assuage',\n",
       " 'tetrasaccharide',\n",
       " 'entobronchium',\n",
       " 'ghostess',\n",
       " 'iridentropium',\n",
       " 'Neomylodon',\n",
       " 'nematognath',\n",
       " 'Canoeiro',\n",
       " 'subitane',\n",
       " 'unalluring',\n",
       " 'teleologically',\n",
       " 'scamles',\n",
       " 'andantino',\n",
       " 'umbrette',\n",
       " 'sulphurproof',\n",
       " 'oligosyllabic',\n",
       " 'underbud',\n",
       " 'laboratorian',\n",
       " 'suitableness',\n",
       " 'foreshank',\n",
       " 'antistimulant',\n",
       " 'untreacherous',\n",
       " 'veneering',\n",
       " 'nondecadence',\n",
       " 'choosable',\n",
       " 'typewriter',\n",
       " 'conceited',\n",
       " 'amene',\n",
       " 'comic',\n",
       " 'spaver',\n",
       " 'ametrometer',\n",
       " 'undismembered',\n",
       " 'compunctive',\n",
       " 'degarnish',\n",
       " 'botanically',\n",
       " 'knightship',\n",
       " 'Mixe',\n",
       " 'upflare',\n",
       " 'ergot',\n",
       " 'manuductor',\n",
       " 'brushbush',\n",
       " 'histioid',\n",
       " 'Laspeyresia',\n",
       " 'Podargidae',\n",
       " 'monographer',\n",
       " 'uniauriculate',\n",
       " 'predonation',\n",
       " 'curvity',\n",
       " 'infallibilism',\n",
       " 'readdress',\n",
       " 'peristole',\n",
       " 'fiddlestring',\n",
       " 'saccharometric',\n",
       " 'Bacis',\n",
       " 'hepatauxe',\n",
       " 'Harderian',\n",
       " 'ganomalite',\n",
       " 'semiquintile',\n",
       " 'sown',\n",
       " 'Oleraceae',\n",
       " 'anathematization',\n",
       " 'bespit',\n",
       " 'prostemmate',\n",
       " 'trichogynic',\n",
       " 'seminasal',\n",
       " 'cooking',\n",
       " 'engrossment',\n",
       " 'busybody',\n",
       " 'fringed',\n",
       " 'yeasty',\n",
       " 'predestroy',\n",
       " 'extramodal',\n",
       " 'cosinage',\n",
       " 'detective',\n",
       " 'egregiousness',\n",
       " 'fruticous',\n",
       " 'furazan',\n",
       " 'bosket',\n",
       " 'Titanesque',\n",
       " 'Ammobium',\n",
       " 'turns',\n",
       " 'viziercraft',\n",
       " 'mogigraphy',\n",
       " 'porterly',\n",
       " 'unscoured',\n",
       " 'Eurygaea',\n",
       " 'Anthesteria',\n",
       " 'countersalient',\n",
       " 'diplococcic',\n",
       " 'counteragency',\n",
       " 'overfruitful',\n",
       " 'typotelegraphy',\n",
       " 'smokyseeming',\n",
       " 'overfoolishly',\n",
       " 'familiarization',\n",
       " 'biogenetically',\n",
       " 'Neroic',\n",
       " 'roughheartedness',\n",
       " 'coabsume',\n",
       " 'undisguisedness',\n",
       " 'unconfounded',\n",
       " 'undistinguishing',\n",
       " 'urceoli',\n",
       " 'nongreasy',\n",
       " 'parastemon',\n",
       " 'Sabbatarianism',\n",
       " 'neurogastric',\n",
       " 'gnathidium',\n",
       " 'curvedly',\n",
       " 'flipper',\n",
       " 'fabaceous',\n",
       " 'palatist',\n",
       " 'joug',\n",
       " 'unexcluded',\n",
       " 'unintersected',\n",
       " 'venatic',\n",
       " 'panspermism',\n",
       " 'unidleness',\n",
       " 'taro',\n",
       " 'holarthritic',\n",
       " 'barony',\n",
       " 'pneumonophthisis',\n",
       " 'south',\n",
       " 'kominuter',\n",
       " 'tiring',\n",
       " 'missingly',\n",
       " 'muktar',\n",
       " 'funk',\n",
       " 'guarantee',\n",
       " 'skittyboot',\n",
       " 'cicatrisive',\n",
       " 'noncrushability',\n",
       " 'unpompous',\n",
       " 'whitehawse',\n",
       " 'hotfoot',\n",
       " 'Acemetae',\n",
       " 'ovariocyesis',\n",
       " 'orbitomaxillary',\n",
       " 'fianchetto',\n",
       " 'practical',\n",
       " 'beadswoman',\n",
       " 'nonhieratic',\n",
       " 'thegndom',\n",
       " 'snatchable',\n",
       " 'fastigiate',\n",
       " 'helianthic',\n",
       " 'aal',\n",
       " 'pampered',\n",
       " 'plagihedral',\n",
       " 'unexalted',\n",
       " 'supraoccipital',\n",
       " 'caricography',\n",
       " 'hider',\n",
       " 'exit',\n",
       " 'carcinological',\n",
       " 'jingled',\n",
       " 'unhatchable',\n",
       " 'mesoperiodic',\n",
       " 'dediticiancy',\n",
       " 'feague',\n",
       " 'Stereum',\n",
       " 'schism',\n",
       " 'providable',\n",
       " 'cor',\n",
       " 'Monomyaria',\n",
       " 'Celtis',\n",
       " 'beardtongue',\n",
       " 'epitome',\n",
       " 'genarchship',\n",
       " 'snew',\n",
       " 'Ethanim',\n",
       " 'greenalite',\n",
       " 'benzolize',\n",
       " 'illoyal',\n",
       " 'kinesis',\n",
       " 'mastatrophia',\n",
       " 'Scirophorion',\n",
       " 'discipliner',\n",
       " 'apiose',\n",
       " 'gyrinid',\n",
       " 'spoky',\n",
       " 'stepgrandmother',\n",
       " 'antispreading',\n",
       " 'fascis',\n",
       " 'specularly',\n",
       " 'uncharitableness',\n",
       " 'threadbarity',\n",
       " 'jerseyed',\n",
       " 'geckotid',\n",
       " 'drawrod',\n",
       " 'lazaretto',\n",
       " 'providore',\n",
       " 'pseudoventricle',\n",
       " 'puzzledness',\n",
       " 'superinduction',\n",
       " 'trifa',\n",
       " 'unsmoky',\n",
       " 'postage',\n",
       " 'mout',\n",
       " 'overslack',\n",
       " 'gawsie',\n",
       " 'panurgic',\n",
       " 'unclarifying',\n",
       " 'electrosteel',\n",
       " 'Zosteropinae',\n",
       " 'whimsey',\n",
       " 'birdcatching',\n",
       " 'epileptic',\n",
       " 'checky',\n",
       " 'goanna',\n",
       " 'Bastard',\n",
       " 'melanorrhea',\n",
       " 'geotropic',\n",
       " 'pucelle',\n",
       " 'dittography',\n",
       " 'bumpkinish',\n",
       " 'mirthlessly',\n",
       " 'tilley',\n",
       " 'vapulation',\n",
       " 'arseniopleite',\n",
       " 'superstimulate',\n",
       " 'Sanskritist',\n",
       " 'guao',\n",
       " 'chromidiogamy',\n",
       " 'angelhood',\n",
       " 'heavy',\n",
       " 'unprecedentedly',\n",
       " 'minsitive',\n",
       " 'paratypically',\n",
       " 'irreligionism',\n",
       " 'palpi',\n",
       " 'tenoroon',\n",
       " 'saker',\n",
       " 'Diomedeidae',\n",
       " 'unneared',\n",
       " 'nonproletarian',\n",
       " 'sorrowy',\n",
       " 'hypanthial',\n",
       " 'mash',\n",
       " 'process',\n",
       " 'hemiparaplegia',\n",
       " 'stormy',\n",
       " 'troglodytal',\n",
       " 'nominated',\n",
       " 'windling',\n",
       " 'pulleyless',\n",
       " 'governorship',\n",
       " 'recement',\n",
       " 'cinnamonic',\n",
       " 'baragnosis',\n",
       " 'indue',\n",
       " 'manzanita',\n",
       " 'Nosairi',\n",
       " 'oxyluminescent',\n",
       " 'oneiroscopist',\n",
       " 'pseudostomatous',\n",
       " 'valgus',\n",
       " 'enterotome',\n",
       " 'nightgown',\n",
       " 'premedical',\n",
       " 'myringomycosis',\n",
       " 'hooter',\n",
       " 'cloisonne',\n",
       " 'micronize',\n",
       " 'deliver',\n",
       " 'redistiller',\n",
       " 'insulting',\n",
       " 'agrostographic',\n",
       " 'woofy',\n",
       " 'wast',\n",
       " 'cnemial',\n",
       " 'nighttime',\n",
       " 'subpiston',\n",
       " 'formulistic',\n",
       " 'subsimple',\n",
       " 'overmount',\n",
       " 'Ersar',\n",
       " 'forestep',\n",
       " 'antipodal',\n",
       " 'interflashing',\n",
       " 'polynucleate',\n",
       " 'potassamide',\n",
       " 'insack',\n",
       " 'tailor',\n",
       " 'toddyize',\n",
       " 'laparoenterostomy',\n",
       " 'distributiveness',\n",
       " 'nonsynchronous',\n",
       " 'punctuation',\n",
       " 'orf',\n",
       " 'mythopoetry',\n",
       " 'polygrooved',\n",
       " 'entocyst',\n",
       " 'desertic',\n",
       " 'unlikableness',\n",
       " 'deorusumduction',\n",
       " 'thaumatography',\n",
       " 'pyrophotometer',\n",
       " 'abetment',\n",
       " 'chrysophilite',\n",
       " 'unice',\n",
       " 'territorian',\n",
       " 'backswordsman',\n",
       " 'obliquity',\n",
       " 'pair',\n",
       " 'pantostome',\n",
       " 'spermolysis',\n",
       " 'brumstone',\n",
       " 'phthor',\n",
       " 'anchor',\n",
       " 'Idiogastra',\n",
       " 'microdissection',\n",
       " 'profaneness',\n",
       " 'unstayed',\n",
       " 'sextipara',\n",
       " 'connumeration',\n",
       " 'disorderliness',\n",
       " 'hypnotizability',\n",
       " 'ribbidge',\n",
       " 'omniscient',\n",
       " 'allantoidal',\n",
       " 'sweatbox',\n",
       " 'adeptship',\n",
       " 'devilkin',\n",
       " 'permit',\n",
       " 'gloriousness',\n",
       " 'keratolysis',\n",
       " 'kennebecker',\n",
       " 'noodleism',\n",
       " 'uncorruptibleness',\n",
       " 'alares',\n",
       " 'unfirmly',\n",
       " 'triable',\n",
       " 'lieutenantry',\n",
       " 'antitheistic',\n",
       " 'duodecuple',\n",
       " 'bellicosity',\n",
       " 'reis',\n",
       " 'simianity',\n",
       " 'Laurence',\n",
       " 'Rodentia',\n",
       " 'photodysphoria',\n",
       " 'oticodinia',\n",
       " 'surmise',\n",
       " 'inurbaneness',\n",
       " 'Lazarist',\n",
       " 'bulbocavernous',\n",
       " 'reguard',\n",
       " 'stuporific',\n",
       " 'uncake',\n",
       " 'Luganda',\n",
       " 'Vestas',\n",
       " 'harridan',\n",
       " 'cardiology',\n",
       " 'photogram',\n",
       " 'prebenediction',\n",
       " 'tapeless',\n",
       " 'hexastichous',\n",
       " 'ventroinguinal',\n",
       " 'els',\n",
       " 'glider',\n",
       " 'Cryptomonadales',\n",
       " 'Ozonium',\n",
       " 'personative',\n",
       " 'shillingless',\n",
       " 'bopeep',\n",
       " 'trachean',\n",
       " 'unwork',\n",
       " 'compter',\n",
       " 'thiohydrate',\n",
       " 'unletterlike',\n",
       " 'unheritable',\n",
       " 'diapyetic',\n",
       " 'naphthalin',\n",
       " 'surrounded',\n",
       " 'reticuloramose',\n",
       " 'unforewarnedness',\n",
       " 'unwilling',\n",
       " 'hemogenesis',\n",
       " 'macroconidium',\n",
       " 'insubstantiation',\n",
       " 'behale',\n",
       " 'pickaway',\n",
       " 'Botryomyces',\n",
       " 'Struthiones',\n",
       " 'homopteran',\n",
       " 'dasypaedic',\n",
       " 'Kabyle',\n",
       " 'chromaticity',\n",
       " 'Linus',\n",
       " 'metafluidal',\n",
       " 'premedieval',\n",
       " 'ptyalolithiasis',\n",
       " 'xerodermatic',\n",
       " 'spheges',\n",
       " 'risorius',\n",
       " 'encephalin',\n",
       " 'nevoy',\n",
       " 'bahoe',\n",
       " 'Sphacelariales',\n",
       " 'Hein',\n",
       " 'succi',\n",
       " 'monadistic',\n",
       " 'counterdogmatism',\n",
       " 'barff',\n",
       " 'roddikin',\n",
       " 'perk',\n",
       " 'thromboplastic',\n",
       " 'turfless',\n",
       " 'uncontrovertably',\n",
       " 'awiwi',\n",
       " 'pennaceous',\n",
       " 'unleavened',\n",
       " 'slantwise',\n",
       " 'cervicectomy',\n",
       " 'omniferous',\n",
       " 'heapstead',\n",
       " 'Beagle',\n",
       " 'glaze',\n",
       " 'hermodact',\n",
       " 'bodenbenderite',\n",
       " 'tectorium',\n",
       " 'fivepins',\n",
       " 'Bradburya',\n",
       " 'feignedness',\n",
       " 'Eneas',\n",
       " 'giant',\n",
       " 'mesocoele',\n",
       " 'trancoidal',\n",
       " 'fantasy',\n",
       " 'cowhage',\n",
       " 'cloisterless',\n",
       " 'shogaol',\n",
       " 'predebit',\n",
       " 'toft',\n",
       " 'Paulinian',\n",
       " 'salivant',\n",
       " 'vying',\n",
       " 'celled',\n",
       " 'provine',\n",
       " 'cubocalcaneal',\n",
       " 'Nummulitidae',\n",
       " 'malarin',\n",
       " 'inscriber',\n",
       " 'betimber',\n",
       " 'fremescence',\n",
       " 'metromalacia',\n",
       " 'stipulary',\n",
       " 'epistolical',\n",
       " 'atrophoderma',\n",
       " 'syndicate',\n",
       " 'jimmy',\n",
       " 'carburation',\n",
       " 'dysacousia',\n",
       " 'pluralistically',\n",
       " 'caba',\n",
       " 'lobeless',\n",
       " 'polyonomy',\n",
       " 'tasselfish',\n",
       " 'chondrodite',\n",
       " 'harmonic',\n",
       " 'inexplicability',\n",
       " 'earplug',\n",
       " 'birma',\n",
       " 'pathematic',\n",
       " 'spiritlessly',\n",
       " 'unperfect',\n",
       " 'guardful',\n",
       " 'hypomyotonia',\n",
       " 'palaeostyly',\n",
       " 'catoptrics',\n",
       " 'radiologist',\n",
       " 'unimagine',\n",
       " 'prion',\n",
       " 'parvenuism',\n",
       " 'Molly',\n",
       " 'hyperurbanism',\n",
       " 'steppeland',\n",
       " 'cryptophthalmos',\n",
       " 'dorsosacral',\n",
       " 'rectoclysis',\n",
       " 'rhytidosis',\n",
       " 'spermotheca',\n",
       " 'testamentalness',\n",
       " 'harefooted',\n",
       " 'Rickettsiales',\n",
       " 'autohypnosis',\n",
       " 'laceybark',\n",
       " 'prodespotic',\n",
       " 'Daneball',\n",
       " 'despairing',\n",
       " 'mattboard',\n",
       " 'ranged',\n",
       " 'Romanize',\n",
       " 'overextend',\n",
       " 'bid',\n",
       " 'sivvens',\n",
       " 'boilerman',\n",
       " 'Dothidella',\n",
       " 'Monday',\n",
       " 'alumina',\n",
       " 'bastardly',\n",
       " 'acrobryous',\n",
       " 'gaus',\n",
       " 'excave',\n",
       " 'nebenkern',\n",
       " 'undisplayed',\n",
       " 'meizoseismal',\n",
       " 'boarhound',\n",
       " 'counterplease',\n",
       " 'exclave',\n",
       " 'lavish',\n",
       " 'unmad',\n",
       " 'ascriptitius',\n",
       " 'exteroceptist',\n",
       " 'possessionate',\n",
       " 'mentary',\n",
       " 'Sacculina',\n",
       " 'unreciprocated',\n",
       " 'eugenolate',\n",
       " 'Maida',\n",
       " 'hydrometamorphism',\n",
       " 'atrichia',\n",
       " 'anilinophile',\n",
       " 'myrtiform',\n",
       " 'muslined',\n",
       " 'sicklewise',\n",
       " 'unconveniently',\n",
       " 'pastern',\n",
       " 'isocratic',\n",
       " 'ichthyosaurian',\n",
       " 'Toryfication',\n",
       " 'unbendably',\n",
       " 'oidiomycotic',\n",
       " 'wagbeard',\n",
       " 'fatherlandish',\n",
       " 'psylla',\n",
       " 'microcheiria',\n",
       " 'petitioner',\n",
       " 'perilabyrinthitis',\n",
       " 'planocylindric',\n",
       " 'mentalization',\n",
       " 'Bhotia',\n",
       " 'Kemalism',\n",
       " 'paparchy',\n",
       " 'unhesitatingness',\n",
       " 'filiality',\n",
       " 'unwariness',\n",
       " 'introductress',\n",
       " 'morga',\n",
       " 'phlebectomy',\n",
       " 'captaculum',\n",
       " 'devouress',\n",
       " 'diddle',\n",
       " 'custom',\n",
       " 'postreduction',\n",
       " 'aisle',\n",
       " 'Targumic',\n",
       " 'lipopod',\n",
       " 'phlegma',\n",
       " 'Uro',\n",
       " 'pardonable',\n",
       " 'Willie',\n",
       " 'dromedarist',\n",
       " 'unfountained',\n",
       " 'bromoauric',\n",
       " 'salvy',\n",
       " 'overcompliant',\n",
       " 'directionless',\n",
       " 'Babist',\n",
       " 'albarium',\n",
       " 'laciniola',\n",
       " 'engagingly',\n",
       " 'hypabyssal',\n",
       " 'merosymmetry',\n",
       " 'subfrontal',\n",
       " 'Bardolatry',\n",
       " 'forechoose',\n",
       " 'unbosomer',\n",
       " 'aphyric',\n",
       " 'abolla',\n",
       " 'remixture',\n",
       " 'cumidine',\n",
       " 'ziganka',\n",
       " 'blastoporal',\n",
       " 'malconceived',\n",
       " 'exemplaric',\n",
       " 'overtrader',\n",
       " 'enzooty',\n",
       " 'bedabble',\n",
       " 'imposable',\n",
       " 'sideway',\n",
       " 'depilation',\n",
       " 'casha',\n",
       " 'unfrounced',\n",
       " 'Argasidae',\n",
       " 'heelband',\n",
       " 'efflorescence',\n",
       " 'hoseman',\n",
       " 'inclusion',\n",
       " 'Quintilis',\n",
       " 'latus',\n",
       " 'subitaneous',\n",
       " 'klaftern',\n",
       " 'unmaid',\n",
       " 'tectosphere',\n",
       " 'sparkleberry',\n",
       " 'anoetic',\n",
       " 'preballot',\n",
       " 'mythicist',\n",
       " 'entomologically',\n",
       " 'Saxonically',\n",
       " 'overcautiously',\n",
       " 'riflebird',\n",
       " 'needing',\n",
       " 'Cotinus',\n",
       " 'duchess',\n",
       " 'cutcherry',\n",
       " 'kentrogon',\n",
       " 'swoop',\n",
       " 'venomosalivary',\n",
       " 'anagyrin',\n",
       " 'furcation',\n",
       " 'distendedly',\n",
       " 'Parisianization',\n",
       " 'unarbitrarily',\n",
       " 'anaphylactogen',\n",
       " 'shiv',\n",
       " 'balloonery',\n",
       " 'outpopulate',\n",
       " 'fugient',\n",
       " 'examinatory',\n",
       " 'faddy',\n",
       " 'unmineralized',\n",
       " 'gracefulness',\n",
       " 'splenoptosis',\n",
       " 'assentingly',\n",
       " 'middy',\n",
       " 'postpharyngeal',\n",
       " 'reversal',\n",
       " 'undetesting',\n",
       " 'commonish',\n",
       " 'monostelous',\n",
       " 'shredless',\n",
       " 'untotaled',\n",
       " 'unreproachingly',\n",
       " 'trichinosis',\n",
       " 'complicate',\n",
       " 'Tzutuhil',\n",
       " 'cample',\n",
       " 'hippophagous',\n",
       " 'disprepare',\n",
       " 'commentarial',\n",
       " 'indivisibility',\n",
       " 'kerasin',\n",
       " 'misfault',\n",
       " 'unassertive',\n",
       " 'seersucker',\n",
       " 'unextenuable',\n",
       " 'isodimorphism',\n",
       " 'neurenteric',\n",
       " 'chalta',\n",
       " 'overdogmatism',\n",
       " 'thematist',\n",
       " 'tricarbimide',\n",
       " 'vaccinial',\n",
       " 'overharshness',\n",
       " 'caliphate',\n",
       " 'Gongoresque',\n",
       " 'triquinate',\n",
       " 'gatchwork',\n",
       " 'romanticist',\n",
       " 'fungian',\n",
       " 'cnemidium',\n",
       " 'respirableness',\n",
       " 'splanchnoscopy',\n",
       " 'impugnable',\n",
       " 'sauropsid',\n",
       " 'neofetus',\n",
       " 'underrating',\n",
       " 'squatterproof',\n",
       " 'cardia',\n",
       " 'conventionally',\n",
       " 'quit',\n",
       " 'swordsmanship',\n",
       " 'apostolicity',\n",
       " 'opacous',\n",
       " 'overhand',\n",
       " 'remember',\n",
       " 'coachwoman',\n",
       " 'lophophoral',\n",
       " 'ocher',\n",
       " 'Melipona',\n",
       " 'spermatocystitis',\n",
       " 'ludibrious',\n",
       " 'outrede',\n",
       " 'buzzwig',\n",
       " 'Senones',\n",
       " 'cyclothymia',\n",
       " 'seminebulous',\n",
       " 'yestreen',\n",
       " 'pearlin',\n",
       " 'nonexciting',\n",
       " 'pekin',\n",
       " 'twilit',\n",
       " 'caracol',\n",
       " 'submakroskelic',\n",
       " 'licenseless',\n",
       " 'diminutiveness',\n",
       " 'northernness',\n",
       " 'twofoldness',\n",
       " 'orpheonist',\n",
       " 'comacine',\n",
       " 'delightsome',\n",
       " 'nondemonstration',\n",
       " 'preoccurrence',\n",
       " 'featherlike',\n",
       " 'Agelaus',\n",
       " 'contreface',\n",
       " 'Jewling',\n",
       " 'anthropology',\n",
       " 'inimicable',\n",
       " 'kinaesthesis',\n",
       " 'unforeseenly',\n",
       " 'enrage',\n",
       " 'phyletism',\n",
       " 'dankishness',\n",
       " 'nonbursting',\n",
       " 'induplicative',\n",
       " 'cinchonology',\n",
       " 'readvance',\n",
       " 'conventicle',\n",
       " 'Pterichthyodes',\n",
       " 'Saccobranchiata',\n",
       " 'nephroerysipelas',\n",
       " 'Achyrodes',\n",
       " 'oleorefractometer',\n",
       " 'mercurify',\n",
       " 'metalloid',\n",
       " 'ovey',\n",
       " 'allogenically',\n",
       " 'inexperience',\n",
       " 'floreal',\n",
       " 'succuss',\n",
       " 'trompe',\n",
       " 'unbowed',\n",
       " 'homesteader',\n",
       " 'controllability',\n",
       " 'undumped',\n",
       " 'ortho',\n",
       " 'esthesiometer',\n",
       " 'hortensian',\n",
       " 'underpropped',\n",
       " 'unordinary',\n",
       " 'cencerro',\n",
       " 'mimetically',\n",
       " 'typologic',\n",
       " 'costulation',\n",
       " 'Lydian',\n",
       " 'subsessile',\n",
       " 'undilute',\n",
       " 'wheft',\n",
       " 'pseudaxis',\n",
       " 'nonenumerated',\n",
       " 'trophied',\n",
       " 'sternson',\n",
       " 'misworship',\n",
       " 'renavigation',\n",
       " 'Tracheophonae',\n",
       " 'taligrade',\n",
       " 'wintrous',\n",
       " 'tenonectomy',\n",
       " 'masslike',\n",
       " 'possessedness',\n",
       " 'slather',\n",
       " 'heteroblastic',\n",
       " 'izle',\n",
       " 'heelmaker',\n",
       " 'Colcine',\n",
       " 'nowed',\n",
       " 'synthronus',\n",
       " 'atemporal',\n",
       " 'unextinctness',\n",
       " 'Kiplingism',\n",
       " 'Odzooks',\n",
       " 'redispel',\n",
       " 'uncivic',\n",
       " 'mythify',\n",
       " 'reobligation',\n",
       " 'anteriorly',\n",
       " 'dulosis',\n",
       " 'toplighted',\n",
       " 'litigious',\n",
       " 'underthaw',\n",
       " 'infrared',\n",
       " 'Eudist',\n",
       " 'dolina',\n",
       " 'hypinosis',\n",
       " 'metantimonic',\n",
       " 'sheng',\n",
       " 'mermother',\n",
       " 'roughdry',\n",
       " 'blastostylar',\n",
       " 'respondent',\n",
       " 'dinoceratid',\n",
       " 'cactoid',\n",
       " 'liquefactive',\n",
       " 'acromegaly',\n",
       " 'Microchiroptera',\n",
       " 'protomorphic',\n",
       " 'Vallisneriaceae',\n",
       " 'nonracial',\n",
       " 'prepontine',\n",
       " 'underhandedness',\n",
       " 'ornithosaur',\n",
       " 'Ancha',\n",
       " 'cathetometer',\n",
       " 'immortalization',\n",
       " 'headily',\n",
       " 'tillotter',\n",
       " 'variolous',\n",
       " 'Bethuel',\n",
       " 'comicography',\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(words_list).intersection(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
