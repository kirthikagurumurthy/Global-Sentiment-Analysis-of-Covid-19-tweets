{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "GO TO THE END OF THE PAGE\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import neurolab as nl\n",
    "import nltk\n",
    "from nltk.tokenize import treebank\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "import math\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import numpy \n",
    "import re\n",
    "from nltk.corpus import words\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "# from sklearn.externals import joblib\n",
    "words_list = words.words()\n",
    "words_list = set(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Datasets/vader_dataset/vaderDataset.csv')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df,test_size):\n",
    "    if isinstance(test_size,float):\n",
    "        test_size = round(test_size * len(df))\n",
    "        \n",
    "    if(test_size > len(df)):\n",
    "        return 0, df\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices,k = test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_df,test_df = train_test_split(dataset,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nan': 10,\n",
       " 'middle': 138,\n",
       " 'crisis': 1037,\n",
       " 'matter': 276,\n",
       " 'urgency': 12,\n",
       " 'finally': 207,\n",
       " 'allow': 115,\n",
       " 'employee': 300,\n",
       " 'sick': 624,\n",
       " 'leave': 291,\n",
       " 'sign': 380,\n",
       " 'emergency': 1461,\n",
       " 'petition': 153,\n",
       " 'bit': 185,\n",
       " 'interesting': 216,\n",
       " 'history': 232,\n",
       " 'chemistry': 10,\n",
       " 'copper': 15,\n",
       " 'kill': 645,\n",
       " 'surface': 107,\n",
       " 'covered': 71,\n",
       " 'launch': 125,\n",
       " 'new': 6059,\n",
       " 'dashboard': 48,\n",
       " 'progress': 46,\n",
       " 'fight': 664,\n",
       " 'tourist': 137,\n",
       " 'cruise': 633,\n",
       " 'ship': 565,\n",
       " 'interfering': 6,\n",
       " 'politics': 186,\n",
       " 'snake': 79,\n",
       " 'behind': 270,\n",
       " 'outbreak': 4069,\n",
       " 'via': 4166,\n",
       " 'strike': 62,\n",
       " 'eleven': 11,\n",
       " 'residential': 12,\n",
       " 'estate': 41,\n",
       " 'nine': 49,\n",
       " 'school': 830,\n",
       " 'biggest': 185,\n",
       " 'food': 495,\n",
       " 'south': 469,\n",
       " 'two': 971,\n",
       " 'first': 2529,\n",
       " 'case': 7515,\n",
       " 'confirmed': 1832,\n",
       " 'prime': 103,\n",
       " 'minister': 412,\n",
       " 'hit': 805,\n",
       " 'corona': 5479,\n",
       " 'virus': 7988,\n",
       " 'please': 1103,\n",
       " 'pray': 210,\n",
       " 'promoter': 3,\n",
       " 'party': 298,\n",
       " 'club': 99,\n",
       " 'already': 699,\n",
       " 'japan': 869,\n",
       " 'news': 2912,\n",
       " 'least': 491,\n",
       " 'half': 175,\n",
       " 'transmission': 411,\n",
       " 'occur': 14,\n",
       " 'patient': 1538,\n",
       " 'yet': 633,\n",
       " 'showing': 153,\n",
       " 'symptom': 844,\n",
       " 'according': 381,\n",
       " 'university': 326,\n",
       " 'researcher': 180,\n",
       " 'current': 342,\n",
       " 'dividing': 4,\n",
       " 'violence': 85,\n",
       " 'loot': 11,\n",
       " 'shoot': 30,\n",
       " 'fiscal': 33,\n",
       " 'policy': 236,\n",
       " 'top': 490,\n",
       " 'spreading': 778,\n",
       " 'quack': 1,\n",
       " 'vaccine': 1115,\n",
       " 'hate': 168,\n",
       " 'anyone': 572,\n",
       " 'brown': 33,\n",
       " 'need': 2114,\n",
       " 'tip': 209,\n",
       " 'career': 29,\n",
       " 'claim': 335,\n",
       " 'u': 4236,\n",
       " 'worker': 719,\n",
       " 'received': 98,\n",
       " 'evacuee': 75,\n",
       " 'without': 507,\n",
       " 'proper': 95,\n",
       " 'precaution': 252,\n",
       " 'fed': 168,\n",
       " 'slash': 26,\n",
       " 'interest': 113,\n",
       " 'rate': 810,\n",
       " 'close': 561,\n",
       " 'zero': 301,\n",
       " 'boost': 103,\n",
       " 'asset': 36,\n",
       " 'pandemic': 2710,\n",
       " 'aboard': 54,\n",
       " 'coast': 60,\n",
       " 'penny': 386,\n",
       " 'say': 3141,\n",
       " 'big': 581,\n",
       " 'true': 306,\n",
       " 'think': 1526,\n",
       " 'people': 5809,\n",
       " 'get': 3506,\n",
       " 'educated': 21,\n",
       " 'serious': 366,\n",
       " 'beginning': 140,\n",
       " 'impact': 808,\n",
       " 'real': 632,\n",
       " 'gon': 381,\n",
       " 'na': 527,\n",
       " 'die': 622,\n",
       " 'lead': 259,\n",
       " 'response': 1245,\n",
       " 'day': 2098,\n",
       " 'mixed': 23,\n",
       " 'message': 194,\n",
       " 'catholic': 39,\n",
       " 'league': 131,\n",
       " 'today': 1432,\n",
       " 'looking': 332,\n",
       " 'pushing': 72,\n",
       " 'back': 1116,\n",
       " 'week': 1531,\n",
       " 'holding': 90,\n",
       " 'high': 514,\n",
       " 'site': 198,\n",
       " 'situation': 468,\n",
       " 'fluid': 14,\n",
       " 'freight': 5,\n",
       " 'pattern': 25,\n",
       " 'plus': 141,\n",
       " 'timely': 38,\n",
       " 'safety': 275,\n",
       " 'record': 261,\n",
       " 'shipping': 57,\n",
       " 'product': 152,\n",
       " 'important': 515,\n",
       " 'time': 2621,\n",
       " 'year': 1315,\n",
       " 'take': 1432,\n",
       " 'minute': 172,\n",
       " 'watch': 647,\n",
       " 'update': 1667,\n",
       " 'awake': 9,\n",
       " 'useful': 55,\n",
       " 'information': 593,\n",
       " 'protect': 571,\n",
       " 'silver': 59,\n",
       " 'sol': 1,\n",
       " 'cure': 465,\n",
       " 'ointment': 1,\n",
       " 'insertion': 9,\n",
       " 'franklin': 5,\n",
       " 'graham': 11,\n",
       " 'anus': 1,\n",
       " 'subject': 37,\n",
       " 'additional': 134,\n",
       " 'conte': 14,\n",
       " 'wa': 3564,\n",
       " 'live': 1038,\n",
       " 'hour': 419,\n",
       " 'ago': 358,\n",
       " 'follow': 354,\n",
       " 'un': 148,\n",
       " 'da': 21,\n",
       " 'al': 50,\n",
       " 'salute': 25,\n",
       " 'military': 134,\n",
       " 'hospital': 1189,\n",
       " 'needle': 14,\n",
       " 'even': 1207,\n",
       " 'gate': 170,\n",
       " 'foundation': 74,\n",
       " 'responsible': 163,\n",
       " 'company': 469,\n",
       " 'gain': 76,\n",
       " 'council': 78,\n",
       " 'begun': 38,\n",
       " 'homeless': 59,\n",
       " 'temporary': 59,\n",
       " 'accommodation': 10,\n",
       " 'tory': 77,\n",
       " 'ease': 52,\n",
       " 'help': 1501,\n",
       " 'slow': 210,\n",
       " 'spread': 2837,\n",
       " 'identify': 94,\n",
       " 'risk': 1066,\n",
       " 'sooner': 67,\n",
       " 'daily': 593,\n",
       " 'mask': 1383,\n",
       " 'contact': 455,\n",
       " 'isolation': 182,\n",
       " 'also': 1101,\n",
       " 'wearing': 266,\n",
       " 'disposable': 16,\n",
       " 'gown': 8,\n",
       " 'sometimes': 43,\n",
       " 'eye': 187,\n",
       " 'coverage': 185,\n",
       " 'well': 1274,\n",
       " 'deal': 346,\n",
       " 'illness': 377,\n",
       " 'touching': 66,\n",
       " 'save': 296,\n",
       " 'medical': 731,\n",
       " 'personnel': 44,\n",
       " 'thread': 262,\n",
       " 'briefing': 213,\n",
       " 'inner': 11,\n",
       " 'city': 1089,\n",
       " 'press': 274,\n",
       " 'corrupt': 37,\n",
       " 'ha': 6289,\n",
       " 'question': 557,\n",
       " 'china': 7521,\n",
       " 'death': 3645,\n",
       " 'toll': 792,\n",
       " 'rise': 502,\n",
       " 'report': 1505,\n",
       " 'fatality': 251,\n",
       " 'could': 1775,\n",
       " 'naturally': 22,\n",
       " 'former': 157,\n",
       " 'director': 170,\n",
       " 'til': 29,\n",
       " 'business': 943,\n",
       " 'moment': 203,\n",
       " 'fill': 25,\n",
       " 'survey': 80,\n",
       " 'share': 444,\n",
       " 'confidential': 4,\n",
       " 'hey': 211,\n",
       " 'guy': 400,\n",
       " 'wake': 158,\n",
       " 'three': 451,\n",
       " 'state': 1847,\n",
       " 'currently': 227,\n",
       " 'capacity': 107,\n",
       " 'run': 239,\n",
       " 'test': 1711,\n",
       " 'locally': 28,\n",
       " 'association': 48,\n",
       " 'public': 1482,\n",
       " 'health': 4237,\n",
       " 'laboratory': 114,\n",
       " 'told': 415,\n",
       " 'pretty': 219,\n",
       " 'sure': 562,\n",
       " 'reduce': 152,\n",
       " 'population': 332,\n",
       " 'set': 299,\n",
       " 'control': 558,\n",
       " 'aka': 71,\n",
       " 'housing': 76,\n",
       " 'fair': 70,\n",
       " 'better': 634,\n",
       " 'commercial': 66,\n",
       " 'investment': 92,\n",
       " 'remember': 340,\n",
       " 'great': 723,\n",
       " 'depression': 44,\n",
       " 'start': 617,\n",
       " 'freak': 31,\n",
       " 'cause': 560,\n",
       " 'stock': 752,\n",
       " 'market': 1151,\n",
       " 'crash': 98,\n",
       " 'ignorance': 41,\n",
       " 'cripple': 13,\n",
       " 'ever': 365,\n",
       " 'chance': 261,\n",
       " 'number': 1384,\n",
       " 'reflected': 3,\n",
       " 'enough': 395,\n",
       " 'testing': 1059,\n",
       " 'kit': 232,\n",
       " 'untested': 8,\n",
       " 'common': 311,\n",
       " 'cold': 292,\n",
       " 'may': 1701,\n",
       " 'weekend': 239,\n",
       " 'still': 1320,\n",
       " 'pick': 64,\n",
       " 'incompetence': 88,\n",
       " 'world': 2280,\n",
       " 'completely': 137,\n",
       " 'understand': 235,\n",
       " 'decision': 209,\n",
       " 'feel': 462,\n",
       " 'sad': 193,\n",
       " 'angry': 45,\n",
       " 'someone': 489,\n",
       " 'make': 1320,\n",
       " 'plague': 185,\n",
       " 'become': 275,\n",
       " 'disaster': 129,\n",
       " 'really': 924,\n",
       " 'worried': 367,\n",
       " 'parent': 173,\n",
       " 'living': 212,\n",
       " 'hope': 728,\n",
       " 'everyone': 834,\n",
       " 'safely': 57,\n",
       " 'strong': 163,\n",
       " 'saa': 2,\n",
       " 'union': 107,\n",
       " 'job': 493,\n",
       " 'banker': 11,\n",
       " 'away': 565,\n",
       " 'blamed': 54,\n",
       " 'unemployment': 86,\n",
       " 'hunger': 25,\n",
       " 'worship': 22,\n",
       " 'essential': 144,\n",
       " 'part': 510,\n",
       " 'life': 1082,\n",
       " 'many': 1339,\n",
       " 'choose': 50,\n",
       " 'gather': 40,\n",
       " 'practice': 150,\n",
       " 'song': 98,\n",
       " 'give': 653,\n",
       " 'peace': 70,\n",
       " 'mind': 195,\n",
       " 'amid': 1052,\n",
       " 'fear': 1258,\n",
       " 'havoc': 33,\n",
       " 'supply': 365,\n",
       " 'chain': 156,\n",
       " 'restaurant': 226,\n",
       " 'owner': 116,\n",
       " 'starting': 214,\n",
       " 'see': 1366,\n",
       " 'call': 713,\n",
       " 'meat': 93,\n",
       " 'shortage': 166,\n",
       " 'relation': 37,\n",
       " 'demand': 243,\n",
       " 'scare': 190,\n",
       " 'official': 1306,\n",
       " 'break': 240,\n",
       " 'wildlife': 70,\n",
       " 'epidemic': 638,\n",
       " 'approach': 105,\n",
       " 'read': 803,\n",
       " 'must': 557,\n",
       " 'act': 213,\n",
       " 'inaccurate': 11,\n",
       " 'ice': 62,\n",
       " 'buy': 285,\n",
       " 'deportation': 6,\n",
       " 'flight': 661,\n",
       " 'nothing': 467,\n",
       " 'treatment': 441,\n",
       " 'everything': 390,\n",
       " 'keeping': 176,\n",
       " 'pipeline': 8,\n",
       " 'open': 391,\n",
       " 'one': 2520,\n",
       " 'rewarding': 1,\n",
       " 'edit': 3,\n",
       " 'far': 664,\n",
       " 'month': 741,\n",
       " 'lee': 25,\n",
       " 'discus': 202,\n",
       " 'trade': 227,\n",
       " 'economy': 707,\n",
       " 'inside': 172,\n",
       " 'tired': 76,\n",
       " 'outside': 387,\n",
       " 'glad': 101,\n",
       " 'canada': 484,\n",
       " 'deadly': 716,\n",
       " 'notice': 132,\n",
       " 'misinformation': 141,\n",
       " 'check': 554,\n",
       " 'reliable': 45,\n",
       " 'bad': 581,\n",
       " 'aware': 101,\n",
       " 'hurricane': 16,\n",
       " 'safe': 705,\n",
       " 'return': 241,\n",
       " 'celebrated': 8,\n",
       " 'travel': 1115,\n",
       " 'voucher': 8,\n",
       " 'date': 176,\n",
       " 'due': 1658,\n",
       " 'able': 234,\n",
       " 'obtain': 7,\n",
       " 'thank': 463,\n",
       " 'advance': 46,\n",
       " 'lesson': 116,\n",
       " 'bay': 94,\n",
       " 'area': 403,\n",
       " 'community': 642,\n",
       " 'college': 151,\n",
       " 'district': 171,\n",
       " 'taking': 467,\n",
       " 'different': 292,\n",
       " 'stem': 41,\n",
       " 'oh': 343,\n",
       " 'come': 942,\n",
       " 'join': 311,\n",
       " 'reopen': 127,\n",
       " 'based': 197,\n",
       " 'finding': 99,\n",
       " 'child': 418,\n",
       " 'carrier': 89,\n",
       " 'sorry': 144,\n",
       " 'democrat': 341,\n",
       " 'barely': 26,\n",
       " 'blip': 6,\n",
       " 'socialist': 25,\n",
       " 'utopian': 1,\n",
       " 'dream': 58,\n",
       " 'end': 571,\n",
       " 'figure': 231,\n",
       " 'know': 2134,\n",
       " 'hard': 348,\n",
       " 'total': 838,\n",
       " 'tested': 980,\n",
       " 'exam': 45,\n",
       " 'concern': 821,\n",
       " 'ave': 4,\n",
       " 'caught': 124,\n",
       " 'fae': 1,\n",
       " 'absolutely': 122,\n",
       " 'rattling': 4,\n",
       " 'height': 16,\n",
       " 'cleaner': 25,\n",
       " 'taught': 21,\n",
       " 'fact': 495,\n",
       " 'manner': 20,\n",
       " 'lady': 94,\n",
       " 'york': 432,\n",
       " 'doctor': 775,\n",
       " 'antiviral': 71,\n",
       " 'spending': 83,\n",
       " 'six': 156,\n",
       " 'jail': 73,\n",
       " 'returned': 85,\n",
       " 'senate': 102,\n",
       " 'fury': 5,\n",
       " 'infected': 1123,\n",
       " 'recently': 191,\n",
       " 'admitted': 61,\n",
       " 'tell': 564,\n",
       " 'covid': 519,\n",
       " 'ward': 51,\n",
       " 'nurse': 218,\n",
       " 'social': 654,\n",
       " 'clear': 218,\n",
       " 'listing': 8,\n",
       " 'industry': 286,\n",
       " 'code': 51,\n",
       " 'sic': 3,\n",
       " 'sustaining': 6,\n",
       " 'recession': 109,\n",
       " 'thanks': 528,\n",
       " 'portfolio': 26,\n",
       " 'coming': 594,\n",
       " 'worse': 406,\n",
       " 'decline': 73,\n",
       " 'rental': 16,\n",
       " 'reit': 5,\n",
       " 'oil': 185,\n",
       " 'pill': 15,\n",
       " 'shot': 170,\n",
       " 'entire': 172,\n",
       " 'nervous': 33,\n",
       " 'system': 528,\n",
       " 'study': 459,\n",
       " 'zombie': 62,\n",
       " 'apocalypse': 55,\n",
       " 'thought': 541,\n",
       " 'peaked': 15,\n",
       " 'debacle': 7,\n",
       " 'authority': 385,\n",
       " 'yellow': 18,\n",
       " 'alert': 307,\n",
       " 'swine': 84,\n",
       " 'flu': 1600,\n",
       " 'bird': 53,\n",
       " 'mosquito': 14,\n",
       " 'mad': 63,\n",
       " 'cow': 21,\n",
       " 'whatever': 78,\n",
       " 'else': 288,\n",
       " 'past': 286,\n",
       " 'said': 1162,\n",
       " 'cheap': 41,\n",
       " 'ticket': 63,\n",
       " 'worry': 352,\n",
       " 'mate': 41,\n",
       " 'alright': 44,\n",
       " 'soon': 891,\n",
       " 'avoid': 344,\n",
       " 'sound': 206,\n",
       " 'advice': 289,\n",
       " 'directly': 67,\n",
       " 'good': 1372,\n",
       " 'mention': 76,\n",
       " 'meet': 199,\n",
       " 'clinical': 140,\n",
       " 'criterion': 32,\n",
       " 'education': 133,\n",
       " 'seeking': 60,\n",
       " 'support': 519,\n",
       " 'effort': 376,\n",
       " 'worked': 84,\n",
       " 'partner': 118,\n",
       " 'like': 2827,\n",
       " 'provide': 166,\n",
       " 'list': 262,\n",
       " 'initiative': 65,\n",
       " 'resource': 257,\n",
       " 'promotion': 5,\n",
       " 'um': 17,\n",
       " 'might': 569,\n",
       " 'want': 1083,\n",
       " 'actual': 115,\n",
       " 'article': 419,\n",
       " 'contract': 154,\n",
       " 'direct': 107,\n",
       " 'recommendation': 88,\n",
       " 'white': 441,\n",
       " 'house': 536,\n",
       " 'task': 152,\n",
       " 'force': 294,\n",
       " 'trump': 3466,\n",
       " 'tweet': 292,\n",
       " 'took': 200,\n",
       " 'government': 1402,\n",
       " 'advise': 31,\n",
       " 'remain': 155,\n",
       " 'home': 1412,\n",
       " 'rest': 187,\n",
       " 'instead': 246,\n",
       " 'rushing': 11,\n",
       " 'mild': 107,\n",
       " 'got': 1124,\n",
       " 'yes': 366,\n",
       " 'going': 1552,\n",
       " 'moving': 98,\n",
       " 'forget': 175,\n",
       " 'mislead': 7,\n",
       " 'view': 134,\n",
       " 'increase': 303,\n",
       " 'meeting': 292,\n",
       " 'decided': 89,\n",
       " 'go': 1592,\n",
       " 'coe': 1,\n",
       " 'another': 685,\n",
       " 'form': 119,\n",
       " 'sexual': 23,\n",
       " 'abuse': 52,\n",
       " 'childhood': 13,\n",
       " 'cable': 9,\n",
       " 'oddity': 1,\n",
       " 'continent': 36,\n",
       " 'despite': 309,\n",
       " 'huge': 194,\n",
       " 'role': 103,\n",
       " 'story': 542,\n",
       " 'link': 312,\n",
       " 'suffering': 115,\n",
       " 'poor': 188,\n",
       " 'hello': 60,\n",
       " 'speak': 117,\n",
       " 'specific': 65,\n",
       " 'ten': 97,\n",
       " 'since': 759,\n",
       " 'expressed': 20,\n",
       " 'confidence': 68,\n",
       " 'step': 296,\n",
       " 'taken': 238,\n",
       " 'contain': 252,\n",
       " 'thing': 1215,\n",
       " 'bidet': 4,\n",
       " 'toilet': 196,\n",
       " 'everywhere': 105,\n",
       " 'paper': 279,\n",
       " 'wash': 354,\n",
       " 'butt': 17,\n",
       " 'clean': 132,\n",
       " 'insight': 66,\n",
       " 'copping': 2,\n",
       " 'flack': 2,\n",
       " 'trying': 482,\n",
       " 'discredit': 6,\n",
       " 'analysis': 152,\n",
       " 'seen': 364,\n",
       " 'us': 55,\n",
       " 'evidence': 228,\n",
       " 'source': 356,\n",
       " 'justify': 23,\n",
       " 'assessment': 74,\n",
       " 'brace': 54,\n",
       " 'nightmare': 48,\n",
       " 'wondering': 111,\n",
       " 'seem': 146,\n",
       " 'axe': 1,\n",
       " 'budget': 103,\n",
       " 'wall': 204,\n",
       " 'suppose': 34,\n",
       " 'pay': 278,\n",
       " 'god': 487,\n",
       " 'heal': 29,\n",
       " 'land': 73,\n",
       " 'meanwhile': 111,\n",
       " 'let': 968,\n",
       " 'continue': 347,\n",
       " 'stay': 936,\n",
       " 'hand': 969,\n",
       " 'regularly': 51,\n",
       " 'joke': 235,\n",
       " 'wait': 332,\n",
       " 'till': 107,\n",
       " 'vanguard': 1,\n",
       " 'cooper': 8,\n",
       " 'blast': 30,\n",
       " 'doe': 1177,\n",
       " 'kil': 1,\n",
       " 'beyond': 124,\n",
       " 'belief': 87,\n",
       " 'fool': 62,\n",
       " 'ca': 547,\n",
       " 'stop': 1136,\n",
       " 'trest': 1,\n",
       " 'actually': 388,\n",
       " 'counting': 39,\n",
       " 'con': 49,\n",
       " 'man': 754,\n",
       " 'honest': 50,\n",
       " 'put': 561,\n",
       " 'charge': 201,\n",
       " 'republican': 176,\n",
       " 'storm': 73,\n",
       " 'slam': 45,\n",
       " 'administration': 355,\n",
       " 'agree': 165,\n",
       " 'cut': 395,\n",
       " 'work': 1280,\n",
       " 'yesterday': 261,\n",
       " 'pathogen': 83,\n",
       " 'blood': 159,\n",
       " 'bank': 162,\n",
       " 'notable': 12,\n",
       " 'location': 85,\n",
       " 'unprotected': 8,\n",
       " 'exposed': 180,\n",
       " 'victim': 211,\n",
       " 'improper': 2,\n",
       " 'protection': 185,\n",
       " 'failure': 122,\n",
       " 'province': 401,\n",
       " 'medium': 822,\n",
       " 'risen': 40,\n",
       " 'statistic': 87,\n",
       " 'suspected': 315,\n",
       " 'likely': 488,\n",
       " 'global': 1582,\n",
       " 'perspective': 103,\n",
       " 'conversation': 101,\n",
       " 'weighing': 9,\n",
       " 'morning': 264,\n",
       " 'swimmer': 1,\n",
       " 'find': 587,\n",
       " 'outlet': 37,\n",
       " 'water': 214,\n",
       " 'grandma': 18,\n",
       " 'blessed': 20,\n",
       " 'irradicate': 1,\n",
       " 'shopping': 76,\n",
       " 'screening': 369,\n",
       " 'begin': 276,\n",
       " 'airport': 587,\n",
       " 'way': 1149,\n",
       " 'maybe': 410,\n",
       " 'expect': 165,\n",
       " 'doubling': 19,\n",
       " 'classic': 22,\n",
       " 'move': 237,\n",
       " 'shameful': 27,\n",
       " 'nation': 278,\n",
       " 'second': 577,\n",
       " 'game': 282,\n",
       " 'organized': 15,\n",
       " 'event': 505,\n",
       " 'unpopular': 9,\n",
       " 'court': 131,\n",
       " 'win': 144,\n",
       " 'shady': 3,\n",
       " 'agenda': 51,\n",
       " 'supreme': 47,\n",
       " 'lack': 168,\n",
       " 'immunity': 131,\n",
       " 'qualify': 9,\n",
       " 'disability': 42,\n",
       " 'law': 168,\n",
       " 'twitter': 352,\n",
       " 'posting': 52,\n",
       " 'possibility': 87,\n",
       " 'censorship': 28,\n",
       " 'getting': 780,\n",
       " 'irrational': 15,\n",
       " 'cry': 46,\n",
       " 'de': 88,\n",
       " 'fit': 67,\n",
       " 'gave': 119,\n",
       " 'air': 305,\n",
       " 'temporarily': 80,\n",
       " 'shanghai': 124,\n",
       " 'commission': 87,\n",
       " 'planet': 91,\n",
       " 'couple': 181,\n",
       " 'happening': 183,\n",
       " 'right': 1078,\n",
       " 'unless': 124,\n",
       " 'throw': 61,\n",
       " 'expedite': 7,\n",
       " 'human': 684,\n",
       " 'race': 199,\n",
       " 'rapidly': 102,\n",
       " 'guardian': 97,\n",
       " 'release': 211,\n",
       " 'political': 288,\n",
       " 'prisoner': 33,\n",
       " 'microphone': 8,\n",
       " 'dead': 472,\n",
       " 'success': 100,\n",
       " 'known': 262,\n",
       " 'pointless': 8,\n",
       " 'next': 670,\n",
       " 'winter': 49,\n",
       " 'modify': 2,\n",
       " 'spring': 137,\n",
       " 'change': 532,\n",
       " 'guess': 249,\n",
       " 'moron': 52,\n",
       " 'would': 1722,\n",
       " 'worthless': 5,\n",
       " 'sort': 61,\n",
       " 'probably': 352,\n",
       " 'strategic': 20,\n",
       " 'lab': 398,\n",
       " 'conference': 282,\n",
       " 'lay': 39,\n",
       " 'blame': 290,\n",
       " 'goofy': 6,\n",
       " 'person': 677,\n",
       " 'shut': 301,\n",
       " 'order': 467,\n",
       " 'video': 607,\n",
       " 'refusing': 32,\n",
       " 'definitely': 137,\n",
       " 'something': 530,\n",
       " 'prepared': 239,\n",
       " 'face': 775,\n",
       " 'learned': 79,\n",
       " 'expert': 737,\n",
       " 'readiness': 23,\n",
       " 'care': 894,\n",
       " 'shown': 69,\n",
       " 'brazil': 148,\n",
       " 'corporate': 37,\n",
       " 'thug': 28,\n",
       " 'disguised': 4,\n",
       " 'baba': 16,\n",
       " 'pride': 15,\n",
       " 'manger': 10,\n",
       " 'plan': 689,\n",
       " 'rent': 51,\n",
       " 'talk': 425,\n",
       " 'bid': 42,\n",
       " 'closure': 155,\n",
       " 'rose': 65,\n",
       " 'exceeding': 18,\n",
       " 'country': 1809,\n",
       " 'met': 41,\n",
       " 'positive': 1445,\n",
       " 'novel': 1741,\n",
       " 'causing': 145,\n",
       " 'church': 150,\n",
       " 'building': 130,\n",
       " 'closed': 332,\n",
       " 'together': 287,\n",
       " 'entrance': 15,\n",
       " 'basic': 105,\n",
       " 'possibly': 108,\n",
       " 'concerning': 72,\n",
       " 'body': 232,\n",
       " 'abandoned': 29,\n",
       " 'rail': 20,\n",
       " 'yard': 12,\n",
       " 'somewhere': 46,\n",
       " 'crudely': 1,\n",
       " 'applied': 11,\n",
       " 'naked': 9,\n",
       " 'waist': 2,\n",
       " 'roast': 3,\n",
       " 'beef': 19,\n",
       " 'wrapper': 2,\n",
       " 'fluttering': 1,\n",
       " 'nearby': 14,\n",
       " 'preprint': 22,\n",
       " 'preclinical': 2,\n",
       " 'manuscript': 5,\n",
       " 'potentially': 100,\n",
       " 'fresh': 70,\n",
       " 'insightful': 10,\n",
       " 'interview': 155,\n",
       " 'bare': 30,\n",
       " 'shelf': 50,\n",
       " 'empty': 98,\n",
       " 'aisle': 9,\n",
       " 'show': 883,\n",
       " 'shopper': 37,\n",
       " 'reaction': 83,\n",
       " 'disturbing': 41,\n",
       " 'problem': 400,\n",
       " 'bash': 12,\n",
       " 'wheeler': 2,\n",
       " 'betty': 4,\n",
       " 'production': 129,\n",
       " 'million': 894,\n",
       " 'issue': 527,\n",
       " 'biological': 81,\n",
       " 'disease': 1255,\n",
       " 'modern': 26,\n",
       " 'la': 204,\n",
       " 'look': 929,\n",
       " 'long': 516,\n",
       " 'anything': 323,\n",
       " 'sorted': 11,\n",
       " 'either': 156,\n",
       " 'side': 154,\n",
       " 'sight': 23,\n",
       " 'kick': 39,\n",
       " 'along': 152,\n",
       " 'attack': 210,\n",
       " 'every': 706,\n",
       " 'respond': 130,\n",
       " 'hack': 22,\n",
       " 'scientific': 91,\n",
       " 'acting': 81,\n",
       " 'x': 78,\n",
       " 'confirm': 156,\n",
       " 'telling': 174,\n",
       " 'resident': 328,\n",
       " 'free': 554,\n",
       " 'calling': 259,\n",
       " 'border': 351,\n",
       " 'fighting': 197,\n",
       " 'employer': 80,\n",
       " 'president': 853,\n",
       " 'ama': 11,\n",
       " 'sat': 36,\n",
       " 'offering': 71,\n",
       " 'bright': 22,\n",
       " 'dull': 3,\n",
       " 'medicine': 205,\n",
       " 'epidemiology': 47,\n",
       " 'discovered': 127,\n",
       " 'scientist': 512,\n",
       " 'investigating': 48,\n",
       " 'pneumonia': 653,\n",
       " 'mike': 210,\n",
       " 'diamond': 142,\n",
       " 'princess': 169,\n",
       " 'quarantine': 916,\n",
       " 'afraid': 152,\n",
       " 'catching': 122,\n",
       " 'selling': 111,\n",
       " 'round': 104,\n",
       " 'trip': 194,\n",
       " 'unfortunately': 78,\n",
       " 'racist': 309,\n",
       " 'knee': 25,\n",
       " 'jerk': 14,\n",
       " 'wo': 265,\n",
       " 'crap': 43,\n",
       " 'falling': 64,\n",
       " 'hysteria': 72,\n",
       " 'talking': 336,\n",
       " 'huh': 41,\n",
       " 'excellent': 94,\n",
       " 'use': 616,\n",
       " 'ai': 145,\n",
       " 'burden': 14,\n",
       " 'radiologist': 2,\n",
       " 'becomes': 110,\n",
       " 'bigger': 108,\n",
       " 'soil': 14,\n",
       " 'origin': 172,\n",
       " 'bat': 264,\n",
       " 'boil': 4,\n",
       " 'eat': 166,\n",
       " 'carry': 77,\n",
       " 'contagious': 164,\n",
       " 'international': 511,\n",
       " 'drew': 20,\n",
       " 'accountable': 24,\n",
       " 'panic': 501,\n",
       " 'hurting': 34,\n",
       " 'money': 441,\n",
       " 'antibody': 112,\n",
       " 'play': 221,\n",
       " 'wish': 216,\n",
       " 'effectively': 40,\n",
       " 'inadvertently': 8,\n",
       " 'complete': 104,\n",
       " 'insensitivity': 1,\n",
       " 'cost': 226,\n",
       " 'resume': 66,\n",
       " 'traveling': 103,\n",
       " 'largely': 31,\n",
       " 'cloistered': 1,\n",
       " 'fellow': 67,\n",
       " 'county': 751,\n",
       " 'hopefully': 95,\n",
       " 'sell': 83,\n",
       " 'grocery': 107,\n",
       " 'store': 290,\n",
       " 'mortgage': 40,\n",
       " 'g': 24,\n",
       " 'hank': 19,\n",
       " 'photo': 140,\n",
       " 'donated': 22,\n",
       " 'plasma': 56,\n",
       " 'recovery': 461,\n",
       " 'credit': 88,\n",
       " 'kudos': 22,\n",
       " 'local': 470,\n",
       " 'clamor': 3,\n",
       " 'shutdown': 140,\n",
       " 'temperature': 74,\n",
       " 'passenger': 525,\n",
       " 'strain': 357,\n",
       " 'silenced': 17,\n",
       " 'orange': 58,\n",
       " 'psychology': 10,\n",
       " 'professor': 112,\n",
       " 'offer': 187,\n",
       " 'handle': 149,\n",
       " 'immigration': 52,\n",
       " 'special': 172,\n",
       " 'examining': 6,\n",
       " 'across': 464,\n",
       " 'latest': 907,\n",
       " 'model': 160,\n",
       " 'infection': 1005,\n",
       " 'nationwide': 92,\n",
       " 'heath': 9,\n",
       " 'governor': 263,\n",
       " 'bill': 372,\n",
       " 'benefit': 138,\n",
       " 'family': 721,\n",
       " 'weekly': 49,\n",
       " 'hatred': 21,\n",
       " 'keep': 905,\n",
       " 'edge': 34,\n",
       " 'incredible': 51,\n",
       " 'super': 148,\n",
       " 'bowl': 34,\n",
       " 'q': 102,\n",
       " 'prep': 51,\n",
       " 'panel': 69,\n",
       " 'point': 513,\n",
       " 'lower': 135,\n",
       " 'stratum': 1,\n",
       " 'society': 111,\n",
       " 'facing': 102,\n",
       " 'particular': 40,\n",
       " 'transmit': 28,\n",
       " 'respect': 96,\n",
       " 'space': 171,\n",
       " 'insider': 116,\n",
       " 'refuse': 77,\n",
       " 'wage': 31,\n",
       " 'reform': 23,\n",
       " 'switched': 8,\n",
       " 'focus': 175,\n",
       " 'ready': 383,\n",
       " 'roll': 85,\n",
       " 'industrial': 22,\n",
       " 'office': 248,\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = set(list(train_df['Tweets']))\n",
    "BOW = {}\n",
    "for tweet in tweets:\n",
    "    tweet = str(tweet)\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in word_tokenize(tweet)]\n",
    "#     unique_words = set(words).intersection(words_list)\n",
    "    for word in words:\n",
    "        s = set([word]).intersection(words_list)\n",
    "        if word not in stop_words and word in s:\n",
    "            if word in BOW:\n",
    "                BOW[word] += 1\n",
    "            else:\n",
    "                BOW[word] = 1\n",
    "\n",
    "BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW =sorted(BOW.items(), key = \n",
    "             lambda kv:(-kv[1], kv[0]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('virus', 7988)\n",
      "('china', 7521)\n",
      "('case', 7515)\n",
      "('ha', 6289)\n",
      "('new', 6059)\n",
      "('people', 5809)\n",
      "('corona', 5479)\n",
      "('health', 4237)\n",
      "('u', 4236)\n",
      "('via', 4166)\n",
      "('outbreak', 4069)\n",
      "('death', 3645)\n",
      "('wa', 3564)\n",
      "('get', 3506)\n",
      "('trump', 3466)\n",
      "('say', 3141)\n",
      "('news', 2912)\n",
      "('spread', 2837)\n",
      "('like', 2827)\n",
      "('pandemic', 2710)\n",
      "('time', 2621)\n",
      "('first', 2529)\n",
      "('one', 2520)\n",
      "('world', 2280)\n",
      "('know', 2134)\n",
      "('need', 2114)\n",
      "('day', 2098)\n",
      "('state', 1847)\n",
      "('confirmed', 1832)\n",
      "('country', 1809)\n",
      "('could', 1775)\n",
      "('novel', 1741)\n",
      "('would', 1722)\n",
      "('test', 1711)\n",
      "('may', 1701)\n",
      "('update', 1667)\n",
      "('due', 1658)\n",
      "('flu', 1600)\n",
      "('go', 1592)\n",
      "('global', 1582)\n",
      "('going', 1552)\n",
      "('patient', 1538)\n",
      "('week', 1531)\n",
      "('think', 1526)\n",
      "('report', 1505)\n",
      "('help', 1501)\n",
      "('public', 1482)\n",
      "('emergency', 1461)\n",
      "('positive', 1445)\n",
      "('take', 1432)\n",
      "('today', 1432)\n",
      "('home', 1412)\n",
      "('government', 1402)\n",
      "('number', 1384)\n",
      "('mask', 1383)\n",
      "('good', 1372)\n",
      "('see', 1366)\n",
      "('many', 1339)\n",
      "('make', 1320)\n",
      "('still', 1320)\n",
      "('year', 1315)\n",
      "('official', 1306)\n",
      "('work', 1280)\n",
      "('well', 1274)\n",
      "('fear', 1258)\n",
      "('disease', 1255)\n",
      "('response', 1245)\n",
      "('thing', 1215)\n",
      "('even', 1207)\n",
      "('hospital', 1189)\n",
      "('doe', 1177)\n",
      "('said', 1162)\n",
      "('market', 1151)\n",
      "('way', 1149)\n",
      "('stop', 1136)\n",
      "('got', 1124)\n",
      "('infected', 1123)\n",
      "('back', 1116)\n",
      "('travel', 1115)\n",
      "('vaccine', 1115)\n",
      "('please', 1103)\n",
      "('also', 1101)\n",
      "('city', 1089)\n",
      "('want', 1083)\n",
      "('life', 1082)\n",
      "('right', 1078)\n",
      "('risk', 1066)\n",
      "('testing', 1059)\n",
      "('amid', 1052)\n",
      "('live', 1038)\n",
      "('crisis', 1037)\n",
      "('infection', 1005)\n",
      "('much', 992)\n",
      "('tested', 980)\n",
      "('two', 971)\n",
      "('hand', 969)\n",
      "('let', 968)\n",
      "('business', 943)\n",
      "('come', 942)\n",
      "('stay', 936)\n",
      "('look', 929)\n",
      "('really', 924)\n",
      "('quarantine', 916)\n",
      "('latest', 907)\n",
      "('keep', 905)\n",
      "('care', 894)\n",
      "('million', 894)\n",
      "('soon', 891)\n",
      "('show', 883)\n",
      "('japan', 869)\n",
      "('around', 864)\n",
      "('last', 864)\n",
      "('president', 853)\n",
      "('symptom', 844)\n",
      "('total', 838)\n",
      "('everyone', 834)\n",
      "('school', 830)\n",
      "('medium', 822)\n",
      "('concern', 821)\n",
      "('rate', 810)\n",
      "('impact', 808)\n",
      "('hit', 805)\n",
      "('read', 803)\n",
      "('toll', 792)\n",
      "('getting', 780)\n",
      "('spreading', 778)\n",
      "('doctor', 775)\n",
      "('face', 775)\n",
      "('since', 759)\n",
      "('man', 754)\n",
      "('stock', 752)\n",
      "('county', 751)\n",
      "('month', 741)\n",
      "('expert', 737)\n",
      "('medical', 731)\n",
      "('hope', 728)\n",
      "('breaking', 727)\n",
      "('great', 723)\n",
      "('family', 721)\n",
      "('worker', 719)\n",
      "('deadly', 716)\n",
      "('call', 713)\n",
      "('economy', 707)\n",
      "('every', 706)\n",
      "('safe', 705)\n",
      "('already', 699)\n",
      "('plan', 689)\n",
      "('another', 685)\n",
      "('human', 684)\n",
      "('person', 677)\n",
      "('next', 670)\n",
      "('far', 664)\n",
      "('fight', 664)\n",
      "('flight', 661)\n",
      "('social', 654)\n",
      "('give', 653)\n",
      "('pneumonia', 653)\n",
      "('made', 651)\n",
      "('watch', 647)\n",
      "('kill', 645)\n",
      "('community', 642)\n",
      "('epidemic', 638)\n",
      "('better', 634)\n",
      "('cruise', 633)\n",
      "('yet', 633)\n",
      "('real', 632)\n",
      "('sick', 624)\n",
      "('die', 622)\n",
      "('start', 617)\n",
      "('use', 616)\n",
      "('video', 607)\n",
      "('coming', 594)\n",
      "('daily', 593)\n",
      "('information', 593)\n",
      "('airport', 587)\n",
      "('find', 587)\n",
      "('never', 583)\n",
      "('bad', 581)\n",
      "('big', 581)\n",
      "('second', 577)\n",
      "('anyone', 572)\n",
      "('end', 571)\n",
      "('protect', 571)\n",
      "('possible', 570)\n",
      "('might', 569)\n",
      "('away', 565)\n",
      "('ship', 565)\n",
      "('lot', 564)\n",
      "('tell', 564)\n",
      "('working', 564)\n",
      "('sure', 562)\n",
      "('close', 561)\n",
      "('put', 561)\n",
      "('cause', 560)\n",
      "('mean', 559)\n",
      "('control', 558)\n",
      "('must', 557)\n",
      "('question', 557)\n",
      "('check', 554)\n",
      "('free', 554)\n",
      "('data', 552)\n",
      "('ca', 547)\n",
      "('story', 542)\n",
      "('thought', 541)\n",
      "('house', 536)\n",
      "('post', 534)\n",
      "('change', 532)\n",
      "('student', 532)\n",
      "('something', 530)\n",
      "('system', 528)\n",
      "('thanks', 528)\n",
      "('issue', 527)\n",
      "('na', 527)\n",
      "('passenger', 525)\n",
      "('best', 523)\n",
      "('covid', 519)\n",
      "('support', 519)\n",
      "('long', 516)\n",
      "('important', 515)\n",
      "('high', 514)\n",
      "('point', 513)\n",
      "('scientist', 512)\n",
      "('international', 511)\n",
      "('part', 510)\n",
      "('without', 507)\n",
      "('event', 505)\n",
      "('rise', 502)\n",
      "('threat', 502)\n",
      "('panic', 501)\n",
      "('national', 499)\n",
      "('fact', 495)\n",
      "('food', 495)\n",
      "('place', 495)\n",
      "('job', 493)\n",
      "('least', 491)\n",
      "('top', 490)\n",
      "('someone', 489)\n",
      "('likely', 488)\n",
      "('god', 487)\n",
      "('canada', 484)\n",
      "('prevent', 482)\n",
      "('trying', 482)\n",
      "('dead', 472)\n",
      "('economic', 470)\n",
      "('local', 470)\n",
      "('woman', 470)\n",
      "('company', 469)\n",
      "('making', 469)\n",
      "('south', 469)\n",
      "('situation', 468)\n",
      "('nothing', 467)\n",
      "('order', 467)\n",
      "('taking', 467)\n",
      "('measure', 466)\n",
      "('cure', 465)\n",
      "('across', 464)\n",
      "('believe', 464)\n",
      "('thank', 463)\n",
      "('feel', 462)\n",
      "('recovery', 461)\n",
      "('study', 459)\n",
      "('contact', 455)\n",
      "('saying', 453)\n",
      "('three', 451)\n",
      "('found', 445)\n",
      "('share', 444)\n",
      "('money', 441)\n",
      "('treatment', 441)\n",
      "('white', 441)\n",
      "('team', 440)\n",
      "('done', 436)\n",
      "('york', 432)\n",
      "('drug', 429)\n",
      "('organization', 428)\n",
      "('talk', 425)\n",
      "('article', 419)\n",
      "('hour', 419)\n",
      "('child', 418)\n",
      "('united', 417)\n",
      "('told', 415)\n",
      "('minister', 412)\n",
      "('transmission', 411)\n",
      "('maybe', 410)\n",
      "('friend', 408)\n",
      "('full', 408)\n",
      "('declared', 407)\n",
      "('worse', 406)\n",
      "('area', 403)\n",
      "('province', 401)\n",
      "('guy', 400)\n",
      "('love', 400)\n",
      "('problem', 400)\n",
      "('lab', 398)\n",
      "('cut', 395)\n",
      "('enough', 395)\n",
      "('little', 395)\n",
      "('result', 393)\n",
      "('open', 391)\n",
      "('everything', 390)\n",
      "('actually', 388)\n",
      "('major', 387)\n",
      "('outside', 387)\n",
      "('penny', 386)\n",
      "('authority', 385)\n",
      "('staff', 384)\n",
      "('ready', 383)\n",
      "('according', 381)\n",
      "('gon', 381)\n",
      "('sign', 380)\n",
      "('service', 378)\n",
      "('illness', 377)\n",
      "('protest', 377)\n",
      "('effort', 376)\n",
      "('bill', 372)\n",
      "('screening', 369)\n",
      "('worried', 367)\n",
      "('serious', 366)\n",
      "('yes', 366)\n",
      "('ever', 365)\n",
      "('supply', 365)\n",
      "('research', 364)\n",
      "('seen', 364)\n",
      "('ago', 358)\n",
      "('leader', 357)\n",
      "('strain', 357)\n",
      "('source', 356)\n",
      "('administration', 355)\n",
      "('low', 355)\n",
      "('follow', 354)\n",
      "('wash', 354)\n",
      "('probably', 352)\n",
      "('twitter', 352)\n",
      "('worry', 352)\n",
      "('border', 351)\n",
      "('hard', 348)\n",
      "('june', 348)\n",
      "('continue', 347)\n",
      "('deal', 346)\n",
      "('avoid', 344)\n",
      "('oh', 343)\n",
      "('current', 342)\n",
      "('democrat', 341)\n",
      "('potential', 340)\n",
      "('reason', 340)\n",
      "('remember', 340)\n",
      "('old', 339)\n",
      "('cancel', 338)\n",
      "('talking', 336)\n",
      "('claim', 335)\n",
      "('name', 335)\n",
      "('war', 334)\n",
      "('ban', 333)\n",
      "('citizen', 333)\n",
      "('closed', 332)\n",
      "('looking', 332)\n",
      "('population', 332)\n",
      "('wait', 332)\n",
      "('thousand', 329)\n",
      "('affected', 328)\n",
      "('resident', 328)\n",
      "('animal', 327)\n",
      "('level', 327)\n",
      "('university', 326)\n",
      "('black', 325)\n",
      "('type', 325)\n",
      "('anything', 323)\n",
      "('always', 321)\n",
      "('early', 321)\n",
      "('science', 320)\n",
      "('march', 319)\n",
      "('member', 318)\n",
      "('came', 317)\n",
      "('suspected', 315)\n",
      "('link', 312)\n",
      "('common', 311)\n",
      "('join', 311)\n",
      "('despite', 309)\n",
      "('racist', 309)\n",
      "('used', 309)\n",
      "('action', 308)\n",
      "('alert', 307)\n",
      "('center', 307)\n",
      "('lie', 307)\n",
      "('racism', 307)\n",
      "('true', 306)\n",
      "('air', 305)\n",
      "('word', 305)\n",
      "('increase', 303)\n",
      "('whole', 302)\n",
      "('hong', 301)\n",
      "('shut', 301)\n",
      "('zero', 301)\n",
      "('employee', 300)\n",
      "('warning', 300)\n",
      "('set', 299)\n",
      "('party', 298)\n",
      "('hear', 297)\n",
      "('available', 296)\n",
      "('save', 296)\n",
      "('step', 296)\n",
      "('force', 294)\n",
      "('line', 294)\n",
      "('cold', 292)\n",
      "('different', 292)\n",
      "('learn', 292)\n",
      "('meeting', 292)\n",
      "('tweet', 292)\n",
      "('leave', 291)\n",
      "('blame', 290)\n",
      "('store', 290)\n",
      "('try', 290)\n",
      "('advice', 289)\n",
      "('else', 288)\n",
      "('future', 288)\n",
      "('political', 288)\n",
      "('price', 288)\n",
      "('group', 287)\n",
      "('per', 287)\n",
      "('together', 287)\n",
      "('industry', 286)\n",
      "('past', 286)\n",
      "('buy', 285)\n",
      "('truth', 285)\n",
      "('conference', 282)\n",
      "('game', 282)\n",
      "('dying', 280)\n",
      "('effect', 280)\n",
      "('catch', 279)\n",
      "('paper', 279)\n",
      "('nation', 278)\n",
      "('pay', 278)\n",
      "('left', 277)\n",
      "('begin', 276)\n",
      "('matter', 276)\n",
      "('become', 275)\n",
      "('safety', 275)\n",
      "('press', 274)\n",
      "('department', 271)\n",
      "('street', 271)\n",
      "('almost', 270)\n",
      "('behind', 270)\n",
      "('head', 270)\n",
      "('higher', 270)\n",
      "('healthy', 269)\n",
      "('wrong', 268)\n",
      "('negative', 267)\n",
      "('wearing', 266)\n",
      "('though', 265)\n",
      "('wo', 265)\n",
      "('bat', 264)\n",
      "('morning', 264)\n",
      "('prayer', 264)\n",
      "('respiratory', 264)\n",
      "('restriction', 264)\n",
      "('governor', 263)\n",
      "('following', 262)\n",
      "('known', 262)\n",
      "('list', 262)\n",
      "('related', 262)\n",
      "('thread', 262)\n",
      "('wear', 262)\n",
      "('worst', 262)\n",
      "('chance', 261)\n",
      "('record', 261)\n",
      "('season', 261)\n",
      "('yesterday', 261)\n",
      "('calling', 259)\n",
      "('condition', 259)\n",
      "('federal', 259)\n",
      "('lead', 259)\n",
      "('police', 259)\n",
      "('especially', 258)\n",
      "('among', 257)\n",
      "('hold', 257)\n",
      "('resource', 257)\n",
      "('san', 256)\n",
      "('bring', 255)\n",
      "('dangerous', 255)\n",
      "('fake', 255)\n",
      "('contain', 252)\n",
      "('night', 252)\n",
      "('precaution', 252)\n",
      "('statement', 252)\n",
      "('fatality', 251)\n",
      "('hoax', 251)\n",
      "('guess', 249)\n",
      "('office', 248)\n",
      "('wonder', 248)\n",
      "('listen', 247)\n",
      "('instead', 246)\n",
      "('ministry', 246)\n",
      "('idea', 245)\n",
      "('immune', 245)\n",
      "('challenge', 243)\n",
      "('demand', 243)\n",
      "('infectious', 243)\n",
      "('prepare', 243)\n",
      "('chief', 241)\n",
      "('return', 241)\n",
      "('break', 240)\n",
      "('prepared', 239)\n",
      "('run', 239)\n",
      "('weekend', 239)\n",
      "('beer', 238)\n",
      "('taken', 238)\n",
      "('move', 237)\n",
      "('policy', 236)\n",
      "('joke', 235)\n",
      "('turn', 235)\n",
      "('understand', 235)\n",
      "('able', 234)\n",
      "('central', 234)\n",
      "('given', 233)\n",
      "('body', 232)\n",
      "('history', 232)\n",
      "('kit', 232)\n",
      "('damn', 231)\n",
      "('figure', 231)\n",
      "('fall', 230)\n",
      "('mass', 229)\n",
      "('evidence', 228)\n",
      "('small', 228)\n",
      "('went', 228)\n",
      "('currently', 227)\n",
      "('rule', 227)\n",
      "('trade', 227)\n",
      "('cost', 226)\n",
      "('dog', 226)\n",
      "('restaurant', 226)\n",
      "('tomorrow', 226)\n",
      "('ahead', 225)\n",
      "('cough', 225)\n",
      "('regarding', 225)\n",
      "('key', 224)\n",
      "('seriously', 224)\n",
      "('visit', 224)\n",
      "('north', 222)\n",
      "('thinking', 222)\n",
      "('apple', 221)\n",
      "('play', 221)\n",
      "('election', 220)\n",
      "('mortality', 220)\n",
      "('pretty', 219)\n",
      "('vote', 219)\n",
      "('clear', 218)\n",
      "('concerned', 218)\n",
      "('happen', 218)\n",
      "('nurse', 218)\n",
      "('spike', 218)\n",
      "('answer', 217)\n",
      "('interesting', 216)\n",
      "('wave', 216)\n",
      "('wish', 216)\n",
      "('class', 215)\n",
      "('lost', 215)\n",
      "('starting', 214)\n",
      "('water', 214)\n",
      "('act', 213)\n",
      "('briefing', 213)\n",
      "('trial', 213)\n",
      "('financial', 212)\n",
      "('living', 212)\n",
      "('five', 211)\n",
      "('hey', 211)\n",
      "('nearly', 211)\n",
      "('release', 211)\n",
      "('relief', 211)\n",
      "('victim', 211)\n",
      "('attack', 210)\n",
      "('mike', 210)\n",
      "('pray', 210)\n",
      "('slow', 210)\n",
      "('decision', 209)\n",
      "('prevention', 209)\n",
      "('tip', 209)\n",
      "('finally', 207)\n",
      "('recent', 207)\n",
      "('ask', 206)\n",
      "('folk', 206)\n",
      "('loss', 206)\n",
      "('reach', 206)\n",
      "('sound', 206)\n",
      "('tonight', 206)\n",
      "('cover', 205)\n",
      "('medicine', 205)\n",
      "('power', 205)\n",
      "('viral', 205)\n",
      "('whether', 205)\n",
      "('effective', 204)\n",
      "('la', 204)\n",
      "('late', 204)\n",
      "('wall', 204)\n",
      "('agency', 203)\n",
      "('moment', 203)\n",
      "('watching', 203)\n",
      "('discus', 202)\n",
      "('kind', 202)\n",
      "('severe', 202)\n",
      "('charge', 201)\n",
      "('gone', 200)\n",
      "('large', 200)\n",
      "('took', 200)\n",
      "('meet', 199)\n",
      "('race', 199)\n",
      "('trust', 199)\n",
      "('fast', 198)\n",
      "('site', 198)\n",
      "('based', 197)\n",
      "('book', 197)\n",
      "('fighting', 197)\n",
      "('killing', 197)\n",
      "('billion', 196)\n",
      "('toilet', 196)\n",
      "('age', 195)\n",
      "('mind', 195)\n",
      "('huge', 194)\n",
      "('message', 194)\n",
      "('scary', 194)\n",
      "('trip', 194)\n",
      "('fox', 193)\n",
      "('happy', 193)\n",
      "('sad', 193)\n",
      "('comment', 192)\n",
      "('within', 192)\n",
      "('recently', 191)\n",
      "('traveler', 191)\n",
      "('feeling', 190)\n",
      "('linked', 190)\n",
      "('saw', 190)\n",
      "('scare', 190)\n",
      "('seeing', 190)\n",
      "('speedy', 190)\n",
      "('sport', 190)\n",
      "('stand', 190)\n",
      "('stupid', 190)\n",
      "('yeah', 190)\n",
      "('drop', 189)\n",
      "('leadership', 189)\n",
      "('map', 189)\n",
      "('period', 189)\n",
      "('imagine', 188)\n",
      "('poor', 188)\n",
      "('eye', 187)\n",
      "('normal', 187)\n",
      "('offer', 187)\n",
      "('rest', 187)\n",
      "('security', 187)\n",
      "('politics', 186)\n",
      "('biggest', 185)\n",
      "('bit', 185)\n",
      "('coverage', 185)\n",
      "('oil', 185)\n",
      "('plague', 185)\n",
      "('protection', 185)\n",
      "('treat', 185)\n",
      "('happening', 183)\n",
      "('influenza', 183)\n",
      "('literally', 183)\n",
      "('giving', 182)\n",
      "('helping', 182)\n",
      "('isolation', 182)\n",
      "('couple', 181)\n",
      "('course', 181)\n",
      "('sent', 181)\n",
      "('access', 180)\n",
      "('detail', 180)\n",
      "('exposed', 180)\n",
      "('fund', 180)\n",
      "('heart', 180)\n",
      "('near', 180)\n",
      "('researcher', 180)\n",
      "('screen', 180)\n",
      "('quickly', 179)\n",
      "('facility', 178)\n",
      "('general', 178)\n",
      "('sense', 178)\n",
      "('young', 178)\n",
      "('affect', 177)\n",
      "('congress', 177)\n",
      "('crazy', 177)\n",
      "('r', 177)\n",
      "('combat', 176)\n",
      "('conspiracy', 176)\n",
      "('date', 176)\n",
      "('handling', 176)\n",
      "('keeping', 176)\n",
      "('rally', 176)\n",
      "('republican', 176)\n",
      "('russia', 176)\n",
      "('development', 175)\n",
      "('focus', 175)\n",
      "('forget', 175)\n",
      "('half', 175)\n",
      "('mystery', 175)\n",
      "('tech', 175)\n",
      "('track', 175)\n",
      "('region', 174)\n",
      "('survive', 174)\n",
      "('telling', 174)\n",
      "('critical', 173)\n",
      "('eating', 173)\n",
      "('fire', 173)\n",
      "('guidance', 173)\n",
      "('hundred', 173)\n",
      "('parent', 173)\n",
      "('sale', 173)\n",
      "('surge', 173)\n",
      "('entire', 172)\n",
      "('four', 172)\n",
      "('inside', 172)\n",
      "('light', 172)\n",
      "('limit', 172)\n",
      "('minute', 172)\n",
      "('origin', 172)\n",
      "('running', 172)\n",
      "('several', 172)\n",
      "('special', 172)\n",
      "('district', 171)\n",
      "('dont', 171)\n",
      "('space', 171)\n",
      "('tax', 171)\n",
      "('director', 170)\n",
      "('gate', 170)\n",
      "('plane', 170)\n",
      "('shot', 170)\n",
      "('opportunity', 169)\n",
      "('princess', 169)\n",
      "('campaign', 168)\n",
      "('fed', 168)\n",
      "('fever', 168)\n",
      "('hate', 168)\n",
      "('lack', 168)\n",
      "('law', 168)\n",
      "('single', 167)\n",
      "('eat', 166)\n",
      "('hell', 166)\n",
      "('provide', 166)\n",
      "('shortage', 166)\n",
      "('solution', 166)\n",
      "('waiting', 166)\n",
      "('agree', 165)\n",
      "('expect', 165)\n",
      "('guideline', 165)\n",
      "('private', 165)\n",
      "('similar', 165)\n",
      "('aid', 164)\n",
      "('attention', 164)\n",
      "('contagious', 164)\n",
      "('responsible', 163)\n",
      "('strong', 163)\n",
      "('alone', 162)\n",
      "('bank', 162)\n",
      "('later', 162)\n",
      "('longer', 162)\n",
      "('sample', 161)\n",
      "('model', 160)\n",
      "('send', 160)\n",
      "('add', 159)\n",
      "('blood', 159)\n",
      "('count', 159)\n",
      "('stuff', 158)\n",
      "('town', 158)\n",
      "('wake', 158)\n",
      "('b', 157)\n",
      "('former', 157)\n",
      "('chain', 156)\n",
      "('confirm', 156)\n",
      "('drink', 156)\n",
      "('either', 156)\n",
      "('six', 156)\n",
      "('closure', 155)\n",
      "('highest', 155)\n",
      "('interview', 155)\n",
      "('remain', 155)\n",
      "('anxiety', 154)\n",
      "('contract', 154)\n",
      "('idiot', 154)\n",
      "('side', 154)\n",
      "('theory', 154)\n",
      "('management', 153)\n",
      "('movie', 153)\n",
      "('petition', 153)\n",
      "('program', 153)\n",
      "('self', 153)\n",
      "('showing', 153)\n",
      "('afraid', 152)\n",
      "('along', 152)\n",
      "('amazing', 152)\n",
      "('analysis', 152)\n",
      "('opinion', 152)\n",
      "('product', 152)\n",
      "('reading', 152)\n",
      "('reduce', 152)\n",
      "('task', 152)\n",
      "('college', 151)\n",
      "('false', 151)\n",
      "('individual', 151)\n",
      "('v', 151)\n",
      "('apparently', 150)\n",
      "('church', 150)\n",
      "('practice', 150)\n",
      "('professional', 150)\n",
      "('dozen', 149)\n",
      "('growing', 149)\n",
      "('handle', 149)\n",
      "('island', 149)\n",
      "('phone', 149)\n",
      "('brazil', 148)\n",
      "('gathering', 148)\n",
      "('growth', 148)\n",
      "('super', 148)\n",
      "('tried', 148)\n",
      "('un', 148)\n",
      "('elderly', 147)\n",
      "('experience', 147)\n",
      "('mayor', 147)\n",
      "('rather', 147)\n",
      "('dow', 146)\n",
      "('seem', 146)\n",
      "('ai', 145)\n",
      "('causing', 145)\n",
      "('climate', 145)\n",
      "('essential', 144)\n",
      "('festival', 144)\n",
      "('headline', 144)\n",
      "('sorry', 144)\n",
      "('win', 144)\n",
      "('wow', 144)\n",
      "('investor', 143)\n",
      "('lying', 143)\n",
      "('room', 143)\n",
      "('diamond', 142)\n",
      "('ill', 142)\n",
      "('officer', 142)\n",
      "('create', 141)\n",
      "('fan', 141)\n",
      "('misinformation', 141)\n",
      "('park', 141)\n",
      "('plus', 141)\n",
      "('push', 141)\n",
      "('raise', 141)\n",
      "('beginning', 140)\n",
      "('clinical', 140)\n",
      "('officially', 140)\n",
      "('photo', 140)\n",
      "('senator', 140)\n",
      "('short', 140)\n",
      "('shutdown', 140)\n",
      "('term', 140)\n",
      "('xi', 140)\n",
      "('miss', 139)\n",
      "('page', 139)\n",
      "('personal', 139)\n",
      "('active', 138)\n",
      "('address', 138)\n",
      "('benefit', 138)\n",
      "('develop', 138)\n",
      "('east', 138)\n",
      "('middle', 138)\n",
      "('nice', 138)\n",
      "('completely', 137)\n",
      "('dear', 137)\n",
      "('definitely', 137)\n",
      "('men', 137)\n",
      "('spring', 137)\n",
      "('tourist', 137)\n",
      "('excuse', 136)\n",
      "('mysterious', 136)\n",
      "('recover', 136)\n",
      "('strategy', 136)\n",
      "('west', 136)\n",
      "('lower', 135)\n",
      "('reality', 135)\n",
      "('additional', 134)\n",
      "('military', 134)\n",
      "('review', 134)\n",
      "('view', 134)\n",
      "('education', 133)\n",
      "('funny', 133)\n",
      "('infect', 133)\n",
      "('knew', 133)\n",
      "('clean', 132)\n",
      "('front', 132)\n",
      "('notice', 132)\n",
      "('senior', 132)\n",
      "('smart', 132)\n",
      "('washing', 132)\n",
      "('bed', 131)\n",
      "('car', 131)\n",
      "('court', 131)\n",
      "('customer', 131)\n",
      "('immunity', 131)\n",
      "('investigation', 131)\n",
      "('jump', 131)\n",
      "('league', 131)\n",
      "('piece', 131)\n",
      "('unknown', 131)\n",
      "('vulnerable', 131)\n",
      "('worth', 131)\n",
      "('building', 130)\n",
      "('exactly', 130)\n",
      "('fun', 130)\n",
      "('girl', 130)\n",
      "('mark', 130)\n",
      "('respond', 130)\n",
      "('disaster', 129)\n",
      "('production', 129)\n",
      "('project', 129)\n",
      "('fine', 128)\n",
      "('forward', 128)\n",
      "('quite', 128)\n",
      "('simple', 128)\n",
      "('discovered', 127)\n",
      "('however', 127)\n",
      "('player', 127)\n",
      "('reopen', 127)\n",
      "('insurance', 126)\n",
      "('note', 126)\n",
      "('summer', 126)\n",
      "('baby', 125)\n",
      "('crowd', 125)\n",
      "('launch', 125)\n",
      "('riot', 125)\n",
      "('beyond', 124)\n",
      "('caught', 124)\n",
      "('consider', 124)\n",
      "('example', 124)\n",
      "('hot', 124)\n",
      "('patent', 124)\n",
      "('shanghai', 124)\n",
      "('unless', 124)\n",
      "('battle', 123)\n",
      "('drinking', 123)\n",
      "('earth', 123)\n",
      "('humanity', 123)\n",
      "('tourism', 123)\n",
      "('absolutely', 122)\n",
      "('catching', 122)\n",
      "('eu', 122)\n",
      "('everybody', 122)\n",
      "('failure', 122)\n",
      "('institute', 122)\n",
      "('warn', 122)\n",
      "('epicenter', 121)\n",
      "('hearing', 121)\n",
      "('led', 121)\n",
      "('impeachment', 120)\n",
      "('remains', 120)\n",
      "('totally', 120)\n",
      "('form', 119)\n",
      "('gave', 119)\n",
      "('hero', 119)\n",
      "('hotel', 119)\n",
      "('nobody', 119)\n",
      "('priority', 119)\n",
      "('series', 119)\n",
      "('w', 119)\n",
      "('ad', 118)\n",
      "('board', 118)\n",
      "('hurt', 118)\n",
      "('nursing', 118)\n",
      "('partner', 118)\n",
      "('present', 118)\n",
      "('urge', 118)\n",
      "('bet', 117)\n",
      "('calm', 117)\n",
      "('dealing', 117)\n",
      "('delay', 117)\n",
      "('difference', 117)\n",
      "('door', 117)\n",
      "('quick', 117)\n",
      "('red', 117)\n",
      "('speak', 117)\n",
      "('immediately', 116)\n",
      "('insider', 116)\n",
      "('lesson', 116)\n",
      "('mother', 116)\n",
      "('owner', 116)\n",
      "('package', 116)\n",
      "('actual', 115)\n",
      "('allow', 115)\n",
      "('bar', 115)\n",
      "('episode', 115)\n",
      "('lung', 115)\n",
      "('shop', 115)\n",
      "('stopped', 115)\n",
      "('suffering', 115)\n",
      "('teacher', 115)\n",
      "('technology', 115)\n",
      "('wan', 115)\n",
      "('wife', 115)\n",
      "('bless', 114)\n",
      "('contagion', 114)\n",
      "('host', 114)\n",
      "('laboratory', 114)\n",
      "('music', 114)\n",
      "('wild', 114)\n",
      "('extra', 113)\n",
      "('interest', 113)\n",
      "('leading', 113)\n",
      "('weapon', 113)\n",
      "('account', 112)\n",
      "('antibody', 112)\n",
      "('brought', 112)\n",
      "('covering', 112)\n",
      "('ensure', 112)\n",
      "('explain', 112)\n",
      "('foreign', 112)\n",
      "('guide', 112)\n",
      "('informed', 112)\n",
      "('professor', 112)\n",
      "('sending', 112)\n",
      "('stuck', 112)\n",
      "('touch', 112)\n",
      "('ya', 112)\n",
      "('build', 111)\n",
      "('communist', 111)\n",
      "('danger', 111)\n",
      "('greater', 111)\n",
      "('learning', 111)\n",
      "('meanwhile', 111)\n",
      "('ongoing', 111)\n",
      "('selling', 111)\n",
      "('society', 111)\n",
      "('wondering', 111)\n",
      "('becomes', 110)\n",
      "('faster', 110)\n",
      "('ground', 110)\n",
      "('highly', 110)\n",
      "('rising', 110)\n",
      "('stimulus', 110)\n",
      "('beach', 109)\n",
      "('exposure', 109)\n",
      "('hygiene', 109)\n",
      "('preparedness', 109)\n",
      "('prison', 109)\n",
      "('recession', 109)\n",
      "('bigger', 108)\n",
      "('northern', 108)\n",
      "('possibly', 108)\n",
      "('secretary', 108)\n",
      "('capacity', 107)\n",
      "('colleague', 107)\n",
      "('damage', 107)\n",
      "('direct', 107)\n",
      "('globally', 107)\n",
      "('grocery', 107)\n",
      "('lose', 107)\n",
      "('mental', 107)\n",
      "('mild', 107)\n",
      "('surface', 107)\n",
      "('till', 107)\n",
      "('union', 107)\n",
      "('cluster', 106)\n",
      "('grow', 106)\n",
      "('hi', 106)\n",
      "('n', 106)\n",
      "('approach', 105)\n",
      "('basic', 105)\n",
      "('boy', 105)\n",
      "('brain', 105)\n",
      "('everywhere', 105)\n",
      "('holiday', 105)\n",
      "('politician', 105)\n",
      "('amount', 104)\n",
      "('complete', 104)\n",
      "('estimate', 104)\n",
      "('often', 104)\n",
      "('round', 104)\n",
      "('although', 103)\n",
      "('boost', 103)\n",
      "('budget', 103)\n",
      "('massive', 103)\n",
      "('perspective', 103)\n",
      "('prime', 103)\n",
      "('protective', 103)\n",
      "('role', 103)\n",
      "('third', 103)\n",
      "('tool', 103)\n",
      "('traveling', 103)\n",
      "('virtual', 103)\n",
      "('weather', 103)\n",
      "('welcome', 103)\n",
      "('beat', 102)\n",
      "('block', 102)\n",
      "('cancer', 102)\n",
      "('facing', 102)\n",
      "('picture', 102)\n",
      "('q', 102)\n",
      "('rapidly', 102)\n",
      "('senate', 102)\n",
      "('aware', 101)\n",
      "('conversation', 101)\n",
      "('glad', 101)\n",
      "('limited', 101)\n",
      "('mouth', 101)\n",
      "('sector', 101)\n",
      "('careful', 100)\n",
      "('closely', 100)\n",
      "('deep', 100)\n",
      "('forced', 100)\n",
      "('potentially', 100)\n",
      "('soap', 100)\n",
      "('speed', 100)\n",
      "('success', 100)\n",
      "('club', 99)\n",
      "('contracted', 99)\n",
      "('difficult', 99)\n",
      "('finding', 99)\n",
      "('leaving', 99)\n",
      "('process', 99)\n",
      "('ta', 99)\n",
      "('wipe', 99)\n",
      "('added', 98)\n",
      "('crash', 98)\n",
      "('empty', 98)\n",
      "('moving', 98)\n",
      "('multiple', 98)\n",
      "('presumptive', 98)\n",
      "('received', 98)\n",
      "('regular', 98)\n",
      "('song', 98)\n",
      "('anyway', 97)\n",
      "('asymptomatic', 97)\n",
      "('base', 97)\n",
      "('boston', 97)\n",
      "('chart', 97)\n",
      "('fly', 97)\n",
      "('gold', 97)\n",
      "('guardian', 97)\n",
      "('halt', 97)\n",
      "('necessary', 97)\n",
      "('perfect', 97)\n",
      "('profit', 97)\n",
      "('struggle', 97)\n",
      "('suggest', 97)\n",
      "('syndrome', 97)\n",
      "('ten', 97)\n",
      "('tour', 97)\n",
      "('busy', 96)\n",
      "('incubation', 96)\n",
      "('perhaps', 96)\n",
      "('protecting', 96)\n",
      "('respect', 96)\n",
      "('hopefully', 95)\n",
      "('image', 95)\n",
      "('increasing', 95)\n",
      "('proper', 95)\n",
      "('reminder', 95)\n",
      "('seek', 95)\n",
      "('speaking', 95)\n",
      "('activity', 94)\n",
      "('bay', 94)\n",
      "('becoming', 94)\n",
      "('campus', 94)\n",
      "('click', 94)\n",
      "('dollar', 94)\n",
      "('drive', 94)\n",
      "('dumb', 94)\n",
      "('excellent', 94)\n",
      "('identify', 94)\n",
      "('impacted', 94)\n",
      "('lady', 94)\n",
      "('operation', 94)\n",
      "('turned', 94)\n",
      "('attempt', 93)\n",
      "('cat', 93)\n",
      "('debate', 93)\n",
      "('liberal', 93)\n",
      "('meat', 93)\n",
      "('ordered', 93)\n",
      "('percent', 93)\n",
      "('posted', 93)\n",
      "('reporter', 93)\n",
      "('simply', 93)\n",
      "('stage', 93)\n",
      "('trend', 93)\n",
      "('ur', 93)\n",
      "('announce', 92)\n",
      "('easy', 92)\n",
      "('investment', 92)\n",
      "('nationwide', 92)\n",
      "('network', 92)\n",
      "('transport', 92)\n",
      "('art', 91)\n",
      "('double', 91)\n",
      "('doubt', 91)\n",
      "('except', 91)\n",
      "('michigan', 91)\n",
      "('planet', 91)\n",
      "('scientific', 91)\n",
      "('vice', 91)\n",
      "('committee', 90)\n",
      "('digital', 90)\n",
      "('discussion', 90)\n",
      "('firm', 90)\n",
      "('fully', 90)\n",
      "('holding', 90)\n",
      "('include', 90)\n",
      "('primary', 90)\n",
      "('sold', 90)\n",
      "('throughout', 90)\n",
      "('affecting', 89)\n",
      "('carrier', 89)\n",
      "('decided', 89)\n",
      "('lax', 89)\n",
      "('nature', 89)\n",
      "('poll', 89)\n",
      "('propaganda', 89)\n",
      "('status', 89)\n",
      "('suspended', 89)\n",
      "('whose', 89)\n",
      "('adult', 88)\n",
      "('brother', 88)\n",
      "('credit', 88)\n",
      "('de', 88)\n",
      "('honestly', 88)\n",
      "('incompetence', 88)\n",
      "('recommendation', 88)\n",
      "('revenue', 88)\n",
      "('rush', 88)\n",
      "('straight', 88)\n",
      "('advisory', 87)\n",
      "('belief', 87)\n",
      "('commission', 87)\n",
      "('cool', 87)\n",
      "('equipment', 87)\n",
      "('globe', 87)\n",
      "('phase', 87)\n",
      "('possibility', 87)\n",
      "('rapid', 87)\n",
      "('statistic', 87)\n",
      "('towards', 87)\n",
      "('delivery', 86)\n",
      "('providing', 86)\n",
      "('shame', 86)\n",
      "('spot', 86)\n",
      "('train', 86)\n",
      "('unemployment', 86)\n",
      "('visitor', 86)\n",
      "('c', 85)\n",
      "('democratic', 85)\n",
      "('evening', 85)\n",
      "('journal', 85)\n",
      "('location', 85)\n",
      "('quarter', 85)\n",
      "('returned', 85)\n",
      "('roll', 85)\n",
      "('target', 85)\n",
      "('training', 85)\n",
      "('violence', 85)\n",
      "('ability', 84)\n",
      "('blaming', 84)\n",
      "('cash', 84)\n",
      "('criminal', 84)\n",
      "('isolated', 84)\n",
      "('letter', 84)\n",
      "('lime', 84)\n",
      "('mail', 84)\n",
      "('majority', 84)\n",
      "('p', 84)\n",
      "('regime', 84)\n",
      "('scenario', 84)\n",
      "('son', 84)\n",
      "('stress', 84)\n",
      "('supporter', 84)\n",
      "('swine', 84)\n",
      "('tracing', 84)\n",
      "('treating', 84)\n",
      "('voice', 84)\n",
      "('worked', 84)\n",
      "('communication', 83)\n",
      "('containment', 83)\n",
      "('driver', 83)\n",
      "('income', 83)\n",
      "('lunar', 83)\n",
      "('main', 83)\n",
      "('mobile', 83)\n",
      "('mostly', 83)\n",
      "('nose', 83)\n",
      "('opening', 83)\n",
      "('pathogen', 83)\n",
      "('reaction', 83)\n",
      "('sell', 83)\n",
      "('sir', 83)\n",
      "('spending', 83)\n",
      "('usual', 83)\n",
      "('brand', 82)\n",
      "('daughter', 82)\n",
      "('decade', 82)\n",
      "('domestic', 82)\n",
      "('dude', 82)\n",
      "('journalist', 82)\n",
      "('king', 82)\n",
      "('ventilator', 82)\n",
      "('acting', 81)\n",
      "('alcohol', 81)\n",
      "('bag', 81)\n",
      "('biological', 81)\n",
      "('dad', 81)\n",
      "('eight', 81)\n",
      "('extended', 81)\n",
      "('film', 81)\n",
      "('flying', 81)\n",
      "('losing', 81)\n",
      "('monitor', 81)\n",
      "('option', 81)\n",
      "('protocol', 81)\n",
      "('realize', 81)\n",
      "('supporting', 81)\n",
      "('basically', 80)\n",
      "('bitch', 80)\n",
      "('camp', 80)\n",
      "('cell', 80)\n",
      "('certain', 80)\n",
      "('employer', 80)\n",
      "('feed', 80)\n",
      "('joe', 80)\n",
      "('search', 80)\n",
      "('supposed', 80)\n",
      "('survey', 80)\n",
      "('temporarily', 80)\n",
      "('traveller', 80)\n",
      "('uncertainty', 80)\n",
      "('volunteer', 80)\n",
      "('zone', 80)\n",
      "('alarm', 79)\n",
      "('capital', 79)\n",
      "('fault', 79)\n",
      "('inequality', 79)\n",
      "('learned', 79)\n",
      "('older', 79)\n",
      "('pressure', 79)\n",
      "('previous', 79)\n",
      "('rich', 79)\n",
      "('snake', 79)\n",
      "('surprise', 79)\n",
      "('suspend', 79)\n",
      "('candidate', 78)\n",
      "('council', 78)\n",
      "('enjoy', 78)\n",
      "('evil', 78)\n",
      "('football', 78)\n",
      "('freedom', 78)\n",
      "('gas', 78)\n",
      "('knowledge', 78)\n",
      "('newly', 78)\n",
      "('peak', 78)\n",
      "('request', 78)\n",
      "('road', 78)\n",
      "('seasonal', 78)\n",
      "('spent', 78)\n",
      "('truly', 78)\n",
      "('unfortunately', 78)\n",
      "('whatever', 78)\n",
      "('x', 78)\n",
      "('carry', 77)\n",
      "('clearly', 77)\n",
      "('conservative', 77)\n",
      "('cross', 77)\n",
      "('donate', 77)\n",
      "('easily', 77)\n",
      "('extremely', 77)\n",
      "('factor', 77)\n",
      "('gun', 77)\n",
      "('refuse', 77)\n",
      "('responsibility', 77)\n",
      "('spend', 77)\n",
      "('tory', 77)\n",
      "('traveled', 77)\n",
      "('walk', 77)\n",
      "('anywhere', 76)\n",
      "('bottle', 76)\n",
      "('correct', 76)\n",
      "('ga', 76)\n",
      "('gain', 76)\n",
      "('hedge', 76)\n",
      "('housing', 76)\n",
      "('importance', 76)\n",
      "('manage', 76)\n",
      "('mention', 76)\n",
      "('shopping', 76)\n",
      "('tired', 76)\n",
      "('vital', 76)\n",
      "('blow', 75)\n",
      "('disruption', 75)\n",
      "('energy', 75)\n",
      "('entry', 75)\n",
      "('evacuee', 75)\n",
      "('praying', 75)\n",
      "('proof', 75)\n",
      "('urgent', 75)\n",
      "('assessment', 74)\n",
      "('beautiful', 74)\n",
      "('bus', 74)\n",
      "('chaos', 74)\n",
      "('choice', 74)\n",
      "('distance', 74)\n",
      "('foundation', 74)\n",
      "('locked', 74)\n",
      "('none', 74)\n",
      "('plant', 74)\n",
      "('premier', 74)\n",
      "('remote', 74)\n",
      "('sister', 74)\n",
      "('standard', 74)\n",
      "('temperature', 74)\n",
      "('accurate', 73)\n",
      "('clinic', 73)\n",
      "('declare', 73)\n",
      "('decline', 73)\n",
      "('guard', 73)\n",
      "('jail', 73)\n",
      "('land', 73)\n",
      "('spoke', 73)\n",
      "('station', 73)\n",
      "('storm', 73)\n",
      "('visiting', 73)\n",
      "('average', 72)\n",
      "('cancellation', 72)\n",
      "('cleaning', 72)\n",
      "('concerning', 72)\n",
      "('crew', 72)\n",
      "('hysteria', 72)\n",
      "('kept', 72)\n",
      "('machine', 72)\n",
      "('pangolin', 72)\n",
      "('previously', 72)\n",
      "('pushing', 72)\n",
      "('seven', 72)\n",
      "('taste', 72)\n",
      "('terrible', 72)\n",
      "('tune', 72)\n",
      "('unprecedented', 72)\n",
      "('widespread', 72)\n",
      "('aka', 71)\n",
      "('antiviral', 71)\n",
      "('bleach', 71)\n",
      "('bunch', 71)\n",
      "('compare', 71)\n",
      "('covered', 71)\n",
      "('guest', 71)\n",
      "('natural', 71)\n",
      "('offering', 71)\n",
      "('preparation', 71)\n",
      "('raising', 71)\n",
      "('revealed', 71)\n",
      "('shutting', 71)\n",
      "('star', 71)\n",
      "('tough', 71)\n",
      "('wrote', 71)\n",
      "('acute', 70)\n",
      "('associated', 70)\n",
      "('considering', 70)\n",
      "('fair', 70)\n",
      "('foot', 70)\n",
      "('fresh', 70)\n",
      "('missing', 70)\n",
      "('peace', 70)\n",
      "('pet', 70)\n",
      "('sander', 70)\n",
      "('stopping', 70)\n",
      "('wildlife', 70)\n",
      "('worrying', 70)\n",
      "('abroad', 69)\n",
      "('attend', 69)\n",
      "('bought', 69)\n",
      "('crime', 69)\n",
      "('disinfectant', 69)\n",
      "('enemy', 69)\n",
      "('era', 69)\n",
      "('everyday', 69)\n",
      "('immediate', 69)\n",
      "('listening', 69)\n",
      "('lock', 69)\n",
      "('luck', 69)\n",
      "('method', 69)\n",
      "('panel', 69)\n",
      "('prof', 69)\n",
      "('receive', 69)\n",
      "('shown', 69)\n",
      "('twice', 69)\n",
      "('ani', 68)\n",
      "('confidence', 68)\n",
      "('curve', 68)\n",
      "('exclusive', 68)\n",
      "('judge', 68)\n",
      "('sequence', 68)\n",
      "('significant', 68)\n",
      "('smell', 68)\n",
      "('sneeze', 68)\n",
      "('spy', 68)\n",
      "('struggling', 68)\n",
      "('afford', 67)\n",
      "('apart', 67)\n",
      "('awareness', 67)\n",
      "('boom', 67)\n",
      "('closer', 67)\n",
      "('directly', 67)\n",
      "('father', 67)\n",
      "('fellow', 67)\n",
      "('fit', 67)\n",
      "('illegal', 67)\n",
      "('lord', 67)\n",
      "('nasty', 67)\n",
      "('promise', 67)\n",
      "('provider', 67)\n",
      "('sooner', 67)\n",
      "('surveillance', 67)\n",
      "('alive', 66)\n",
      "('birthday', 66)\n",
      "('blue', 66)\n",
      "('commercial', 66)\n",
      "('deserve', 66)\n",
      "('earnings', 66)\n",
      "('finance', 66)\n",
      "('green', 66)\n",
      "('hide', 66)\n",
      "('insight', 66)\n",
      "('l', 66)\n",
      "('movement', 66)\n",
      "('otherwise', 66)\n",
      "('pull', 66)\n",
      "('refugee', 66)\n",
      "('resume', 66)\n",
      "('sadly', 66)\n",
      "('stream', 66)\n",
      "('suddenly', 66)\n",
      "('surgical', 66)\n",
      "('touching', 66)\n",
      "('value', 66)\n",
      "('anybody', 65)\n",
      "('channel', 65)\n",
      "('chicken', 65)\n",
      "('exercise', 65)\n",
      "('factory', 65)\n",
      "('field', 65)\n",
      "('gym', 65)\n",
      "('initiative', 65)\n",
      "('reportedly', 65)\n",
      "('rose', 65)\n",
      "('screened', 65)\n",
      "('specific', 65)\n",
      "('upcoming', 65)\n",
      "('weak', 65)\n",
      "('annual', 64)\n",
      "('appear', 64)\n",
      "('connection', 64)\n",
      "('disgusting', 64)\n",
      "('e', 64)\n",
      "('falling', 64)\n",
      "('hospitalization', 64)\n",
      "('match', 64)\n",
      "('minority', 64)\n",
      "('obviously', 64)\n",
      "('pick', 64)\n",
      "('pose', 64)\n",
      "('reduced', 64)\n",
      "('trading', 64)\n",
      "('workplace', 64)\n",
      "('yahoo', 64)\n",
      "('certainly', 63)\n",
      "('consequence', 63)\n",
      "('initial', 63)\n",
      "('intelligence', 63)\n",
      "('knowing', 63)\n",
      "('mad', 63)\n",
      "('math', 63)\n",
      "('narrative', 63)\n",
      "('radio', 63)\n",
      "('saving', 63)\n",
      "('shall', 63)\n",
      "('ticket', 63)\n",
      "('voting', 63)\n",
      "('allergy', 62)\n",
      "('box', 62)\n",
      "('comparison', 62)\n",
      "('dark', 62)\n",
      "('final', 62)\n",
      "('fool', 62)\n",
      "('genome', 62)\n",
      "('husband', 62)\n",
      "('ice', 62)\n",
      "('labour', 62)\n",
      "('li', 62)\n",
      "('pass', 62)\n",
      "('payment', 62)\n",
      "('provided', 62)\n",
      "('recommend', 62)\n",
      "('strike', 62)\n",
      "('suspect', 62)\n",
      "('topic', 62)\n",
      "('tournament', 62)\n",
      "('understanding', 62)\n",
      "('version', 62)\n",
      "('voter', 62)\n",
      "('western', 62)\n",
      "('zombie', 62)\n",
      "('admit', 61)\n",
      "('admitted', 61)\n",
      "('afternoon', 61)\n",
      "('apply', 61)\n",
      "('assistance', 61)\n",
      "('civil', 61)\n",
      "('collapse', 61)\n",
      "('context', 61)\n",
      "('culture', 61)\n",
      "('defense', 61)\n",
      "('donation', 61)\n",
      "('eventually', 61)\n",
      "('extreme', 61)\n",
      "('fired', 61)\n",
      "('grant', 61)\n",
      "('hall', 61)\n",
      "('midst', 61)\n",
      "('rumor', 61)\n",
      "('sky', 61)\n",
      "('sort', 61)\n",
      "('southern', 61)\n",
      "('suck', 61)\n",
      "('sun', 61)\n",
      "('throw', 61)\n",
      "('village', 61)\n",
      "('wide', 61)\n",
      "('card', 60)\n",
      "('coast', 60)\n",
      "('colorado', 60)\n",
      "('concert', 60)\n",
      "('consumer', 60)\n",
      "('enter', 60)\n",
      "('evacuation', 60)\n",
      "('genetic', 60)\n",
      "('germ', 60)\n",
      "('hello', 60)\n",
      "('involved', 60)\n",
      "('plunge', 60)\n",
      "('properly', 60)\n",
      "('scam', 60)\n",
      "('secret', 60)\n",
      "('seeking', 60)\n",
      "('strange', 60)\n",
      "('write', 60)\n",
      "('announcement', 59)\n",
      "('broke', 59)\n",
      "('cotton', 59)\n",
      "('detect', 59)\n",
      "('economist', 59)\n",
      "('epidemiologist', 59)\n",
      "('executive', 59)\n",
      "('exist', 59)\n",
      "('fifth', 59)\n",
      "('fourth', 59)\n",
      "('homeless', 59)\n",
      "('ignore', 59)\n",
      "('justice', 59)\n",
      "('meant', 59)\n",
      "('mistake', 59)\n",
      "('physical', 59)\n",
      "('silver', 59)\n",
      "('ted', 59)\n",
      "('temporary', 59)\n",
      "('upon', 59)\n",
      "('weird', 59)\n",
      "('dream', 58)\n",
      "('faith', 58)\n",
      "('isolate', 58)\n",
      "('orange', 58)\n",
      "('passing', 58)\n",
      "('paying', 58)\n",
      "('port', 58)\n",
      "('preliminary', 58)\n",
      "('scale', 58)\n",
      "('sex', 58)\n",
      "('shift', 58)\n",
      "('traffic', 58)\n",
      "('walking', 58)\n",
      "('bond', 57)\n",
      "('caution', 57)\n",
      "('cope', 57)\n",
      "('corruption', 57)\n",
      "('curb', 57)\n",
      "('diagnosis', 57)\n",
      "('handled', 57)\n",
      "('highlight', 57)\n",
      "('material', 57)\n",
      "('monkey', 57)\n",
      "('retail', 57)\n",
      "('safely', 57)\n",
      "('shipping', 57)\n",
      "('size', 57)\n",
      "('sudden', 57)\n",
      "('suffer', 57)\n",
      "('table', 57)\n",
      "('turkey', 57)\n",
      "('vaccination', 57)\n",
      "('agent', 56)\n",
      "('considered', 56)\n",
      "('ending', 56)\n",
      "('giant', 56)\n",
      "('grand', 56)\n",
      "('harm', 56)\n",
      "('plasma', 56)\n",
      "('platform', 56)\n",
      "('protester', 56)\n",
      "('ross', 56)\n",
      "('setting', 56)\n",
      "('sue', 56)\n",
      "('transportation', 56)\n",
      "('trigger', 56)\n",
      "('usually', 56)\n",
      "('various', 56)\n",
      "('window', 56)\n",
      "('apocalypse', 55)\n",
      "('arrest', 55)\n",
      "('built', 55)\n",
      "('detection', 55)\n",
      "('favorite', 55)\n",
      "('forecast', 55)\n",
      "('forgot', 55)\n",
      "('helpful', 55)\n",
      "('ignorant', 55)\n",
      "('inevitable', 55)\n",
      "('loan', 55)\n",
      "('neighbor', 55)\n",
      "('outdoors', 55)\n",
      "('pharmaceutical', 55)\n",
      "('position', 55)\n",
      "('raised', 55)\n",
      "('refund', 55)\n",
      "('regulation', 55)\n",
      "('session', 55)\n",
      "('sitting', 55)\n",
      "('speech', 55)\n",
      "('universal', 55)\n",
      "('us', 55)\n",
      "('useful', 55)\n",
      "('watched', 55)\n",
      "('written', 55)\n",
      "('youth', 55)\n",
      "('aboard', 54)\n",
      "('blamed', 54)\n",
      "('brace', 54)\n",
      "('carrying', 54)\n",
      "('climb', 54)\n",
      "('defeat', 54)\n",
      "('glove', 54)\n",
      "('gotten', 54)\n",
      "('household', 54)\n",
      "('mar', 54)\n",
      "('meaning', 54)\n",
      "('particularly', 54)\n",
      "('physician', 54)\n",
      "('queen', 54)\n",
      "('ridiculous', 54)\n",
      "('solidarity', 54)\n",
      "('somebody', 54)\n",
      "('suit', 54)\n",
      "('trace', 54)\n",
      "('transparency', 54)\n",
      "('bird', 53)\n",
      "('cant', 53)\n",
      "('cap', 53)\n",
      "('cop', 53)\n",
      "('debt', 53)\n",
      "('entering', 53)\n",
      "('forever', 53)\n",
      "('goal', 53)\n",
      "('heat', 53)\n",
      "('immigrant', 53)\n",
      "('lift', 53)\n",
      "('marketing', 53)\n",
      "('meal', 53)\n",
      "('personally', 53)\n",
      "('powerful', 53)\n",
      "('rat', 53)\n",
      "('relevant', 53)\n",
      "('soar', 53)\n",
      "('survival', 53)\n",
      "('unlikely', 53)\n",
      "('vacation', 53)\n",
      "('vitamin', 53)\n",
      "('abuse', 52)\n",
      "('army', 52)\n",
      "('awesome', 52)\n",
      "('broken', 52)\n",
      "('coincidence', 52)\n",
      "('creative', 52)\n",
      "('destroy', 52)\n",
      "('dirty', 52)\n",
      "('ease', 52)\n",
      "('emerge', 52)\n",
      "('gear', 52)\n",
      "('holy', 52)\n",
      "('immigration', 52)\n",
      "('institution', 52)\n",
      "('investigate', 52)\n",
      "('killer', 52)\n",
      "('lawmaker', 52)\n",
      "('lied', 52)\n",
      "('moron', 52)\n",
      "('outlook', 52)\n",
      "('pain', 52)\n",
      "('posting', 52)\n",
      "('rip', 52)\n",
      "('shocking', 52)\n",
      "('standing', 52)\n",
      "('text', 52)\n",
      "('useless', 52)\n",
      "('affair', 51)\n",
      "('agenda', 51)\n",
      "('burn', 51)\n",
      "('code', 51)\n",
      "('content', 51)\n",
      "('easing', 51)\n",
      "('environment', 51)\n",
      "('experimental', 51)\n",
      "('farmer', 51)\n",
      "('fatal', 51)\n",
      "('felt', 51)\n",
      "('german', 51)\n",
      "('included', 51)\n",
      "('incredible', 51)\n",
      "('item', 51)\n",
      "('liar', 51)\n",
      "('pilot', 51)\n",
      "('prep', 51)\n",
      "('produce', 51)\n",
      "('racial', 51)\n",
      "('random', 51)\n",
      "('range', 51)\n",
      "('raw', 51)\n",
      "('regularly', 51)\n",
      "('rent', 51)\n",
      "('sit', 51)\n",
      "('tho', 51)\n",
      "('trouble', 51)\n",
      "('underlying', 51)\n",
      "('ward', 51)\n",
      "('yo', 51)\n",
      "('al', 50)\n",
      "('breathing', 50)\n",
      "('checked', 50)\n",
      "('choose', 50)\n",
      "('curious', 50)\n",
      "('decide', 50)\n",
      "('declaration', 50)\n",
      "('disappear', 50)\n",
      "('f', 50)\n",
      "('honest', 50)\n",
      "('legal', 50)\n",
      "('murder', 50)\n",
      "('quiet', 50)\n",
      "('regardless', 50)\n",
      "('register', 50)\n",
      "('seat', 50)\n",
      "('shake', 50)\n",
      "('shelf', 50)\n",
      "('simulation', 50)\n",
      "('sleep', 50)\n",
      "('soup', 50)\n",
      "('tackle', 50)\n",
      "('throat', 50)\n",
      "('arrival', 49)\n",
      "('assume', 49)\n",
      "('audience', 49)\n",
      "('bout', 49)\n",
      "('broadcast', 49)\n",
      "('burning', 49)\n",
      "('chat', 49)\n",
      "('chill', 49)\n",
      "('con', 49)\n",
      "('cricketer', 49)\n",
      "('design', 49)\n",
      "('ended', 49)\n",
      "('experiment', 49)\n",
      "('expose', 49)\n",
      "('impossible', 49)\n",
      "('lethal', 49)\n",
      "('mine', 49)\n",
      "('nine', 49)\n",
      "('prince', 49)\n",
      "('reveal', 49)\n",
      "('summary', 49)\n",
      "('supermarket', 49)\n",
      "('surrounding', 49)\n",
      "('warfare', 49)\n",
      "('waste', 49)\n",
      "('weekly', 49)\n",
      "('welfare', 49)\n",
      "('winter', 49)\n",
      "('wishing', 49)\n",
      "('association', 48)\n",
      "('continued', 48)\n",
      "('crowded', 48)\n",
      "('dashboard', 48)\n",
      "('doc', 48)\n",
      "('excited', 48)\n",
      "('fuel', 48)\n",
      "('harder', 48)\n",
      "('indeed', 48)\n",
      "('investigating', 48)\n",
      "('joint', 48)\n",
      "('mile', 48)\n",
      "('mutation', 48)\n",
      "('nightmare', 48)\n",
      "('prediction', 48)\n",
      "('presidential', 48)\n",
      "('regard', 48)\n",
      "('regional', 48)\n",
      "('relative', 48)\n",
      "('swear', 48)\n",
      "('therapy', 48)\n",
      "('trillion', 48)\n",
      "('valley', 48)\n",
      "('xenophobia', 48)\n",
      "('artist', 47)\n",
      "('deliver', 47)\n",
      "('diagnostic', 47)\n",
      "('epidemiology', 47)\n",
      "('escape', 47)\n",
      "('funeral', 47)\n",
      "('herd', 47)\n",
      "('inmate', 47)\n",
      "('lake', 47)\n",
      "('maker', 47)\n",
      "('mall', 47)\n",
      "('proven', 47)\n",
      "('ramp', 47)\n",
      "('sa', 47)\n",
      "('supreme', 47)\n",
      "('swab', 47)\n",
      "('tally', 47)\n",
      "('turning', 47)\n",
      "('wale', 47)\n",
      "('yep', 47)\n",
      "('advance', 46)\n",
      "('crucial', 46)\n",
      "('cry', 46)\n",
      "('dry', 46)\n",
      "('failing', 46)\n",
      "('fashion', 46)\n",
      "('incredibly', 46)\n",
      "('insane', 46)\n",
      "('mission', 46)\n",
      "('mode', 46)\n",
      "('original', 46)\n",
      "('pic', 46)\n",
      "('pool', 46)\n",
      "('pop', 46)\n",
      "('progress', 46)\n",
      "('salary', 46)\n",
      "('severity', 46)\n",
      "('somewhere', 46)\n",
      "('spark', 46)\n",
      "('survivor', 46)\n",
      "('yr', 46)\n",
      "('amidst', 45)\n",
      "('angry', 45)\n",
      "('bacteria', 45)\n",
      "('ball', 45)\n",
      "('bubble', 45)\n",
      "('celebrity', 45)\n",
      "('driving', 45)\n",
      "('epoch', 45)\n",
      "('exam', 45)\n",
      "('follower', 45)\n",
      "('gay', 45)\n",
      "('horrible', 45)\n",
      "('incompetent', 45)\n",
      "('load', 45)\n",
      "('migrant', 45)\n",
      "('misleading', 45)\n",
      "('mitigate', 45)\n",
      "('mount', 45)\n",
      "('property', 45)\n",
      "('quit', 45)\n",
      "('reliable', 45)\n",
      "('remove', 45)\n",
      "('removed', 45)\n",
      "('robot', 45)\n",
      "('slam', 45)\n",
      "('suggesting', 45)\n",
      "('switch', 45)\n",
      "('wonderful', 45)\n",
      "('advantage', 44)\n",
      "('agreed', 44)\n",
      "('aim', 44)\n",
      "('alright', 44)\n",
      "('analyst', 44)\n",
      "('bug', 44)\n",
      "('celebration', 44)\n",
      "('depression', 44)\n",
      "('deputy', 44)\n",
      "('desperate', 44)\n",
      "('distribution', 44)\n",
      "('earthquake', 44)\n",
      "('foreigner', 44)\n",
      "('independent', 44)\n",
      "('innovation', 44)\n",
      "('interested', 44)\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "for i in range(2000):\n",
    "    print(BOW[i])\n",
    "    vocab.append(BOW[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Vader-sentiment value</th>\n",
       "      <th>Vader-sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I wish quick recovery for talented @TOLOnews J...</td>\n",
       "      <td>2020-04-29 23:33:40+00:00</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>These chinese people on campus are so consider...</td>\n",
       "      <td>2020-01-28 23:41:13</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.5777</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>China’s Leader, Under Fire, Says He Led Corona...</td>\n",
       "      <td>2020-02-15 23:17:09</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>RT @DarrenEuronews: Top 5 countries 🌍 with hig...</td>\n",
       "      <td>Sat Jun 13 07:50:54 +0000 2020</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>RT @MileyCyrus: Spain, you united in solidarit...</td>\n",
       "      <td>Sat Jun 13 09:52:29 +0000 2020</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113566</th>\n",
       "      <td>30500</td>\n",
       "      <td>30500</td>\n",
       "      <td>RT @YourAnonNews: Yesterday, there were 140,92...</td>\n",
       "      <td>Sat Jun 13 11:24:47 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113567</th>\n",
       "      <td>30501</td>\n",
       "      <td>30501</td>\n",
       "      <td>RT @iloharare: In the face of #covid19, we run...</td>\n",
       "      <td>Sat Jun 13 14:12:11 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.3274</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113568</th>\n",
       "      <td>30502</td>\n",
       "      <td>30502</td>\n",
       "      <td>RT @SAfridiOfficial: I’ve been feeling unwell ...</td>\n",
       "      <td>Sat Jun 13 09:52:26 +0000 2020</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.8020</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113569</th>\n",
       "      <td>30503</td>\n",
       "      <td>30503</td>\n",
       "      <td>It must be this Gvt which is worse than corona...</td>\n",
       "      <td>2020-03-02 23:49:25</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113570</th>\n",
       "      <td>30504</td>\n",
       "      <td>30504</td>\n",
       "      <td>BREAKING: Deputy leader of Iran's parliament s...</td>\n",
       "      <td>2020-03-03 23:57:40</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113571 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  \\\n",
       "0                0             0   \n",
       "1                1             1   \n",
       "2                2             2   \n",
       "3                3             3   \n",
       "4                4             4   \n",
       "...            ...           ...   \n",
       "113566       30500         30500   \n",
       "113567       30501         30501   \n",
       "113568       30502         30502   \n",
       "113569       30503         30503   \n",
       "113570       30504         30504   \n",
       "\n",
       "                                                   Tweets  \\\n",
       "0       I wish quick recovery for talented @TOLOnews J...   \n",
       "1       These chinese people on campus are so consider...   \n",
       "2       China’s Leader, Under Fire, Says He Led Corona...   \n",
       "3       RT @DarrenEuronews: Top 5 countries 🌍 with hig...   \n",
       "4       RT @MileyCyrus: Spain, you united in solidarit...   \n",
       "...                                                   ...   \n",
       "113566  RT @YourAnonNews: Yesterday, there were 140,92...   \n",
       "113567  RT @iloharare: In the face of #covid19, we run...   \n",
       "113568  RT @SAfridiOfficial: I’ve been feeling unwell ...   \n",
       "113569  It must be this Gvt which is worse than corona...   \n",
       "113570  BREAKING: Deputy leader of Iran's parliament s...   \n",
       "\n",
       "                                  Date      Country  Vader-sentiment value  \\\n",
       "0            2020-04-29 23:33:40+00:00  afghanistan                 0.9022   \n",
       "1                  2020-01-28 23:41:13  afghanistan                 0.5777   \n",
       "2                  2020-02-15 23:17:09  afghanistan                -0.6124   \n",
       "3       Sat Jun 13 07:50:54 +0000 2020  afghanistan                 0.2732   \n",
       "4       Sat Jun 13 09:52:29 +0000 2020  afghanistan                 0.6249   \n",
       "...                                ...          ...                    ...   \n",
       "113566  Sat Jun 13 11:24:47 +0000 2020     zimbabwe                 0.0000   \n",
       "113567  Sat Jun 13 14:12:11 +0000 2020     zimbabwe                -0.3274   \n",
       "113568  Sat Jun 13 09:52:26 +0000 2020     zimbabwe                -0.8020   \n",
       "113569             2020-03-02 23:49:25     zimbabwe                -0.4767   \n",
       "113570             2020-03-03 23:57:40     zimbabwe                -0.4939   \n",
       "\n",
       "       Vader-sentiment  \n",
       "0             positive  \n",
       "1             positive  \n",
       "2             negative  \n",
       "3             positive  \n",
       "4             positive  \n",
       "...                ...  \n",
       "113566         Neutral  \n",
       "113567        negative  \n",
       "113568        negative  \n",
       "113569        negative  \n",
       "113570        negative  \n",
       "\n",
       "[113571 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordVector(review,max_words):\n",
    "    vector=[]\n",
    "#     print(len(vocab))\n",
    "    words = ([str(word).lower() for word in word_tokenize(str(review))])\n",
    "    for word in vocab:\n",
    "        if word.lower() in words:\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    ?\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = []\n",
    "sentiments = list(train_df['Vader-sentiment']) \n",
    "for sentiment in sentiments:\n",
    "    if sentiment == \"positive\":\n",
    "        train_targets.append([1,0,0])\n",
    "    elif sentiment == \"Neutral\":\n",
    "        train_targets.append([0,1,0])\n",
    "    elif sentiment == \"negative\":\n",
    "        train_targets.append([0,0,1])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "test_targets = []\n",
    "sentiments = list(test_df['Vader-sentiment']) \n",
    "for sentiment in sentiments:\n",
    "    if sentiment == \"positive\":\n",
    "        test_targets.append([1,0,0])\n",
    "    elif sentiment == \"Neutral\":\n",
    "        test_targets.append([0,1,0])\n",
    "    elif sentiment == \"negative\":\n",
    "        test_targets.append([0,0,1])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = list(dataset['Tweets'])\n",
    "max_words = -1\n",
    "for tweet in tweets:\n",
    "    size = len(([str(word).lower() for word in word_tokenize(str(tweet))]))\n",
    "    \n",
    "    if(size > max_words):\n",
    "        max_words = size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = list(train_df['Tweets'])\n",
    "inputs = []\n",
    "for tweet in tweets:\n",
    "    inputs.append(getWordVector(tweet,max_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = list(test_df['Tweets'])\n",
    "testInput = []\n",
    "for tweet in test_tweets:\n",
    "    testInput.append(getWordVector(tweet,max_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "# accuracy_score(list(out), test_targets, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf8 = MLPClassifier(activation='relu',solver='adam',hidden_layer_sizes=(1000),verbose=True,max_iter=1,learning_rate_init=0.001,warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.28872897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anantharam\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 0.7623773584905661\n",
      "test accuracy = 0.7336444483578409\n",
      "\n",
      "Iteration 2, loss = 1.00853627\n",
      "train accuracy = 0.7952578616352202\n",
      "test accuracy = 0.7474391711426139\n",
      "\n",
      "Iteration 3, loss = 0.86492981\n",
      "train accuracy = 0.8372955974842767\n",
      "test accuracy = 0.7501394147515482\n",
      "\n",
      "Iteration 4, loss = 0.69584328\n",
      "train accuracy = 0.889308176100629\n",
      "test accuracy = 0.7552463972293153\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-9bf78e6e65f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mclf8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrainscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtestscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestInput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train accuracy =\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1026\u001b[0m         \"\"\"\n\u001b[0;32m   1027\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[1;32m-> 1028\u001b[1;33m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    324\u001b[0m                              hidden_layer_sizes)\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n\u001b[1;32m--> 965\u001b[1;33m                                    multi_output=True)\n\u001b[0m\u001b[0;32m    966\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    804\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    clf8.fit(inputs,train_targets)\n",
    "    trainscore = clf8.score(inputs,train_targets)\n",
    "    testscore = clf8.score(testInput,test_targets)\n",
    "    print(\"train accuracy =\",trainscore)\n",
    "    print(\"test accuracy =\",testscore)\n",
    "    print()\n",
    "    if(testscore >= 0.85):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.53022488\n",
      "train accuracy = 0.9250817610062894\n",
      "test accuracy = 0.7539843268468785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    clf8.fit(inputs,train_targets)\n",
    "    trainscore = clf8.score(inputs,train_targets)\n",
    "    testscore = clf8.score(testInput,test_targets)\n",
    "    print(\"train accuracy =\",trainscore)\n",
    "    print(\"test accuracy =\",testscore)\n",
    "    print()\n",
    "    if(testscore >= 0.85):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testInput.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf8,'bestclassifier.pkl')\n",
    "joblib.dump(inputs,'inputs.pkl')\n",
    "joblib.dump(test_targets,'test_targets.pkl')\n",
    "joblib.dump(train_targets,'train_targets.pkl')\n",
    "joblib.dump(testInput,'testInput.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.39910973\n",
      "train accuracy = 0.9461383647798742\n",
      "test accuracy = 0.7574183323060667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    clf8.fit(inputs,train_targets)\n",
    "    trainscore = clf8.score(inputs,train_targets)\n",
    "    testscore = clf8.score(testInput,test_targets)\n",
    "    print(\"train accuracy =\",trainscore)\n",
    "    print(\"test accuracy =\",testscore)\n",
    "    print()\n",
    "    if(testscore >= 0.85):\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bestclassifier.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf8,'bestclassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.30603705\n",
      "train accuracy = 0.9596100628930817\n",
      "test accuracy = 0.7553344486513457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    clf8.fit(inputs,train_targets)\n",
    "    trainscore = clf8.score(inputs,train_targets)\n",
    "    testscore = clf8.score(testInput,test_targets)\n",
    "    print(\"train accuracy =\",trainscore)\n",
    "    print(\"test accuracy =\",testscore)\n",
    "    print()\n",
    "    if(testscore >= 0.85):\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf9 = MLPClassifier(activation='relu',solver='adam',hidden_layer_sizes=(2000),verbose=True,max_iter=1,learning_rate_init=0.001,warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.25867071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anantharam\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 0.767245283018868\n",
      "test accuracy = 0.7352000234803792\n",
      "\n",
      "Iteration 2, loss = 0.97126442\n",
      "train accuracy = 0.8109559748427673\n",
      "test accuracy = 0.7408940154383493\n",
      "\n",
      "Iteration 3, loss = 0.77445700\n",
      "train accuracy = 0.8782893081761006\n",
      "test accuracy = 0.7526342050424114\n",
      "\n",
      "Iteration 4, loss = 0.55046666\n",
      "train accuracy = 0.9291069182389937\n",
      "test accuracy = 0.7567432714038331\n",
      "\n",
      "Iteration 5, loss = 0.37510331\n",
      "train accuracy = 0.9531823899371069\n",
      "test accuracy = 0.760294678759062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    clf9.fit(inputs,train_targets)\n",
    "    trainscore = clf9.score(inputs,train_targets)\n",
    "    testscore = clf9.score(testInput,test_targets)\n",
    "    print(\"train accuracy =\",trainscore)\n",
    "    print(\"test accuracy =\",testscore)\n",
    "    print()\n",
    "    if(testscore >= 0.85):\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bestclassifier.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf9,'bestclassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.26947353\n",
      "train accuracy = 0.9657232704402515\n",
      "test accuracy = 0.7552463972293153\n",
      "\n",
      "Iteration 7, loss = 0.21034346\n",
      "train accuracy = 0.9722767295597484\n",
      "test accuracy = 0.7552757477033254\n",
      "\n",
      "Iteration 8, loss = 0.17769268\n",
      "train accuracy = 0.9750062893081761\n",
      "test accuracy = 0.7575357342021074\n",
      "\n",
      "Iteration 9, loss = 0.15779758\n",
      "train accuracy = 0.9772704402515723\n",
      "test accuracy = 0.758210795104341\n",
      "\n",
      "Iteration 10, loss = 0.14651564\n",
      "train accuracy = 0.9786037735849057\n",
      "test accuracy = 0.7573596313580464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    clf9.fit(inputs,train_targets)\n",
    "    trainscore = clf9.score(inputs,train_targets)\n",
    "    testscore = clf9.score(testInput,test_targets)\n",
    "    print(\"train accuracy =\",trainscore)\n",
    "    print(\"test accuracy =\",testscore)\n",
    "    print()\n",
    "    if(testscore >= 0.85):\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.13910668\n",
      "train accuracy = 0.9789056603773585\n",
      "test accuracy = 0.7579466408382496\n",
      "\n",
      "Iteration 12, loss = 0.13388133\n",
      "train accuracy = 0.9788050314465409\n",
      "test accuracy = 0.7539549763728685\n",
      "\n",
      "Iteration 13, loss = 0.13016010\n",
      "train accuracy = 0.9795849056603774\n",
      "test accuracy = 0.7507851251797717\n",
      "\n",
      "Iteration 14, loss = 0.12853066\n",
      "train accuracy = 0.979811320754717\n",
      "test accuracy = 0.7533386164186552\n",
      "\n",
      "Iteration 15, loss = 0.12585240\n",
      "train accuracy = 0.9795849056603774\n",
      "test accuracy = 0.7553050981773356\n",
      "\n",
      "Iteration 16, loss = 0.12511524\n",
      "train accuracy = 0.9795849056603774\n",
      "test accuracy = 0.7537495230547974\n",
      "\n",
      "Iteration 17, loss = 0.12278852\n",
      "train accuracy = 0.9798490566037736\n",
      "test accuracy = 0.754453934431041\n",
      "\n",
      "Iteration 18, loss = 0.12360997\n",
      "train accuracy = 0.9791069182389938\n",
      "test accuracy = 0.7501981156995685\n",
      "\n",
      "Iteration 19, loss = 0.12368824\n",
      "train accuracy = 0.9791572327044025\n",
      "test accuracy = 0.7470282645064718\n",
      "\n",
      "Iteration 20, loss = 0.12166216\n",
      "train accuracy = 0.9801006289308176\n",
      "test accuracy = 0.7508144756537818\n",
      "\n",
      "Iteration 21, loss = 0.12037308\n",
      "train accuracy = 0.9801635220125786\n",
      "test accuracy = 0.7493176014792639\n",
      "\n",
      "Iteration 22, loss = 0.11931164\n",
      "train accuracy = 0.9800754716981132\n",
      "test accuracy = 0.7531331631005841\n",
      "\n",
      "Iteration 23, loss = 0.11750481\n",
      "train accuracy = 0.9803773584905661\n",
      "test accuracy = 0.7490240967391624\n",
      "\n",
      "Iteration 24, loss = 0.11768779\n",
      "train accuracy = 0.9807798742138365\n",
      "test accuracy = 0.7540430277948988\n",
      "\n",
      "Iteration 25, loss = 0.11667412\n",
      "train accuracy = 0.9807798742138365\n",
      "test accuracy = 0.7535440697367263\n",
      "\n",
      "Iteration 26, loss = 0.11749604\n",
      "train accuracy = 0.9791949685534591\n",
      "test accuracy = 0.7464706055002789\n",
      "\n",
      "Iteration 27, loss = 0.11715226\n",
      "train accuracy = 0.9804528301886792\n",
      "test accuracy = 0.7470282645064718\n",
      "\n",
      "Iteration 28, loss = 0.11484628\n",
      "train accuracy = 0.9807924528301887\n",
      "test accuracy = 0.7501981156995685\n",
      "\n",
      "Iteration 29, loss = 0.11497895\n",
      "train accuracy = 0.980993710691824\n",
      "test accuracy = 0.7518710927181474\n",
      "\n",
      "Iteration 30, loss = 0.11572086\n",
      "train accuracy = 0.9804905660377359\n",
      "test accuracy = 0.749904610959467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    clf9.fit(inputs,train_targets)\n",
    "    trainscore = clf9.score(inputs,train_targets)\n",
    "    testscore = clf9.score(testInput,test_targets)\n",
    "    print(\"train accuracy =\",trainscore)\n",
    "    print(\"test accuracy =\",testscore)\n",
    "    print()\n",
    "    if(testscore >= 0.85):\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = joblib.load('inputs.pkl')\n",
    "train_targets = joblib.load('train_targets.pkl')\n",
    "testInput = joblib.load('testInput.pkl')\n",
    "test_targets = joblib.load('test_targets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf10 = MLPClassifier(activation='relu',solver='adam',hidden_layer_sizes=(500,500),verbose=True,max_iter=1,learning_rate_init=0.001,warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.21108389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anantharam\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 0.7691698113207547\n",
      "test accuracy = 0.7275689002377388\n",
      "\n",
      "Iteration 2, loss = 0.90492931\n",
      "train accuracy = 0.8459748427672956\n",
      "test accuracy = 0.7593848140647471\n",
      "\n",
      "Iteration 3, loss = 0.65507040\n",
      "train accuracy = 0.9175220125786163\n",
      "test accuracy = 0.7595902673828182\n",
      "\n",
      "Iteration 4, loss = 0.39610759\n",
      "train accuracy = 0.9528427672955975\n",
      "test accuracy = 0.7641689413284024\n",
      "\n",
      "Iteration 5, loss = 0.24839164\n",
      "train accuracy = 0.9679496855345912\n",
      "test accuracy = 0.7642569927504329\n",
      "\n",
      "Iteration 6, loss = 0.17840160\n",
      "train accuracy = 0.9737106918238994\n",
      "test accuracy = 0.7619676557776408\n",
      "\n",
      "Iteration 7, loss = 0.14671791\n",
      "train accuracy = 0.9771320754716981\n",
      "test accuracy = 0.7617622024595697\n",
      "\n",
      "Iteration 8, loss = 0.12994733\n",
      "train accuracy = 0.977937106918239\n",
      "test accuracy = 0.7651081564967275\n",
      "\n",
      "Iteration 9, loss = 0.12314090\n",
      "train accuracy = 0.9780754716981132\n",
      "test accuracy = 0.7589152064805846\n",
      "\n",
      "Iteration 10, loss = 0.11531927\n",
      "train accuracy = 0.9787169811320755\n",
      "test accuracy = 0.7621437586217017\n",
      "\n",
      "Iteration 11, loss = 0.11234471\n",
      "train accuracy = 0.9781509433962264\n",
      "test accuracy = 0.7641982918024126\n",
      "\n",
      "Iteration 12, loss = 0.13060228\n",
      "train accuracy = 0.9728427672955975\n",
      "test accuracy = 0.7546593877491121\n",
      "\n",
      "Iteration 13, loss = 0.14433900\n",
      "train accuracy = 0.9751320754716981\n",
      "test accuracy = 0.7594728654867776\n",
      "\n",
      "Iteration 14, loss = 0.12884100\n",
      "train accuracy = 0.977937106918239\n",
      "test accuracy = 0.7607936368172346\n",
      "\n",
      "Iteration 15, loss = 0.11263543\n",
      "train accuracy = 0.9786666666666667\n",
      "test accuracy = 0.7650788060227173\n",
      "\n",
      "Iteration 16, loss = 0.10440167\n",
      "train accuracy = 0.9802138364779874\n",
      "test accuracy = 0.7630829737900268\n",
      "\n",
      "Iteration 17, loss = 0.09866389\n",
      "train accuracy = 0.9795723270440252\n",
      "test accuracy = 0.7616154500895189\n",
      "\n",
      "Iteration 18, loss = 0.09462337\n",
      "train accuracy = 0.9809056603773585\n",
      "test accuracy = 0.7636699832702298\n",
      "\n",
      "Iteration 19, loss = 0.09480210\n",
      "train accuracy = 0.9804402515723271\n",
      "test accuracy = 0.7619089548296205\n",
      "\n",
      "Iteration 20, loss = 0.09286693\n",
      "train accuracy = 0.9810188679245283\n",
      "test accuracy = 0.7656951659769305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    clf10.fit(inputs,train_targets)\n",
    "    trainscore = clf10.score(inputs,train_targets)\n",
    "    testscore = clf10.score(testInput,test_targets)\n",
    "    print(\"train accuracy =\",trainscore)\n",
    "    print(\"test accuracy =\",testscore)\n",
    "    print()\n",
    "    if(testscore >= 0.85):\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier_till_now = joblib.load(\"Pickle files/bestclassifier.pkl\")\n",
    "inputs = joblib.load('Pickle files/inputs.pkl')\n",
    "train_targets = joblib.load('Pickle files/train_targets.pkl')\n",
    "testInput = joblib.load('Pickle files/testInput.pkl')\n",
    "test_targets = joblib.load('Pickle files/test_targets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainscore = best_classifier_till_now.score(inputs,train_targets)\n",
    "testscore = best_classifier_till_now.score(testInput,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9531823899371069 0.760294678759062\n"
     ]
    }
   ],
   "source": [
    "print(trainscore,testscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of neurons in hidden layer : 2000\n",
      "No. of neurons in input layer : 2000\n",
      "Activation function : relu\n",
      "Learning rate : 0.001\n",
      "<bound method BaseEstimator.get_params of MLPClassifier(hidden_layer_sizes=2000, max_iter=1, verbose=True,\n",
      "              warm_start=True)> Here warm start means it starts with the same initial weights everytime\n",
      "Train accuracy : 0.9531823899371069\n",
      "Test accuracy : 0.760294678759062\n"
     ]
    }
   ],
   "source": [
    "'''SPECS OF THE CLASSIFIER vvv'''\n",
    "\n",
    "print(\"No. of neurons in hidden layer :\",best_classifier_till_now.hidden_layer_sizes)\n",
    "print(\"No. of neurons in input layer :\",len(inputs[0]))\n",
    "print(\"Activation function :\",best_classifier_till_now.activation)\n",
    "print(\"Learning rate :\",best_classifier_till_now.learning_rate_init)\n",
    "print(best_classifier_till_now.get_params,\"Here warm start means it starts with the same initial weights everytime\")\n",
    "print(\"Train accuracy :\",trainscore)\n",
    "print(\"Test accuracy :\",testscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier_till_now.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MORE DETAILS CAN BE FOUND HERE - https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''MORE DETAILS CAN BE FOUND HERE - https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
